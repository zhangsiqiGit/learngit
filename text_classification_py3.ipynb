{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from tqdm import tqdm\n",
    "from sklearn.svm import SVC\n",
    "from keras.models import Sequential\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from keras.layers import GlobalMaxPool1D, Conv1D, MaxPool1D, Flatten, Bidirectional, SpatialDropout1D\n",
    "from keras.preprocessing import sequence, text\n",
    "from keras.callbacks import EarlyStopping\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\len\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text author\n",
       "0  id26305  This process, however, afforded me no means of...    EAP\n",
       "1  id17569  It never once occurred to me that the fumbling...    HPL\n",
       "2  id11008  In his left hand was a gold snuff box, from wh...    EAP\n",
       "3  id27763  How lovely is spring As we looked from Windsor...    MWS\n",
       "4  id12958  Finding nothing else, not even gold, the Super...    HPL"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "train = pd.read_csv('E://kaggle_train/dataset/train.csv')\n",
    "test = pd.read_csv('E://kaggle_train/dataset/test.csv')\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_logloss(label, predicted, eps = 1e-15):\n",
    "    # Convert 'label' to a binary array if it's not already\n",
    "    if len(label.shape) == 1:\n",
    "        actual = np.zeros((label.shape[0], predicted.shape[1]))\n",
    "        for i, val in enumerate(label):\n",
    "            actual[i, val] = 1\n",
    "        label = actual\n",
    "        \n",
    "    clip = np.clip(predicted, eps, 1-eps)\n",
    "    rows = label.shape[0]\n",
    "    vsota = np.sum(label * np.log(clip))\n",
    "    return -1.0 / rows * vsota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_enc = preprocessing.LabelEncoder()\n",
    "y = lbl_enc.fit_transform(train.author.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xvalid, ytrain, yvalid = train_test_split(train.text.values, y, \n",
    "                                                  stratify=y, \n",
    "                                                  random_state=42, \n",
    "                                                  test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17621,)\n",
      "(1958,)\n"
     ]
    }
   ],
   "source": [
    "print (xtrain.shape)\n",
    "print (xvalid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Always start with these features. They work (almost) everytime!\n",
    "tfv = TfidfVectorizer(min_df=3,  max_features=None, \n",
    "            strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n",
    "            ngram_range=(1, 3), use_idf=1,smooth_idf=1,sublinear_tf=1,\n",
    "            stop_words = 'english')\n",
    "\n",
    "# Fitting TF-IDF to both training and test sets (semi-supervised learning)\n",
    "tfv.fit(list(xtrain) + list(xvalid))\n",
    "xtrain_tfv =  tfv.transform(xtrain) \n",
    "xvalid_tfv = tfv.transform(xvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Software\\Anaconda\\envs\\py3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\Software\\Anaconda\\envs\\py3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.626 \n"
     ]
    }
   ],
   "source": [
    "# Fitting a simple Logistic Regression on TFIDF\n",
    "clf = LogisticRegression(C=1.0)\n",
    "clf.fit(xtrain_tfv, ytrain)\n",
    "predictions = clf.predict_proba(xvalid_tfv)\n",
    "\n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctv = CountVectorizer(analyzer='word',token_pattern=r'\\w{1,}',\n",
    "            ngram_range=(1, 3), stop_words = 'english')\n",
    "\n",
    "# Fitting Count Vectorizer to both training and test sets (semi-supervised learning)\n",
    "ctv.fit(list(xtrain) + list(xvalid))\n",
    "xtrain_ctv =  ctv.transform(xtrain) \n",
    "xvalid_ctv = ctv.transform(xvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.528 \n"
     ]
    }
   ],
   "source": [
    "# Fitting a simple Logistic Regression on Counts\n",
    "clf = LogisticRegression(C=1.0)\n",
    "clf.fit(xtrain_ctv, ytrain)\n",
    "predictions = clf.predict_proba(xvalid_ctv)\n",
    "\n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.578 \n"
     ]
    }
   ],
   "source": [
    "# Fitting a simple Naive Bayes on TFIDF\n",
    "clf = MultinomialNB()\n",
    "clf.fit(xtrain_tfv, ytrain)\n",
    "predictions = clf.predict_proba(xvalid_tfv)\n",
    "\n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.485 \n"
     ]
    }
   ],
   "source": [
    "# Fitting a simple Naive Bayes on Counts\n",
    "clf = MultinomialNB()\n",
    "clf.fit(xtrain_ctv, ytrain)\n",
    "predictions = clf.predict_proba(xvalid_ctv)\n",
    "\n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SVD, I chose 120 components. 120-200 components are good enough for SVM model.\n",
    "svd = decomposition.TruncatedSVD(n_components=120)\n",
    "svd.fit(xtrain_tfv)\n",
    "xtrain_svd = svd.transform(xtrain_tfv)\n",
    "xvalid_svd = svd.transform(xvalid_tfv)\n",
    "\n",
    "# Scale the data obtained from SVD. Renaming variable to reuse without scaling.\n",
    "scl = preprocessing.StandardScaler()\n",
    "scl.fit(xtrain_svd)\n",
    "xtrain_svd_scl = scl.transform(xtrain_svd)\n",
    "xvalid_svd_scl = scl.transform(xvalid_svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.733 \n"
     ]
    }
   ],
   "source": [
    "# Fitting a simple SVM\n",
    "clf = SVC(C=1.0, probability=True) # since we need probabilities\n",
    "clf.fit(xtrain_svd_scl, ytrain)\n",
    "predictions = clf.predict_proba(xvalid_svd_scl)\n",
    "\n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.781 \n"
     ]
    }
   ],
   "source": [
    "# Fitting a simple xgboost on tf-idf\n",
    "clf = xgb.XGBClassifier(max_depth=7, n_estimators=200, colsample_bytree=0.8, \n",
    "                        subsample=0.8, nthread=10, learning_rate=0.1)\n",
    "clf.fit(xtrain_tfv.tocsc(), ytrain)\n",
    "predictions = clf.predict_proba(xvalid_tfv.tocsc())\n",
    "\n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.772 \n"
     ]
    }
   ],
   "source": [
    "# Fitting a simple xgboost on tf-idf\n",
    "clf = xgb.XGBClassifier(max_depth=7, n_estimators=200, colsample_bytree=0.8, \n",
    "                        subsample=0.8, nthread=10, learning_rate=0.1)\n",
    "clf.fit(xtrain_ctv.tocsc(), ytrain)\n",
    "predictions = clf.predict_proba(xvalid_ctv.tocsc())\n",
    "\n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.774 \n"
     ]
    }
   ],
   "source": [
    "# Fitting a simple xgboost on tf-idf svd features\n",
    "clf = xgb.XGBClassifier(max_depth=7, n_estimators=200, colsample_bytree=0.8, \n",
    "                        subsample=0.8, nthread=10, learning_rate=0.1)\n",
    "clf.fit(xtrain_svd, ytrain)\n",
    "predictions = clf.predict_proba(xvalid_svd)\n",
    "\n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.814 \n"
     ]
    }
   ],
   "source": [
    "# Fitting a simple xgboost on tf-idf svd features\n",
    "clf = xgb.XGBClassifier(nthread=10)\n",
    "clf.fit(xtrain_svd, ytrain)\n",
    "predictions = clf.predict_proba(xvalid_svd)\n",
    "\n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mll_scorer = metrics.make_scorer(multiclass_logloss, greater_is_better=False, needs_proba=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SVD\n",
    "svd = TruncatedSVD()\n",
    "    \n",
    "# Initialize the standard scaler \n",
    "scl = preprocessing.StandardScaler()\n",
    "\n",
    "# We will use logistic regression here..\n",
    "lr_model = LogisticRegression()\n",
    "\n",
    "# Create the pipeline \n",
    "clf = pipeline.Pipeline([('svd', svd),\n",
    "                         ('scl', scl),\n",
    "                         ('lr', lr_model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'svd__n_components' : [120, 180],\n",
    "              'lr__C': [0.1, 1.0, 10], \n",
    "              'lr__penalty': ['l1', 'l2']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 12 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:   13.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   24.7s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  24 | elapsed:   33.6s remaining:   33.6s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  24 | elapsed:   40.6s remaining:   24.3s\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  24 | elapsed:   52.7s remaining:   17.5s\n",
      "[Parallel(n_jobs=-1)]: Done  21 out of  24 | elapsed:   57.5s remaining:    8.1s\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:   59.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:   59.5s finished\n",
      "D:\\Software\\Anaconda\\envs\\py3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\Software\\Anaconda\\envs\\py3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -0.740\n",
      "Best parameters set:\n",
      "\tlr__C: 10\n",
      "\tlr__penalty: 'l1'\n",
      "\tsvd__n_components: 180\n"
     ]
    }
   ],
   "source": [
    "# Initialize Grid Search Model\n",
    "model = GridSearchCV(estimator=clf, param_grid=param_grid, scoring=mll_scorer,\n",
    "                                 verbose=10, n_jobs=-1, iid=True, refit=True, cv=2)\n",
    "\n",
    "# Fit Grid Search Model\n",
    "model.fit(xtrain_tfv, ytrain)  # we can use the full data here but im only using xtrain\n",
    "print(\"Best score: %0.3f\" % model.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = model.best_estimator_.get_params()\n",
    "for param_name in sorted(param_grid.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 6 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1240s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  12 | elapsed:    0.0s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  12 | elapsed:    0.1s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  12 | elapsed:    0.2s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of  12 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -0.492\n",
      "Best parameters set:\n",
      "\tnb__alpha: 0.1\n"
     ]
    }
   ],
   "source": [
    "nb_model = MultinomialNB()\n",
    "\n",
    "# Create the pipeline \n",
    "clf = pipeline.Pipeline([('nb', nb_model)])\n",
    "\n",
    "# parameter grid\n",
    "param_grid = {'nb__alpha': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# Initialize Grid Search Model\n",
    "model = GridSearchCV(estimator=clf, param_grid=param_grid, scoring=mll_scorer,\n",
    "                                 verbose=10, n_jobs=-1, iid=True, refit=True, cv=2)\n",
    "\n",
    "# Fit Grid Search Model\n",
    "model.fit(xtrain_tfv, ytrain)  # we can use the full data here but im only using xtrain. \n",
    "print(\"Best score: %0.3f\" % model.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = model.best_estimator_.get_params()\n",
    "for param_name in sorted(param_grid.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0it [00:00, ?it/s]\n",
      "\n",
      "977it [00:00, 9673.28it/s]\n",
      "\n",
      "1744it [00:00, 8939.05it/s]\n",
      "\n",
      "2648it [00:00, 8969.09it/s]\n",
      "\n",
      "3552it [00:00, 8963.50it/s]\n",
      "\n",
      "4589it [00:00, 9343.69it/s]\n",
      "\n",
      "5589it [00:00, 9504.18it/s]\n",
      "\n",
      "6599it [00:00, 9675.41it/s]\n",
      "\n",
      "7701it [00:00, 10015.65it/s]\n",
      "\n",
      "8807it [00:00, 10278.91it/s]\n",
      "\n",
      "9816it [00:01, 10221.49it/s]\n",
      "\n",
      "10857it [00:01, 10246.97it/s]\n",
      "\n",
      "11866it [00:01, 10047.03it/s]\n",
      "\n",
      "12861it [00:01, 9957.58it/s] \n",
      "\n",
      "13850it [00:01, 9937.20it/s]\n",
      "\n",
      "14887it [00:01, 10033.99it/s]\n",
      "\n",
      "15927it [00:01, 10141.05it/s]\n",
      "\n",
      "16981it [00:01, 10227.67it/s]\n",
      "\n",
      "18040it [00:01, 10333.74it/s]\n",
      "\n",
      "19129it [00:01, 10464.31it/s]\n",
      "\n",
      "20176it [00:02, 10311.40it/s]\n",
      "\n",
      "21208it [00:02, 10161.64it/s]\n",
      "\n",
      "22226it [00:02, 9702.03it/s] \n",
      "\n",
      "23202it [00:02, 8681.87it/s]\n",
      "\n",
      "24155it [00:02, 8920.02it/s]\n",
      "\n",
      "25224it [00:02, 9361.60it/s]\n",
      "\n",
      "26195it [00:02, 9435.88it/s]\n",
      "\n",
      "27152it [00:02, 8994.78it/s]\n",
      "\n",
      "28100it [00:02, 9108.72it/s]\n",
      "\n",
      "29064it [00:03, 9261.85it/s]\n",
      "\n",
      "30186it [00:03, 9748.09it/s]\n",
      "\n",
      "31203it [00:03, 9870.94it/s]\n",
      "\n",
      "32245it [00:03, 10000.61it/s]\n",
      "\n",
      "33320it [00:03, 10185.18it/s]\n",
      "\n",
      "34365it [00:03, 10233.06it/s]\n",
      "\n",
      "35393it [00:03, 9751.37it/s] \n",
      "\n",
      "36376it [00:03, 9464.26it/s]\n",
      "\n",
      "37330it [00:03, 9265.72it/s]\n",
      "\n",
      "38374it [00:03, 9562.94it/s]\n",
      "\n",
      "39343it [00:04, 9572.26it/s]\n",
      "\n",
      "40363it [00:04, 9724.42it/s]\n",
      "\n",
      "41392it [00:04, 9887.45it/s]\n",
      "\n",
      "42417it [00:04, 9964.36it/s]\n",
      "\n",
      "43486it [00:04, 10171.49it/s]\n",
      "\n",
      "44506it [00:04, 10149.64it/s]\n",
      "\n",
      "45523it [00:04, 9369.78it/s] \n",
      "\n",
      "46474it [00:04, 9300.95it/s]\n",
      "\n",
      "47414it [00:04, 9060.64it/s]\n",
      "\n",
      "48340it [00:04, 9092.68it/s]\n",
      "\n",
      "49382it [00:05, 9428.29it/s]\n",
      "\n",
      "50392it [00:05, 9592.83it/s]\n",
      "\n",
      "51408it [00:05, 9728.19it/s]\n",
      "\n",
      "52426it [00:05, 9395.38it/s]\n",
      "\n",
      "53372it [00:05, 9036.95it/s]\n",
      "\n",
      "54306it [00:05, 9099.10it/s]\n",
      "\n",
      "55403it [00:05, 9589.75it/s]\n",
      "\n",
      "56373it [00:05, 9509.36it/s]\n",
      "\n",
      "57332it [00:05, 9022.18it/s]\n",
      "\n",
      "58245it [00:06, 8974.16it/s]\n",
      "\n",
      "59355it [00:06, 9521.20it/s]\n",
      "\n",
      "60358it [00:06, 9640.46it/s]\n",
      "\n",
      "61333it [00:06, 8953.55it/s]\n",
      "\n",
      "62246it [00:06, 8772.14it/s]\n",
      "\n",
      "63313it [00:06, 9242.53it/s]\n",
      "\n",
      "64262it [00:06, 9315.40it/s]\n",
      "\n",
      "65205it [00:06, 9001.43it/s]\n",
      "\n",
      "66116it [00:06, 8953.81it/s]\n",
      "\n",
      "67019it [00:07, 8896.94it/s]\n",
      "\n",
      "68135it [00:07, 9449.18it/s]\n",
      "\n",
      "69348it [00:07, 10094.91it/s]\n",
      "\n",
      "70561it [00:07, 10602.06it/s]\n",
      "\n",
      "71669it [00:07, 10741.05it/s]\n",
      "\n",
      "72763it [00:07, 10768.09it/s]\n",
      "\n",
      "73851it [00:07, 9524.85it/s] \n",
      "\n",
      "74838it [00:07, 8849.12it/s]\n",
      "\n",
      "75757it [00:07, 8227.65it/s]\n",
      "\n",
      "76804it [00:08, 8792.57it/s]\n",
      "\n",
      "77932it [00:08, 9391.94it/s]\n",
      "\n",
      "78907it [00:08, 9468.90it/s]\n",
      "\n",
      "79950it [00:08, 9738.10it/s]\n",
      "\n",
      "81205it [00:08, 10413.85it/s]\n",
      "\n",
      "82273it [00:08, 9963.70it/s] \n",
      "\n",
      "83335it [00:08, 10122.89it/s]\n",
      "\n",
      "84376it [00:08, 10207.34it/s]\n",
      "\n",
      "85409it [00:08, 9228.06it/s] \n",
      "\n",
      "86358it [00:09, 8715.46it/s]\n",
      "\n",
      "87254it [00:09, 8710.53it/s]\n",
      "\n",
      "88171it [00:09, 8843.46it/s]\n",
      "\n",
      "89253it [00:09, 9331.99it/s]\n",
      "\n",
      "90398it [00:09, 9854.78it/s]\n",
      "\n",
      "91457it [00:09, 10064.39it/s]\n",
      "\n",
      "92517it [00:09, 9686.98it/s] \n",
      "\n",
      "93581it [00:09, 9954.46it/s]\n",
      "\n",
      "94672it [00:09, 10194.42it/s]\n",
      "\n",
      "95701it [00:09, 9955.85it/s] \n",
      "\n",
      "96705it [00:10, 9366.40it/s]\n",
      "\n",
      "97655it [00:10, 8853.81it/s]\n",
      "\n",
      "98555it [00:10, 8818.70it/s]\n",
      "\n",
      "99460it [00:10, 8860.74it/s]\n",
      "\n",
      "100354it [00:10, 8528.40it/s]\n",
      "\n",
      "101215it [00:10, 8094.40it/s]\n",
      "\n",
      "102085it [00:10, 8243.55it/s]\n",
      "\n",
      "103088it [00:10, 8708.89it/s]\n",
      "\n",
      "104156it [00:10, 9195.54it/s]\n",
      "\n",
      "105092it [00:11, 8926.87it/s]\n",
      "\n",
      "105998it [00:11, 7059.16it/s]\n",
      "\n",
      "106951it [00:11, 7654.53it/s]\n",
      "\n",
      "107974it [00:11, 8259.83it/s]\n",
      "\n",
      "108859it [00:11, 8171.63it/s]\n",
      "\n",
      "109769it [00:11, 8429.62it/s]\n",
      "\n",
      "110726it [00:11, 8718.25it/s]\n",
      "\n",
      "111677it [00:11, 8916.43it/s]\n",
      "\n",
      "112746it [00:11, 9358.82it/s]\n",
      "\n",
      "113701it [00:12, 8815.66it/s]\n",
      "\n",
      "114701it [00:12, 9115.43it/s]\n",
      "\n",
      "115629it [00:12, 8799.23it/s]\n",
      "\n",
      "116646it [00:12, 9170.02it/s]\n",
      "\n",
      "117790it [00:12, 9725.58it/s]\n",
      "\n",
      "118835it [00:12, 9903.89it/s]\n",
      "\n",
      "119942it [00:12, 10198.82it/s]\n",
      "\n",
      "121095it [00:12, 10535.79it/s]\n",
      "\n",
      "122175it [00:12, 10613.68it/s]\n",
      "\n",
      "123291it [00:12, 10740.78it/s]\n",
      "\n",
      "124372it [00:13, 10729.40it/s]\n",
      "\n",
      "125472it [00:13, 10777.40it/s]\n",
      "\n",
      "126580it [00:13, 10866.43it/s]\n",
      "\n",
      "127669it [00:13, 10588.05it/s]\n",
      "\n",
      "128731it [00:13, 10472.22it/s]\n",
      "\n",
      "129786it [00:13, 10495.43it/s]\n",
      "\n",
      "130838it [00:13, 10257.03it/s]\n",
      "\n",
      "131880it [00:13, 10305.38it/s]\n",
      "\n",
      "133095it [00:13, 10768.44it/s]\n",
      "\n",
      "134179it [00:14, 10356.83it/s]\n",
      "\n",
      "135252it [00:14, 10466.03it/s]\n",
      "\n",
      "136305it [00:14, 10064.24it/s]\n",
      "\n",
      "137404it [00:14, 10296.15it/s]\n",
      "\n",
      "138441it [00:14, 9764.40it/s] \n",
      "\n",
      "139428it [00:14, 9297.55it/s]\n",
      "\n",
      "140370it [00:14, 9306.28it/s]\n",
      "\n",
      "141309it [00:14, 9194.20it/s]\n",
      "\n",
      "142395it [00:14, 9637.69it/s]\n",
      "\n",
      "143369it [00:14, 9470.74it/s]\n",
      "\n",
      "144324it [00:15, 9139.99it/s]\n",
      "\n",
      "145246it [00:15, 9055.84it/s]\n",
      "\n",
      "146213it [00:15, 9231.74it/s]\n",
      "\n",
      "147329it [00:15, 9711.01it/s]\n",
      "\n",
      "148461it [00:15, 10116.34it/s]\n",
      "\n",
      "149656it [00:15, 10576.35it/s]\n",
      "\n",
      "150728it [00:15, 10433.01it/s]\n",
      "\n",
      "151782it [00:15, 9685.91it/s] \n",
      "\n",
      "152769it [00:15, 9326.24it/s]\n",
      "\n",
      "153717it [00:16, 8947.28it/s]\n",
      "\n",
      "154778it [00:16, 9363.82it/s]\n",
      "\n",
      "155730it [00:16, 9218.77it/s]\n",
      "\n",
      "156663it [00:16, 9197.13it/s]\n",
      "\n",
      "157648it [00:16, 9356.98it/s]\n",
      "\n",
      "158622it [00:16, 9468.68it/s]\n",
      "\n",
      "159574it [00:16, 9077.09it/s]\n",
      "\n",
      "160489it [00:16, 8835.27it/s]\n",
      "\n",
      "161387it [00:16, 8851.95it/s]\n",
      "\n",
      "162355it [00:17, 9085.09it/s]\n",
      "\n",
      "163507it [00:17, 9675.73it/s]\n",
      "\n",
      "164489it [00:17, 9251.61it/s]\n",
      "\n",
      "165428it [00:17, 9103.50it/s]\n",
      "\n",
      "166440it [00:17, 9386.34it/s]\n",
      "\n",
      "167508it [00:17, 9713.72it/s]\n",
      "\n",
      "168489it [00:17, 9487.99it/s]\n",
      "\n",
      "169446it [00:17, 9290.81it/s]\n",
      "\n",
      "170395it [00:17, 9322.13it/s]\n",
      "\n",
      "171371it [00:17, 9449.31it/s]\n",
      "\n",
      "172320it [00:18, 9186.70it/s]\n",
      "\n",
      "173243it [00:18, 9117.86it/s]\n",
      "\n",
      "174176it [00:18, 8994.63it/s]\n",
      "\n",
      "175078it [00:18, 8690.00it/s]\n",
      "\n",
      "176008it [00:18, 8839.15it/s]\n",
      "\n",
      "176896it [00:18, 8351.87it/s]\n",
      "\n",
      "177916it [00:18, 8809.07it/s]\n",
      "\n",
      "178810it [00:18, 8693.08it/s]\n",
      "\n",
      "179757it [00:18, 8887.33it/s]\n",
      "\n",
      "180654it [00:19, 7319.40it/s]\n",
      "\n",
      "181646it [00:19, 7925.15it/s]\n",
      "\n",
      "182580it [00:19, 8302.45it/s]\n",
      "\n",
      "183451it [00:19, 8002.85it/s]\n",
      "\n",
      "184418it [00:19, 8417.31it/s]\n",
      "\n",
      "185444it [00:19, 8873.58it/s]\n",
      "\n",
      "186493it [00:19, 9278.98it/s]\n",
      "\n",
      "187492it [00:19, 9481.42it/s]\n",
      "\n",
      "188458it [00:19, 8926.39it/s]\n",
      "\n",
      "189370it [00:20, 8904.66it/s]\n",
      "\n",
      "190274it [00:20, 8892.04it/s]\n",
      "\n",
      "191173it [00:20, 8894.72it/s]\n",
      "\n",
      "192165it [00:20, 9153.93it/s]\n",
      "\n",
      "193244it [00:20, 9590.17it/s]\n",
      "\n",
      "194422it [00:20, 10130.39it/s]\n",
      "\n",
      "195500it [00:20, 10316.89it/s]\n",
      "\n",
      "196544it [00:20, 10083.52it/s]\n",
      "\n",
      "197562it [00:20, 9791.31it/s] \n",
      "\n",
      "198550it [00:20, 9561.23it/s]\n",
      "\n",
      "199514it [00:21, 9174.24it/s]\n",
      "\n",
      "200440it [00:21, 9011.79it/s]\n",
      "\n",
      "201348it [00:21, 8873.27it/s]\n",
      "\n",
      "202330it [00:21, 9137.55it/s]\n",
      "\n",
      "203359it [00:21, 9429.24it/s]\n",
      "\n",
      "204342it [00:21, 9518.27it/s]\n",
      "\n",
      "205299it [00:21, 9203.65it/s]\n",
      "\n",
      "206225it [00:21, 9165.73it/s]\n",
      "\n",
      "207160it [00:21, 9193.04it/s]\n",
      "\n",
      "208082it [00:22, 8328.42it/s]\n",
      "\n",
      "209003it [00:22, 8550.77it/s]\n",
      "\n",
      "209872it [00:22, 8110.89it/s]\n",
      "\n",
      "210843it [00:22, 8510.02it/s]\n",
      "\n",
      "211715it [00:22, 8571.94it/s]\n",
      "\n",
      "212583it [00:22, 8553.21it/s]\n",
      "\n",
      "213491it [00:22, 8679.74it/s]\n",
      "\n",
      "214422it [00:22, 8834.46it/s]\n",
      "\n",
      "215397it [00:22, 9065.19it/s]\n",
      "\n",
      "216309it [00:22, 8569.56it/s]\n",
      "\n",
      "217226it [00:23, 8716.34it/s]\n",
      "\n",
      "218180it [00:23, 8948.11it/s]\n",
      "\n",
      "219229it [00:23, 9335.89it/s]\n",
      "\n",
      "220172it [00:23, 8643.00it/s]\n",
      "\n",
      "221091it [00:23, 8800.13it/s]\n",
      "\n",
      "222076it [00:23, 9065.72it/s]\n",
      "\n",
      "223013it [00:23, 9128.16it/s]\n",
      "\n",
      "224103it [00:23, 9596.12it/s]\n",
      "\n",
      "225297it [00:23, 10170.56it/s]\n",
      "\n",
      "226366it [00:24, 10321.01it/s]\n",
      "\n",
      "227411it [00:24, 9888.83it/s] \n",
      "\n",
      "228555it [00:24, 10280.35it/s]\n",
      "\n",
      "229596it [00:24, 9822.34it/s] \n",
      "\n",
      "230671it [00:24, 10055.09it/s]\n",
      "\n",
      "231688it [00:24, 9713.47it/s] \n",
      "\n",
      "232670it [00:24, 9382.07it/s]\n",
      "\n",
      "233618it [00:24, 9165.56it/s]\n",
      "\n",
      "234610it [00:24, 9379.56it/s]\n",
      "\n",
      "235652it [00:24, 9642.36it/s]\n",
      "\n",
      "236762it [00:25, 10037.80it/s]\n",
      "\n",
      "237892it [00:25, 10357.28it/s]\n",
      "\n",
      "238937it [00:25, 9856.01it/s] \n",
      "\n",
      "239934it [00:25, 9548.93it/s]\n",
      "\n",
      "240899it [00:25, 9579.02it/s]\n",
      "\n",
      "241955it [00:25, 9826.13it/s]\n",
      "\n",
      "242945it [00:25, 9732.00it/s]\n",
      "\n",
      "243923it [00:25, 9574.60it/s]\n",
      "\n",
      "244922it [00:25, 9667.40it/s]\n",
      "\n",
      "245892it [00:26, 9368.72it/s]\n",
      "\n",
      "246833it [00:26, 8704.22it/s]\n",
      "\n",
      "247716it [00:26, 8274.65it/s]\n",
      "\n",
      "248661it [00:26, 8595.36it/s]\n",
      "\n",
      "249593it [00:26, 8775.78it/s]\n",
      "\n",
      "250481it [00:26, 8454.62it/s]\n",
      "\n",
      "251349it [00:26, 8520.99it/s]\n",
      "\n",
      "252293it [00:26, 8752.93it/s]\n",
      "\n",
      "253176it [00:26, 8775.91it/s]\n",
      "\n",
      "254123it [00:27, 8947.78it/s]\n",
      "\n",
      "255022it [00:27, 8526.96it/s]\n",
      "\n",
      "255895it [00:27, 8586.87it/s]\n",
      "\n",
      "256759it [00:27, 8551.65it/s]\n",
      "\n",
      "257618it [00:27, 8012.02it/s]\n",
      "\n",
      "258429it [00:27, 7786.40it/s]\n",
      "\n",
      "259216it [00:27, 7629.55it/s]\n",
      "\n",
      "259986it [00:27, 7240.49it/s]\n",
      "\n",
      "260752it [00:27, 7361.44it/s]\n",
      "\n",
      "261495it [00:27, 7338.13it/s]\n",
      "\n",
      "262234it [00:28, 7161.21it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "263064it [00:28, 7448.52it/s]\n",
      "\n",
      "263872it [00:28, 7627.35it/s]\n",
      "\n",
      "264723it [00:28, 7850.52it/s]\n",
      "\n",
      "265514it [00:28, 7488.37it/s]\n",
      "\n",
      "266400it [00:28, 7832.27it/s]\n",
      "\n",
      "267193it [00:28, 7504.25it/s]\n",
      "\n",
      "267953it [00:28, 7422.37it/s]\n",
      "\n",
      "268896it [00:28, 7908.83it/s]\n",
      "\n",
      "269805it [00:29, 8229.64it/s]\n",
      "\n",
      "270641it [00:29, 6863.21it/s]\n",
      "\n",
      "271375it [00:29, 6748.63it/s]\n",
      "\n",
      "272282it [00:29, 7292.27it/s]\n",
      "\n",
      "273273it [00:29, 7919.88it/s]\n",
      "\n",
      "274106it [00:29, 7969.39it/s]\n",
      "\n",
      "275084it [00:29, 8438.04it/s]\n",
      "\n",
      "275956it [00:29, 8026.58it/s]\n",
      "\n",
      "276798it [00:29, 8140.69it/s]\n",
      "\n",
      "277738it [00:30, 8458.68it/s]\n",
      "\n",
      "278599it [00:30, 8164.83it/s]\n",
      "\n",
      "279510it [00:30, 8427.12it/s]\n",
      "\n",
      "280364it [00:30, 8216.47it/s]\n",
      "\n",
      "281457it [00:30, 8856.09it/s]\n",
      "\n",
      "282364it [00:30, 8764.07it/s]\n",
      "\n",
      "283255it [00:30, 8337.58it/s]\n",
      "\n",
      "284226it [00:30, 8706.76it/s]\n",
      "\n",
      "285162it [00:30, 8867.68it/s]\n",
      "\n",
      "286250it [00:31, 9388.62it/s]\n",
      "\n",
      "287396it [00:31, 9901.18it/s]\n",
      "\n",
      "288405it [00:31, 9453.32it/s]\n",
      "\n",
      "289499it [00:31, 9855.09it/s]\n",
      "\n",
      "290502it [00:31, 9705.60it/s]\n",
      "\n",
      "291586it [00:31, 9992.48it/s]\n",
      "\n",
      "292596it [00:31, 9595.91it/s]\n",
      "\n",
      "293660it [00:31, 9886.96it/s]\n",
      "\n",
      "294748it [00:31, 10136.90it/s]\n",
      "\n",
      "295771it [00:31, 10015.38it/s]\n",
      "\n",
      "296905it [00:32, 10350.67it/s]\n",
      "\n",
      "297948it [00:32, 9929.88it/s] \n",
      "\n",
      "299024it [00:32, 10165.15it/s]\n",
      "\n",
      "300112it [00:32, 10339.98it/s]\n",
      "\n",
      "301305it [00:32, 10770.63it/s]\n",
      "\n",
      "302391it [00:32, 10765.17it/s]\n",
      "\n",
      "303474it [00:32, 10263.31it/s]\n",
      "\n",
      "304618it [00:32, 10590.09it/s]\n",
      "\n",
      "305747it [00:32, 10759.93it/s]\n",
      "\n",
      "306831it [00:32, 10501.75it/s]\n",
      "\n",
      "307990it [00:33, 10806.14it/s]\n",
      "\n",
      "309078it [00:33, 10334.50it/s]\n",
      "\n",
      "310186it [00:33, 10517.36it/s]\n",
      "\n",
      "311343it [00:33, 10812.47it/s]\n",
      "\n",
      "312471it [00:33, 10916.83it/s]\n",
      "\n",
      "313568it [00:33, 10867.74it/s]\n",
      "\n",
      "314659it [00:33, 10473.04it/s]\n",
      "\n",
      "315745it [00:33, 10555.34it/s]\n",
      "\n",
      "316851it [00:33, 10701.83it/s]\n",
      "\n",
      "317925it [00:34, 10165.68it/s]\n",
      "\n",
      "319077it [00:34, 10508.48it/s]\n",
      "\n",
      "320137it [00:34, 10171.80it/s]\n",
      "\n",
      "321163it [00:34, 9874.23it/s] \n",
      "\n",
      "322306it [00:34, 10294.59it/s]\n",
      "\n",
      "323346it [00:34, 9969.64it/s] \n",
      "\n",
      "324438it [00:34, 10208.20it/s]\n",
      "\n",
      "325469it [00:34, 10238.52it/s]\n",
      "\n",
      "326499it [00:34, 10226.34it/s]\n",
      "\n",
      "327526it [00:34, 9970.99it/s] \n",
      "\n",
      "328586it [00:35, 10151.71it/s]\n",
      "\n",
      "329744it [00:35, 10074.07it/s]\n",
      "\n",
      "330816it [00:35, 10230.15it/s]\n",
      "\n",
      "331877it [00:35, 10341.21it/s]\n",
      "\n",
      "333021it [00:35, 10618.38it/s]\n",
      "\n",
      "334087it [00:35, 10232.85it/s]\n",
      "\n",
      "335165it [00:35, 10391.07it/s]\n",
      "\n",
      "336355it [00:35, 10772.65it/s]\n",
      "\n",
      "337521it [00:35, 10993.15it/s]\n",
      "\n",
      "338668it [00:36, 11099.68it/s]\n",
      "\n",
      "339813it [00:36, 11169.72it/s]\n",
      "\n",
      "340934it [00:36, 10701.42it/s]\n",
      "\n",
      "342042it [00:36, 10780.69it/s]\n",
      "\n",
      "343125it [00:36, 9061.23it/s] \n",
      "\n",
      "344081it [00:36, 8562.23it/s]\n",
      "\n",
      "345042it [00:36, 8827.37it/s]\n",
      "\n",
      "346175it [00:36, 9453.83it/s]\n",
      "\n",
      "347330it [00:36, 9972.30it/s]\n",
      "\n",
      "348475it [00:37, 10373.94it/s]\n",
      "\n",
      "349539it [00:37, 9870.57it/s] \n",
      "\n",
      "350550it [00:37, 9574.05it/s]\n",
      "\n",
      "351693it [00:37, 10037.78it/s]\n",
      "\n",
      "352824it [00:37, 10359.80it/s]\n",
      "\n",
      "353876it [00:37, 9205.26it/s] \n",
      "\n",
      "355088it [00:37, 9896.74it/s]\n",
      "\n",
      "356274it [00:37, 10413.90it/s]\n",
      "\n",
      "357580it [00:37, 11059.69it/s]\n",
      "\n",
      "358865it [00:38, 11511.09it/s]\n",
      "\n",
      "360055it [00:38, 11591.10it/s]\n",
      "\n",
      "361235it [00:38, 11032.00it/s]\n",
      "\n",
      "362382it [00:38, 11159.84it/s]\n",
      "\n",
      "363514it [00:38, 11174.23it/s]\n",
      "\n",
      "364642it [00:38, 10635.23it/s]\n",
      "\n",
      "365719it [00:38, 9936.61it/s] \n",
      "\n",
      "366912it [00:38, 10460.99it/s]\n",
      "\n",
      "368144it [00:38, 10927.84it/s]\n",
      "\n",
      "369305it [00:38, 11123.91it/s]\n",
      "\n",
      "370432it [00:39, 10690.64it/s]\n",
      "\n",
      "371515it [00:39, 9799.80it/s] \n",
      "\n",
      "372520it [00:39, 6750.08it/s]\n",
      "\n",
      "373341it [00:39, 6472.73it/s]\n",
      "\n",
      "374472it [00:39, 7425.49it/s]\n",
      "\n",
      "375338it [00:39, 7715.77it/s]\n",
      "\n",
      "376412it [00:39, 8427.71it/s]\n",
      "\n",
      "377449it [00:40, 8906.45it/s]\n",
      "\n",
      "378558it [00:40, 9465.56it/s]\n",
      "\n",
      "379560it [00:40, 8675.31it/s]\n",
      "\n",
      "380589it [00:40, 9079.78it/s]\n",
      "\n",
      "381688it [00:40, 9579.28it/s]\n",
      "\n",
      "382682it [00:40, 9277.93it/s]\n",
      "\n",
      "383637it [00:40, 9276.10it/s]\n",
      "\n",
      "384676it [00:40, 9557.91it/s]\n",
      "\n",
      "385741it [00:40, 9833.96it/s]\n",
      "\n",
      "386860it [00:40, 10177.12it/s]\n",
      "\n",
      "387926it [00:41, 9859.30it/s] \n",
      "\n",
      "388933it [00:41, 9921.57it/s]\n",
      "\n",
      "389999it [00:41, 10103.32it/s]\n",
      "\n",
      "391016it [00:41, 9773.02it/s] \n",
      "\n",
      "392181it [00:41, 10269.38it/s]\n",
      "\n",
      "393323it [00:41, 10560.09it/s]\n",
      "\n",
      "394389it [00:41, 10194.88it/s]\n",
      "\n",
      "395557it [00:41, 10570.41it/s]\n",
      "\n",
      "396625it [00:41, 10478.22it/s]\n",
      "\n",
      "397681it [00:42, 9911.18it/s] \n",
      "\n",
      "398684it [00:42, 9631.34it/s]\n",
      "\n",
      "399830it [00:42, 10088.87it/s]\n",
      "\n",
      "400852it [00:42, 9695.49it/s] \n",
      "\n",
      "401896it [00:42, 9907.44it/s]\n",
      "\n",
      "403028it [00:42, 10264.76it/s]\n",
      "\n",
      "404065it [00:42, 10145.01it/s]\n",
      "\n",
      "405183it [00:42, 10405.68it/s]\n",
      "\n",
      "406231it [00:42, 10038.32it/s]\n",
      "\n",
      "407314it [00:43, 10263.39it/s]\n",
      "\n",
      "408366it [00:43, 10308.66it/s]\n",
      "\n",
      "409402it [00:43, 10112.38it/s]\n",
      "\n",
      "410535it [00:43, 10420.45it/s]\n",
      "\n",
      "411583it [00:43, 9821.92it/s] \n",
      "\n",
      "412739it [00:43, 10258.49it/s]\n",
      "\n",
      "413859it [00:43, 10523.89it/s]\n",
      "\n",
      "414922it [00:43, 10132.91it/s]\n",
      "\n",
      "416078it [00:43, 10493.96it/s]\n",
      "\n",
      "417138it [00:43, 10018.20it/s]\n",
      "\n",
      "418261it [00:44, 10324.81it/s]\n",
      "\n",
      "419358it [00:44, 10510.25it/s]\n",
      "\n",
      "420418it [00:44, 10143.76it/s]\n",
      "\n",
      "421542it [00:44, 10420.44it/s]\n",
      "\n",
      "422592it [00:44, 10025.36it/s]\n",
      "\n",
      "423604it [00:44, 8550.12it/s] \n",
      "\n",
      "424632it [00:44, 8981.11it/s]\n",
      "\n",
      "425687it [00:44, 9400.49it/s]\n",
      "\n",
      "426658it [00:44, 9435.91it/s]\n",
      "\n",
      "427718it [00:45, 9757.37it/s]\n",
      "\n",
      "428715it [00:45, 9791.28it/s]\n",
      "\n",
      "429707it [00:45, 9657.30it/s]\n",
      "\n",
      "430792it [00:45, 9959.13it/s]\n",
      "\n",
      "431797it [00:45, 9669.17it/s]\n",
      "\n",
      "432885it [00:45, 10003.14it/s]\n",
      "\n",
      "433971it [00:45, 10216.74it/s]\n",
      "\n",
      "435000it [00:45, 10058.46it/s]\n",
      "\n",
      "436130it [00:45, 10372.66it/s]\n",
      "\n",
      "437174it [00:46, 9890.62it/s] \n",
      "\n",
      "438271it [00:46, 10163.13it/s]\n",
      "\n",
      "439364it [00:46, 10381.65it/s]\n",
      "\n",
      "440410it [00:46, 10045.30it/s]\n",
      "\n",
      "441597it [00:46, 10503.01it/s]\n",
      "\n",
      "442658it [00:46, 10410.83it/s]\n",
      "\n",
      "443746it [00:46, 10050.39it/s]\n",
      "\n",
      "444760it [00:46, 9929.08it/s] \n",
      "\n",
      "445759it [00:46, 9603.05it/s]\n",
      "\n",
      "446917it [00:46, 10094.97it/s]\n",
      "\n",
      "448061it [00:47, 10464.05it/s]\n",
      "\n",
      "449119it [00:47, 10224.63it/s]\n",
      "\n",
      "450179it [00:47, 10334.42it/s]\n",
      "\n",
      "451220it [00:47, 9970.13it/s] \n",
      "\n",
      "452283it [00:47, 10130.28it/s]\n",
      "\n",
      "453351it [00:47, 10289.15it/s]\n",
      "\n",
      "454385it [00:47, 10005.24it/s]\n",
      "\n",
      "455530it [00:47, 10370.62it/s]\n",
      "\n",
      "456652it [00:47, 10611.62it/s]\n",
      "\n",
      "457750it [00:47, 10688.20it/s]\n",
      "\n",
      "458867it [00:48, 10796.93it/s]\n",
      "\n",
      "459951it [00:48, 10809.81it/s]\n",
      "\n",
      "461077it [00:48, 10909.24it/s]\n",
      "\n",
      "462204it [00:48, 11015.02it/s]\n",
      "\n",
      "463308it [00:48, 10796.14it/s]\n",
      "\n",
      "464390it [00:48, 10675.38it/s]\n",
      "\n",
      "465460it [00:48, 10050.59it/s]\n",
      "\n",
      "466612it [00:48, 10422.13it/s]\n",
      "\n",
      "467765it [00:48, 10701.58it/s]\n",
      "\n",
      "468901it [00:49, 10859.72it/s]\n",
      "\n",
      "469994it [00:49, 10784.09it/s]\n",
      "\n",
      "471097it [00:49, 10824.74it/s]\n",
      "\n",
      "472183it [00:49, 10738.86it/s]\n",
      "\n",
      "473361it [00:49, 11000.45it/s]\n",
      "\n",
      "474465it [00:49, 10449.44it/s]\n",
      "\n",
      "475519it [00:49, 10383.55it/s]\n",
      "\n",
      "476581it [00:49, 10422.60it/s]\n",
      "\n",
      "477697it [00:49, 10633.38it/s]\n",
      "\n",
      "478868it [00:49, 10904.44it/s]\n",
      "\n",
      "480027it [00:50, 11101.43it/s]\n",
      "\n",
      "481142it [00:50, 11017.12it/s]\n",
      "\n",
      "482282it [00:50, 11129.25it/s]\n",
      "\n",
      "483412it [00:50, 11146.84it/s]\n",
      "\n",
      "484529it [00:50, 10643.63it/s]\n",
      "\n",
      "485600it [00:50, 10568.75it/s]\n",
      "\n",
      "486662it [00:50, 10217.49it/s]\n",
      "\n",
      "487716it [00:50, 10281.97it/s]\n",
      "\n",
      "488797it [00:50, 10434.88it/s]\n",
      "\n",
      "489844it [00:50, 10414.23it/s]\n",
      "\n",
      "490954it [00:51, 10610.89it/s]\n",
      "\n",
      "492040it [00:51, 10652.98it/s]\n",
      "\n",
      "493180it [00:51, 10866.59it/s]\n",
      "\n",
      "494343it [00:51, 11053.28it/s]\n",
      "\n",
      "495451it [00:51, 10995.41it/s]\n",
      "\n",
      "496553it [00:51, 8686.98it/s] \n",
      "\n",
      "497499it [00:51, 8708.54it/s]\n",
      "\n",
      "498542it [00:51, 9138.12it/s]\n",
      "\n",
      "499713it [00:52, 9758.24it/s]\n",
      "\n",
      "500732it [00:52, 9883.87it/s]\n",
      "\n",
      "501751it [00:52, 9801.09it/s]\n",
      "\n",
      "502899it [00:52, 10223.45it/s]\n",
      "\n",
      "503975it [00:52, 10348.76it/s]\n",
      "\n",
      "505031it [00:52, 10380.54it/s]\n",
      "\n",
      "506121it [00:52, 10500.67it/s]\n",
      "\n",
      "507179it [00:52, 10400.20it/s]\n",
      "\n",
      "508225it [00:52, 10264.71it/s]\n",
      "\n",
      "509319it [00:52, 10428.47it/s]\n",
      "\n",
      "510431it [00:53, 10626.72it/s]\n",
      "\n",
      "511498it [00:53, 10607.94it/s]\n",
      "\n",
      "512572it [00:53, 10615.65it/s]\n",
      "\n",
      "513636it [00:53, 10559.68it/s]\n",
      "\n",
      "514699it [00:53, 10549.18it/s]\n",
      "\n",
      "515776it [00:53, 10614.47it/s]\n",
      "\n",
      "516839it [00:53, 10524.50it/s]\n",
      "\n",
      "517940it [00:53, 10665.59it/s]\n",
      "\n",
      "519073it [00:53, 10825.47it/s]\n",
      "\n",
      "520157it [00:53, 10514.68it/s]\n",
      "\n",
      "521243it [00:54, 10615.95it/s]\n",
      "\n",
      "522368it [00:54, 10767.52it/s]\n",
      "\n",
      "523447it [00:54, 10108.09it/s]\n",
      "\n",
      "524644it [00:54, 10574.77it/s]\n",
      "\n",
      "525747it [00:54, 10676.25it/s]\n",
      "\n",
      "526824it [00:54, 9798.51it/s] \n",
      "\n",
      "527825it [00:54, 8591.47it/s]\n",
      "\n",
      "528726it [00:54, 8123.71it/s]\n",
      "\n",
      "529677it [00:54, 8495.21it/s]\n",
      "\n",
      "530555it [00:55, 8358.20it/s]\n",
      "\n",
      "531570it [00:55, 8802.63it/s]\n",
      "\n",
      "532540it [00:55, 9053.91it/s]\n",
      "\n",
      "533462it [00:55, 8452.20it/s]\n",
      "\n",
      "534359it [00:55, 8601.15it/s]\n",
      "\n",
      "535287it [00:55, 8769.21it/s]\n",
      "\n",
      "536175it [00:55, 8597.62it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "537178it [00:55, 8958.38it/s]\n",
      "\n",
      "538084it [00:55, 8580.03it/s]\n",
      "\n",
      "539006it [00:56, 8737.59it/s]\n",
      "\n",
      "539961it [00:56, 8966.41it/s]\n",
      "\n",
      "540948it [00:56, 9193.87it/s]\n",
      "\n",
      "542081it [00:56, 9719.98it/s]\n",
      "\n",
      "543180it [00:56, 10041.46it/s]\n",
      "\n",
      "544196it [00:56, 9958.21it/s] \n",
      "\n",
      "545233it [00:56, 10048.97it/s]\n",
      "\n",
      "546244it [00:56, 9718.81it/s] \n",
      "\n",
      "547330it [00:56, 10035.16it/s]\n",
      "\n",
      "548400it [00:56, 10196.54it/s]\n",
      "\n",
      "549426it [00:57, 9558.80it/s] \n",
      "\n",
      "550616it [00:57, 10132.42it/s]\n",
      "\n",
      "551746it [00:57, 10427.61it/s]\n",
      "\n",
      "552887it [00:57, 10704.09it/s]\n",
      "\n",
      "553970it [00:57, 8221.77it/s] \n",
      "\n",
      "555097it [00:57, 8926.56it/s]\n",
      "\n",
      "556075it [00:57, 8701.64it/s]\n",
      "\n",
      "557006it [00:57, 8305.54it/s]\n",
      "\n",
      "557912it [00:58, 8518.34it/s]\n",
      "\n",
      "558810it [00:58, 8626.85it/s]\n",
      "\n",
      "559697it [00:58, 8284.06it/s]\n",
      "\n",
      "560627it [00:58, 8541.15it/s]\n",
      "\n",
      "561497it [00:58, 8512.56it/s]\n",
      "\n",
      "562380it [00:58, 8580.29it/s]\n",
      "\n",
      "563315it [00:58, 8797.56it/s]\n",
      "\n",
      "564266it [00:58, 8974.35it/s]\n",
      "\n",
      "565200it [00:58, 9054.60it/s]\n",
      "\n",
      "566217it [00:58, 9362.65it/s]\n",
      "\n",
      "567159it [00:59, 8901.17it/s]\n",
      "\n",
      "568166it [00:59, 9222.30it/s]\n",
      "\n",
      "569098it [00:59, 8906.59it/s]\n",
      "\n",
      "570111it [00:59, 9216.20it/s]\n",
      "\n",
      "571067it [00:59, 9316.71it/s]\n",
      "\n",
      "572006it [00:59, 9310.80it/s]\n",
      "\n",
      "572942it [00:59, 9297.72it/s]\n",
      "\n",
      "573970it [00:59, 9572.11it/s]\n",
      "\n",
      "575014it [00:59, 9789.33it/s]\n",
      "\n",
      "575998it [00:59, 9746.20it/s]\n",
      "\n",
      "576985it [01:00, 9754.01it/s]\n",
      "\n",
      "577963it [01:00, 9450.51it/s]\n",
      "\n",
      "578933it [01:00, 9523.99it/s]\n",
      "\n",
      "580016it [01:00, 9854.51it/s]\n",
      "\n",
      "581007it [01:00, 9841.68it/s]\n",
      "\n",
      "581995it [01:00, 9765.50it/s]\n",
      "\n",
      "583002it [01:00, 9854.89it/s]\n",
      "\n",
      "583990it [01:00, 9357.99it/s]\n",
      "\n",
      "584933it [01:00, 8801.68it/s]\n",
      "\n",
      "585868it [01:01, 8959.30it/s]\n",
      "\n",
      "586933it [01:01, 9382.47it/s]\n",
      "\n",
      "587962it [01:01, 9637.46it/s]\n",
      "\n",
      "588936it [01:01, 9388.42it/s]\n",
      "\n",
      "589966it [01:01, 9617.48it/s]\n",
      "\n",
      "590935it [01:01, 9639.12it/s]\n",
      "\n",
      "591914it [01:01, 9655.24it/s]\n",
      "\n",
      "593023it [01:01, 10017.90it/s]\n",
      "\n",
      "594080it [01:01, 10177.37it/s]\n",
      "\n",
      "595262it [01:01, 10591.59it/s]\n",
      "\n",
      "596329it [01:02, 10277.58it/s]\n",
      "\n",
      "597365it [01:02, 10121.00it/s]\n",
      "\n",
      "598434it [01:02, 10255.64it/s]\n",
      "\n",
      "599465it [01:02, 10090.92it/s]\n",
      "\n",
      "600478it [01:02, 9613.64it/s] \n",
      "\n",
      "601513it [01:02, 9795.42it/s]\n",
      "\n",
      "602542it [01:02, 9910.02it/s]\n",
      "\n",
      "603538it [01:02, 9418.16it/s]\n",
      "\n",
      "604489it [01:02, 9198.84it/s]\n",
      "\n",
      "605416it [01:03, 8901.35it/s]\n",
      "\n",
      "606383it [01:03, 9093.08it/s]\n",
      "\n",
      "607299it [01:03, 9113.05it/s]\n",
      "\n",
      "608283it [01:03, 9293.19it/s]\n",
      "\n",
      "609280it [01:03, 9459.39it/s]\n",
      "\n",
      "610326it [01:03, 9738.87it/s]\n",
      "\n",
      "611310it [01:03, 9739.99it/s]\n",
      "\n",
      "612322it [01:03, 9850.96it/s]\n",
      "\n",
      "613310it [01:03, 9629.03it/s]\n",
      "\n",
      "614276it [01:03, 9524.27it/s]\n",
      "\n",
      "615231it [01:04, 8942.85it/s]\n",
      "\n",
      "616295it [01:04, 9367.49it/s]\n",
      "\n",
      "617341it [01:04, 9670.50it/s]\n",
      "\n",
      "618358it [01:04, 9786.79it/s]\n",
      "\n",
      "619345it [01:04, 9555.14it/s]\n",
      "\n",
      "620308it [01:04, 9063.67it/s]\n",
      "\n",
      "621289it [01:04, 9275.36it/s]\n",
      "\n",
      "622232it [01:04, 9293.66it/s]\n",
      "\n",
      "623168it [01:04, 9043.51it/s]\n",
      "\n",
      "624148it [01:05, 9257.90it/s]\n",
      "\n",
      "625079it [01:05, 8677.10it/s]\n",
      "\n",
      "625958it [01:05, 8459.18it/s]\n",
      "\n",
      "626949it [01:05, 8847.77it/s]\n",
      "\n",
      "627993it [01:05, 9247.36it/s]\n",
      "\n",
      "628974it [01:05, 9382.25it/s]\n",
      "\n",
      "629922it [01:05, 8365.01it/s]\n",
      "\n",
      "630786it [01:05, 7999.91it/s]\n",
      "\n",
      "631741it [01:05, 8007.48it/s]\n",
      "\n",
      "632677it [01:06, 8347.95it/s]\n",
      "\n",
      "633527it [01:06, 8198.69it/s]\n",
      "\n",
      "634391it [01:06, 7980.20it/s]\n",
      "\n",
      "635339it [01:06, 8355.68it/s]\n",
      "\n",
      "636355it [01:06, 8802.96it/s]\n",
      "\n",
      "637250it [01:06, 8768.56it/s]\n",
      "\n",
      "638313it [01:06, 9230.64it/s]\n",
      "\n",
      "639321it [01:06, 9470.02it/s]\n",
      "\n",
      "640304it [01:06, 9547.32it/s]\n",
      "\n",
      "641303it [01:06, 9675.95it/s]\n",
      "\n",
      "642288it [01:07, 9698.78it/s]\n",
      "\n",
      "643294it [01:07, 9804.39it/s]\n",
      "\n",
      "644278it [01:07, 9031.31it/s]\n",
      "\n",
      "645289it [01:07, 9304.20it/s]\n",
      "\n",
      "646263it [01:07, 9403.48it/s]\n",
      "\n",
      "647213it [01:07, 7728.69it/s]\n",
      "\n",
      "648042it [01:07, 7669.97it/s]\n",
      "\n",
      "649072it [01:07, 8286.21it/s]\n",
      "\n",
      "649942it [01:07, 8309.80it/s]\n",
      "\n",
      "650901it [01:08, 8633.10it/s]\n",
      "\n",
      "651854it [01:08, 8883.93it/s]\n",
      "\n",
      "652803it [01:08, 9031.60it/s]\n",
      "\n",
      "653720it [01:08, 8785.83it/s]\n",
      "\n",
      "654703it [01:08, 9075.02it/s]\n",
      "\n",
      "655737it [01:08, 9395.10it/s]\n",
      "\n",
      "656843it [01:08, 9813.26it/s]\n",
      "\n",
      "657906it [01:08, 10044.79it/s]\n",
      "\n",
      "659002it [01:08, 10273.92it/s]\n",
      "\n",
      "660038it [01:09, 9774.83it/s] \n",
      "\n",
      "661102it [01:09, 9991.02it/s]\n",
      "\n",
      "662298it [01:09, 10482.46it/s]\n",
      "\n",
      "663478it [01:09, 10815.94it/s]\n",
      "\n",
      "664571it [01:09, 10722.18it/s]\n",
      "\n",
      "665652it [01:09, 10716.41it/s]\n",
      "\n",
      "666730it [01:09, 9989.31it/s] \n",
      "\n",
      "667743it [01:09, 9337.62it/s]\n",
      "\n",
      "668733it [01:09, 9472.24it/s]\n",
      "\n",
      "669846it [01:09, 9888.87it/s]\n",
      "\n",
      "670945it [01:10, 10195.32it/s]\n",
      "\n",
      "672054it [01:10, 10418.75it/s]\n",
      "\n",
      "673126it [01:10, 10507.33it/s]\n",
      "\n",
      "674184it [01:10, 10313.48it/s]\n",
      "\n",
      "675222it [01:10, 10033.69it/s]\n",
      "\n",
      "676232it [01:10, 9993.81it/s] \n",
      "\n",
      "677280it [01:10, 10105.55it/s]\n",
      "\n",
      "678330it [01:10, 10220.73it/s]\n",
      "\n",
      "679404it [01:10, 10341.20it/s]\n",
      "\n",
      "680441it [01:11, 9848.52it/s] \n",
      "\n",
      "681490it [01:11, 10003.88it/s]\n",
      "\n",
      "682496it [01:11, 9990.80it/s] \n",
      "\n",
      "683499it [01:11, 9943.02it/s]\n",
      "\n",
      "684496it [01:11, 9921.40it/s]\n",
      "\n",
      "685490it [01:11, 9809.41it/s]\n",
      "\n",
      "686473it [01:11, 9447.66it/s]\n",
      "\n",
      "687422it [01:11, 9432.11it/s]\n",
      "\n",
      "688368it [01:11, 9384.28it/s]\n",
      "\n",
      "689309it [01:11, 9363.94it/s]\n",
      "\n",
      "690247it [01:12, 9203.29it/s]\n",
      "\n",
      "691169it [01:12, 8762.00it/s]\n",
      "\n",
      "692131it [01:12, 8977.69it/s]\n",
      "\n",
      "693034it [01:12, 8887.10it/s]\n",
      "\n",
      "693996it [01:12, 9069.25it/s]\n",
      "\n",
      "694907it [01:12, 8895.22it/s]\n",
      "\n",
      "695912it [01:12, 9187.53it/s]\n",
      "\n",
      "696852it [01:12, 9250.25it/s]\n",
      "\n",
      "697781it [01:12, 9234.52it/s]\n",
      "\n",
      "698710it [01:12, 9251.09it/s]\n",
      "\n",
      "699637it [01:13, 7886.48it/s]\n",
      "\n",
      "700653it [01:13, 8454.00it/s]\n",
      "\n",
      "701694it [01:13, 8935.94it/s]\n",
      "\n",
      "702796it [01:13, 9449.05it/s]\n",
      "\n",
      "703899it [01:13, 9873.61it/s]\n",
      "\n",
      "705061it [01:13, 10312.28it/s]\n",
      "\n",
      "706117it [01:13, 10324.44it/s]\n",
      "\n",
      "707205it [01:13, 10454.83it/s]\n",
      "\n",
      "708278it [01:13, 10535.89it/s]\n",
      "\n",
      "709376it [01:14, 10634.32it/s]\n",
      "\n",
      "710448it [01:14, 10659.87it/s]\n",
      "\n",
      "711519it [01:14, 10643.04it/s]\n",
      "\n",
      "712618it [01:14, 10713.38it/s]\n",
      "\n",
      "713746it [01:14, 10877.30it/s]\n",
      "\n",
      "714836it [01:14, 10660.56it/s]\n",
      "\n",
      "715905it [01:14, 10574.39it/s]\n",
      "\n",
      "717032it [01:14, 10773.88it/s]\n",
      "\n",
      "718112it [01:14, 10717.51it/s]\n",
      "\n",
      "719186it [01:14, 10442.71it/s]\n",
      "\n",
      "720233it [01:15, 10327.18it/s]\n",
      "\n",
      "721268it [01:15, 10211.67it/s]\n",
      "\n",
      "722342it [01:15, 10364.62it/s]\n",
      "\n",
      "723381it [01:15, 10099.99it/s]\n",
      "\n",
      "724394it [01:15, 10078.81it/s]\n",
      "\n",
      "725404it [01:15, 9907.08it/s] \n",
      "\n",
      "726453it [01:15, 10046.10it/s]\n",
      "\n",
      "727460it [01:15, 9875.78it/s] \n",
      "\n",
      "728450it [01:15, 9824.20it/s]\n",
      "\n",
      "729434it [01:16, 9487.76it/s]\n",
      "\n",
      "730477it [01:16, 9752.05it/s]\n",
      "\n",
      "731514it [01:16, 9901.13it/s]\n",
      "\n",
      "732508it [01:16, 9596.92it/s]\n",
      "\n",
      "733473it [01:16, 9388.33it/s]\n",
      "\n",
      "734468it [01:16, 9550.06it/s]\n",
      "\n",
      "735530it [01:16, 9820.38it/s]\n",
      "\n",
      "736517it [01:16, 9522.09it/s]\n",
      "\n",
      "737542it [01:16, 9701.75it/s]\n",
      "\n",
      "738595it [01:16, 9936.21it/s]\n",
      "\n",
      "739632it [01:17, 10033.28it/s]\n",
      "\n",
      "740639it [01:17, 9896.20it/s] \n",
      "\n",
      "741632it [01:17, 9847.38it/s]\n",
      "\n",
      "742647it [01:17, 9936.25it/s]\n",
      "\n",
      "743654it [01:17, 9946.44it/s]\n",
      "\n",
      "744650it [01:17, 9361.30it/s]\n",
      "\n",
      "745619it [01:17, 9429.94it/s]\n",
      "\n",
      "746568it [01:17, 7499.26it/s]\n",
      "\n",
      "747557it [01:17, 7835.79it/s]\n",
      "\n",
      "748711it [01:18, 8670.75it/s]\n",
      "\n",
      "749836it [01:18, 9288.11it/s]\n",
      "\n",
      "750918it [01:18, 9700.11it/s]\n",
      "\n",
      "751993it [01:18, 9774.82it/s]\n",
      "\n",
      "753002it [01:18, 9809.73it/s]\n",
      "\n",
      "754005it [01:18, 9646.84it/s]\n",
      "\n",
      "755119it [01:18, 10023.87it/s]\n",
      "\n",
      "756180it [01:18, 10192.79it/s]\n",
      "\n",
      "757211it [01:18, 10197.32it/s]\n",
      "\n",
      "758239it [01:19, 10071.76it/s]\n",
      "\n",
      "759295it [01:19, 10183.88it/s]\n",
      "\n",
      "760318it [01:19, 9759.86it/s] \n",
      "\n",
      "761325it [01:19, 9822.06it/s]\n",
      "\n",
      "762313it [01:19, 9810.06it/s]\n",
      "\n",
      "763298it [01:19, 9454.33it/s]\n",
      "\n",
      "764395it [01:19, 9836.62it/s]\n",
      "\n",
      "765435it [01:19, 9970.36it/s]\n",
      "\n",
      "766438it [01:19, 9841.18it/s]\n",
      "\n",
      "767477it [01:19, 9999.64it/s]\n",
      "\n",
      "768548it [01:20, 10173.57it/s]\n",
      "\n",
      "769638it [01:20, 10351.55it/s]\n",
      "\n",
      "770689it [01:20, 10367.81it/s]\n",
      "\n",
      "771790it [01:20, 10522.21it/s]\n",
      "\n",
      "772845it [01:20, 10436.77it/s]\n",
      "\n",
      "773891it [01:20, 10081.36it/s]\n",
      "\n",
      "775012it [01:20, 10366.51it/s]\n",
      "\n",
      "776054it [01:20, 10382.50it/s]\n",
      "\n",
      "777146it [01:20, 10507.69it/s]\n",
      "\n",
      "778292it [01:20, 10776.33it/s]\n",
      "\n",
      "779374it [01:21, 10445.67it/s]\n",
      "\n",
      "780424it [01:21, 10430.73it/s]\n",
      "\n",
      "781471it [01:21, 10411.32it/s]\n",
      "\n",
      "782515it [01:21, 10236.03it/s]\n",
      "\n",
      "783541it [01:21, 9802.80it/s] \n",
      "\n",
      "784600it [01:21, 9998.00it/s]\n",
      "\n",
      "785763it [01:21, 10409.36it/s]\n",
      "\n",
      "786888it [01:21, 10617.91it/s]\n",
      "\n",
      "787957it [01:21, 10482.93it/s]\n",
      "\n",
      "789035it [01:22, 10539.32it/s]\n",
      "\n",
      "790135it [01:22, 10642.43it/s]\n",
      "\n",
      "791202it [01:22, 10587.29it/s]\n",
      "\n",
      "792263it [01:22, 10197.01it/s]\n",
      "\n",
      "793369it [01:22, 10411.93it/s]\n",
      "\n",
      "794469it [01:22, 10551.19it/s]\n",
      "\n",
      "795528it [01:22, 9938.30it/s] \n",
      "\n",
      "796532it [01:22, 9880.30it/s]\n",
      "\n",
      "797527it [01:22, 9670.17it/s]\n",
      "\n",
      "798524it [01:22, 9729.64it/s]\n",
      "\n",
      "799554it [01:23, 9894.00it/s]\n",
      "\n",
      "800547it [01:23, 9845.85it/s]\n",
      "\n",
      "801580it [01:23, 9986.26it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "802679it [01:23, 10238.89it/s]\n",
      "\n",
      "803735it [01:23, 10333.15it/s]\n",
      "\n",
      "804812it [01:23, 10430.05it/s]\n",
      "\n",
      "805944it [01:23, 10651.84it/s]\n",
      "\n",
      "807022it [01:23, 10689.96it/s]\n",
      "\n",
      "808093it [01:23, 10600.69it/s]\n",
      "\n",
      "809215it [01:23, 10779.18it/s]\n",
      "\n",
      "810328it [01:24, 10850.26it/s]\n",
      "\n",
      "811463it [01:24, 10995.49it/s]\n",
      "\n",
      "812609it [01:24, 11098.50it/s]\n",
      "\n",
      "813721it [01:24, 10941.05it/s]\n",
      "\n",
      "814817it [01:24, 10445.93it/s]\n",
      "\n",
      "815894it [01:24, 10510.22it/s]\n",
      "\n",
      "817038it [01:24, 10742.55it/s]\n",
      "\n",
      "818141it [01:24, 10795.40it/s]\n",
      "\n",
      "819282it [01:24, 10972.71it/s]\n",
      "\n",
      "820383it [01:25, 10790.11it/s]\n",
      "\n",
      "821469it [01:25, 10778.80it/s]\n",
      "\n",
      "822607it [01:25, 10920.84it/s]\n",
      "\n",
      "823701it [01:25, 10893.95it/s]\n",
      "\n",
      "824873it [01:25, 11097.66it/s]\n",
      "\n",
      "825985it [01:25, 10506.33it/s]\n",
      "\n",
      "827117it [01:25, 10707.41it/s]\n",
      "\n",
      "828195it [01:25, 9533.53it/s] \n",
      "\n",
      "829177it [01:25, 9316.59it/s]\n",
      "\n",
      "830130it [01:25, 9136.80it/s]\n",
      "\n",
      "831183it [01:26, 9488.73it/s]\n",
      "\n",
      "832174it [01:26, 9611.30it/s]\n",
      "\n",
      "833197it [01:26, 9760.89it/s]\n",
      "\n",
      "834184it [01:26, 9793.37it/s]\n",
      "\n",
      "835220it [01:26, 9928.12it/s]\n",
      "\n",
      "836351it [01:26, 10277.78it/s]\n",
      "\n",
      "837436it [01:26, 10443.00it/s]\n",
      "\n",
      "838582it [01:26, 10698.59it/s]\n",
      "\n",
      "839706it [01:26, 10855.45it/s]\n",
      "\n",
      "840796it [01:26, 10740.27it/s]\n",
      "\n",
      "841874it [01:27, 10752.15it/s]\n",
      "\n",
      "842952it [01:27, 10327.52it/s]\n",
      "\n",
      "843990it [01:27, 9899.32it/s] \n",
      "\n",
      "844988it [01:27, 9835.37it/s]\n",
      "\n",
      "846001it [01:27, 9892.88it/s]\n",
      "\n",
      "847145it [01:27, 10283.41it/s]\n",
      "\n",
      "848180it [01:27, 9975.59it/s] \n",
      "\n",
      "849185it [01:27, 9909.08it/s]\n",
      "\n",
      "850181it [01:28, 8415.02it/s]\n",
      "\n",
      "851065it [01:28, 8321.16it/s]\n",
      "\n",
      "852125it [01:28, 8872.51it/s]\n",
      "\n",
      "853160it [01:28, 9244.63it/s]\n",
      "\n",
      "854187it [01:28, 9503.63it/s]\n",
      "\n",
      "855211it [01:28, 9685.62it/s]\n",
      "\n",
      "856243it [01:28, 9867.59it/s]\n",
      "\n",
      "857274it [01:28, 9967.28it/s]\n",
      "\n",
      "858326it [01:28, 10126.90it/s]\n",
      "\n",
      "859390it [01:28, 10245.87it/s]\n",
      "\n",
      "860420it [01:29, 10201.07it/s]\n",
      "\n",
      "861504it [01:29, 10354.94it/s]\n",
      "\n",
      "862567it [01:29, 10405.30it/s]\n",
      "\n",
      "863675it [01:29, 10568.60it/s]\n",
      "\n",
      "864734it [01:29, 10327.50it/s]\n",
      "\n",
      "865794it [01:29, 10377.20it/s]\n",
      "\n",
      "866900it [01:29, 10573.02it/s]\n",
      "\n",
      "867960it [01:29, 10394.34it/s]\n",
      "\n",
      "869101it [01:29, 10679.52it/s]\n",
      "\n",
      "870276it [01:29, 10948.92it/s]\n",
      "\n",
      "871454it [01:30, 11185.66it/s]\n",
      "\n",
      "872577it [01:30, 11165.53it/s]\n",
      "\n",
      "873697it [01:30, 10544.54it/s]\n",
      "\n",
      "874788it [01:30, 10620.48it/s]\n",
      "\n",
      "875857it [01:30, 10515.62it/s]\n",
      "\n",
      "876914it [01:30, 10438.27it/s]\n",
      "\n",
      "877962it [01:30, 10357.79it/s]\n",
      "\n",
      "879064it [01:30, 10517.75it/s]\n",
      "\n",
      "880197it [01:30, 10748.92it/s]\n",
      "\n",
      "881275it [01:30, 10726.12it/s]\n",
      "\n",
      "882367it [01:31, 10751.69it/s]\n",
      "\n",
      "883455it [01:31, 10757.87it/s]\n",
      "\n",
      "884532it [01:31, 10602.59it/s]\n",
      "\n",
      "885594it [01:31, 10544.61it/s]\n",
      "\n",
      "886650it [01:31, 10362.88it/s]\n",
      "\n",
      "887688it [01:31, 10066.37it/s]\n",
      "\n",
      "888793it [01:31, 10313.61it/s]\n",
      "\n",
      "889972it [01:31, 10716.18it/s]\n",
      "\n",
      "891136it [01:31, 10946.59it/s]\n",
      "\n",
      "892237it [01:32, 10804.13it/s]\n",
      "\n",
      "893322it [01:32, 10785.59it/s]\n",
      "\n",
      "894404it [01:32, 10668.15it/s]\n",
      "\n",
      "895474it [01:32, 10189.61it/s]\n",
      "\n",
      "896545it [01:32, 10340.33it/s]\n",
      "\n",
      "897584it [01:32, 10202.66it/s]\n",
      "\n",
      "898609it [01:32, 10186.36it/s]\n",
      "\n",
      "899650it [01:32, 10222.24it/s]\n",
      "\n",
      "900675it [01:32, 9904.32it/s] \n",
      "\n",
      "901801it [01:32, 10275.46it/s]\n",
      "\n",
      "902835it [01:33, 10233.61it/s]\n",
      "\n",
      "903998it [01:33, 10587.01it/s]\n",
      "\n",
      "905102it [01:33, 10687.83it/s]\n",
      "\n",
      "906176it [01:33, 10484.01it/s]\n",
      "\n",
      "907272it [01:33, 10591.62it/s]\n",
      "\n",
      "908349it [01:33, 10644.50it/s]\n",
      "\n",
      "909453it [01:33, 10728.78it/s]\n",
      "\n",
      "910539it [01:33, 10735.87it/s]\n",
      "\n",
      "911614it [01:33, 10519.41it/s]\n",
      "\n",
      "912668it [01:33, 10494.13it/s]\n",
      "\n",
      "913771it [01:34, 10618.59it/s]\n",
      "\n",
      "914835it [01:34, 10625.00it/s]\n",
      "\n",
      "915924it [01:34, 10671.68it/s]\n",
      "\n",
      "917013it [01:34, 10704.59it/s]\n",
      "\n",
      "918084it [01:34, 10216.01it/s]\n",
      "\n",
      "919142it [01:34, 10292.42it/s]\n",
      "\n",
      "920175it [01:34, 10212.00it/s]\n",
      "\n",
      "921256it [01:34, 10354.49it/s]\n",
      "\n",
      "922361it [01:34, 10553.77it/s]\n",
      "\n",
      "923506it [01:34, 10777.04it/s]\n",
      "\n",
      "924587it [01:35, 10690.89it/s]\n",
      "\n",
      "925752it [01:35, 10930.77it/s]\n",
      "\n",
      "926848it [01:35, 10810.04it/s]\n",
      "\n",
      "927932it [01:35, 10628.09it/s]\n",
      "\n",
      "928998it [01:35, 10388.83it/s]\n",
      "\n",
      "930064it [01:35, 10468.72it/s]\n",
      "\n",
      "931138it [01:35, 10517.66it/s]\n",
      "\n",
      "932192it [01:35, 10524.35it/s]\n",
      "\n",
      "933246it [01:35, 10466.31it/s]\n",
      "\n",
      "934376it [01:36, 10672.89it/s]\n",
      "\n",
      "935445it [01:36, 10218.68it/s]\n",
      "\n",
      "936492it [01:36, 10262.54it/s]\n",
      "\n",
      "937545it [01:36, 10341.34it/s]\n",
      "\n",
      "938582it [01:36, 10197.26it/s]\n",
      "\n",
      "939605it [01:36, 10026.98it/s]\n",
      "\n",
      "940610it [01:36, 9575.01it/s] \n",
      "\n",
      "941675it [01:36, 9874.01it/s]\n",
      "\n",
      "942770it [01:36, 10145.65it/s]\n",
      "\n",
      "943869it [01:36, 10355.65it/s]\n",
      "\n",
      "944971it [01:37, 10516.20it/s]\n",
      "\n",
      "946098it [01:37, 10700.97it/s]\n",
      "\n",
      "947173it [01:37, 10683.68it/s]\n",
      "\n",
      "948245it [01:37, 10630.92it/s]\n",
      "\n",
      "949329it [01:37, 10692.79it/s]\n",
      "\n",
      "950434it [01:37, 10765.95it/s]\n",
      "\n",
      "951562it [01:37, 10915.17it/s]\n",
      "\n",
      "952655it [01:37, 10822.31it/s]\n",
      "\n",
      "953796it [01:37, 10992.16it/s]\n",
      "\n",
      "954897it [01:38, 9768.12it/s] \n",
      "\n",
      "955901it [01:38, 6917.06it/s]\n",
      "\n",
      "956938it [01:38, 7684.70it/s]\n",
      "\n",
      "957918it [01:38, 7976.02it/s]\n",
      "\n",
      "958956it [01:38, 8550.38it/s]\n",
      "\n",
      "960048it [01:38, 9145.76it/s]\n",
      "\n",
      "961094it [01:38, 9478.17it/s]\n",
      "\n",
      "962157it [01:38, 9796.62it/s]\n",
      "\n",
      "963219it [01:38, 10001.58it/s]\n",
      "\n",
      "964314it [01:39, 10239.59it/s]\n",
      "\n",
      "965402it [01:39, 10423.65it/s]\n",
      "\n",
      "966554it [01:39, 10700.10it/s]\n",
      "\n",
      "967691it [01:39, 10892.63it/s]\n",
      "\n",
      "968831it [01:39, 11008.06it/s]\n",
      "\n",
      "969939it [01:39, 10867.27it/s]\n",
      "\n",
      "971031it [01:39, 10818.35it/s]\n",
      "\n",
      "972117it [01:39, 10671.17it/s]\n",
      "\n",
      "973188it [01:39, 10650.92it/s]\n",
      "\n",
      "974315it [01:39, 10798.26it/s]\n",
      "\n",
      "975447it [01:40, 10917.98it/s]\n",
      "\n",
      "976554it [01:40, 10963.14it/s]\n",
      "\n",
      "977652it [01:40, 10806.27it/s]\n",
      "\n",
      "978734it [01:40, 10682.32it/s]\n",
      "\n",
      "979861it [01:40, 10852.08it/s]\n",
      "\n",
      "980948it [01:40, 10825.02it/s]\n",
      "\n",
      "982032it [01:40, 10701.21it/s]\n",
      "\n",
      "983104it [01:40, 10611.46it/s]\n",
      "\n",
      "984167it [01:40, 10460.30it/s]\n",
      "\n",
      "985221it [01:41, 10452.90it/s]\n",
      "\n",
      "986268it [01:41, 10458.02it/s]\n",
      "\n",
      "987390it [01:41, 10645.13it/s]\n",
      "\n",
      "988456it [01:41, 10586.13it/s]\n",
      "\n",
      "989610it [01:41, 10824.77it/s]\n",
      "\n",
      "990695it [01:41, 10672.49it/s]\n",
      "\n",
      "991765it [01:41, 10492.22it/s]\n",
      "\n",
      "992826it [01:41, 10527.27it/s]\n",
      "\n",
      "993891it [01:41, 10532.46it/s]\n",
      "\n",
      "994995it [01:41, 10679.75it/s]\n",
      "\n",
      "996150it [01:42, 10895.81it/s]\n",
      "\n",
      "997242it [01:42, 9582.70it/s] \n",
      "\n",
      "998231it [01:42, 6771.89it/s]\n",
      "\n",
      "999044it [01:42, 6213.76it/s]\n",
      "\n",
      "999770it [01:42, 5479.82it/s]\n",
      "\n",
      "1000407it [01:42, 4758.30it/s]\n",
      "\n",
      "1000997it [01:43, 5051.55it/s]\n",
      "\n",
      "1001563it [01:43, 4946.20it/s]\n",
      "\n",
      "1002201it [01:43, 5137.23it/s]\n",
      "\n",
      "1002834it [01:43, 5445.03it/s]\n",
      "\n",
      "1003568it [01:43, 5887.96it/s]\n",
      "\n",
      "1004413it [01:43, 6477.11it/s]\n",
      "\n",
      "1005100it [01:43, 6571.27it/s]\n",
      "\n",
      "1006134it [01:43, 7362.25it/s]\n",
      "\n",
      "1007232it [01:43, 8151.61it/s]\n",
      "\n",
      "1008431it [01:43, 8997.36it/s]\n",
      "\n",
      "1009496it [01:44, 9436.67it/s]\n",
      "\n",
      "1010688it [01:44, 10040.35it/s]\n",
      "\n",
      "1011852it [01:44, 10472.09it/s]\n",
      "\n",
      "1013028it [01:44, 10798.01it/s]\n",
      "\n",
      "1014168it [01:44, 10971.82it/s]\n",
      "\n",
      "1015287it [01:44, 10875.49it/s]\n",
      "\n",
      "1016390it [01:44, 10824.91it/s]\n",
      "\n",
      "1017642it [01:44, 11252.79it/s]\n",
      "\n",
      "1018780it [01:44, 11125.08it/s]\n",
      "\n",
      "1019902it [01:44, 11087.26it/s]\n",
      "\n",
      "1021058it [01:45, 11224.97it/s]\n",
      "\n",
      "1022192it [01:45, 11225.80it/s]\n",
      "\n",
      "1023355it [01:45, 11344.07it/s]\n",
      "\n",
      "1024520it [01:45, 11400.59it/s]\n",
      "\n",
      "1025662it [01:45, 11271.31it/s]\n",
      "\n",
      "1026791it [01:45, 11077.74it/s]\n",
      "\n",
      "1027901it [01:45, 9324.55it/s] \n",
      "\n",
      "1028883it [01:45, 8735.14it/s]\n",
      "\n",
      "1029887it [01:45, 9089.54it/s]\n",
      "\n",
      "1030829it [01:46, 9079.97it/s]\n",
      "\n",
      "1031968it [01:46, 9668.21it/s]\n",
      "\n",
      "1033136it [01:46, 10168.39it/s]\n",
      "\n",
      "1034232it [01:46, 10364.12it/s]\n",
      "\n",
      "1035344it [01:46, 10549.76it/s]\n",
      "\n",
      "1036520it [01:46, 10855.69it/s]\n",
      "\n",
      "1037618it [01:46, 10732.97it/s]\n",
      "\n",
      "1038777it [01:46, 10976.47it/s]\n",
      "\n",
      "1039883it [01:46, 10968.67it/s]\n",
      "\n",
      "1041006it [01:46, 11013.29it/s]\n",
      "\n",
      "1042170it [01:47, 11194.10it/s]\n",
      "\n",
      "1043293it [01:47, 11072.28it/s]\n",
      "\n",
      "1044403it [01:47, 10917.10it/s]\n",
      "\n",
      "1045530it [01:47, 11020.62it/s]\n",
      "\n",
      "1046636it [01:47, 10999.50it/s]\n",
      "\n",
      "1047738it [01:47, 10354.18it/s]\n",
      "\n",
      "1048859it [01:47, 10596.88it/s]\n",
      "\n",
      "1049963it [01:47, 10694.87it/s]\n",
      "\n",
      "1051038it [01:47, 10679.42it/s]\n",
      "\n",
      "1052123it [01:48, 10698.29it/s]\n",
      "\n",
      "1053196it [01:48, 10675.82it/s]\n",
      "\n",
      "1054306it [01:48, 10289.09it/s]\n",
      "\n",
      "1055353it [01:48, 10312.14it/s]\n",
      "\n",
      "1056473it [01:48, 10563.35it/s]\n",
      "\n",
      "1057575it [01:48, 10665.27it/s]\n",
      "\n",
      "1058645it [01:48, 10216.94it/s]\n",
      "\n",
      "1059744it [01:48, 10407.55it/s]\n",
      "\n",
      "1060917it [01:48, 10742.29it/s]\n",
      "\n",
      "1062126it [01:48, 11113.96it/s]\n",
      "\n",
      "1063263it [01:49, 11156.62it/s]\n",
      "\n",
      "1064385it [01:49, 11076.26it/s]\n",
      "\n",
      "1065497it [01:49, 10582.77it/s]\n",
      "\n",
      "1066632it [01:49, 10801.82it/s]\n",
      "\n",
      "1067719it [01:49, 10241.02it/s]\n",
      "\n",
      "1068811it [01:49, 10405.85it/s]\n",
      "\n",
      "1069910it [01:49, 10574.46it/s]\n",
      "\n",
      "1070974it [01:49, 10407.51it/s]\n",
      "\n",
      "1072195it [01:49, 10860.73it/s]\n",
      "\n",
      "1073290it [01:50, 10188.38it/s]\n",
      "\n",
      "1074340it [01:50, 10249.81it/s]\n",
      "\n",
      "1075376it [01:50, 9956.50it/s] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1076433it [01:50, 10103.88it/s]\n",
      "\n",
      "1077535it [01:50, 10333.17it/s]\n",
      "\n",
      "1078588it [01:50, 10360.77it/s]\n",
      "\n",
      "1079725it [01:50, 10159.16it/s]\n",
      "\n",
      "1080851it [01:50, 10437.03it/s]\n",
      "\n",
      "1081945it [01:50, 10582.99it/s]\n",
      "\n",
      "1083008it [01:50, 10055.73it/s]\n",
      "\n",
      "1084187it [01:51, 10491.88it/s]\n",
      "\n",
      "1085247it [01:51, 9378.76it/s] \n",
      "\n",
      "1086215it [01:51, 8495.07it/s]\n",
      "\n",
      "1087127it [01:51, 8409.45it/s]\n",
      "\n",
      "1088200it [01:51, 8970.36it/s]\n",
      "\n",
      "1089350it [01:51, 9580.14it/s]\n",
      "\n",
      "1090392it [01:51, 9817.53it/s]\n",
      "\n",
      "1091554it [01:51, 10269.39it/s]\n",
      "\n",
      "1092671it [01:51, 10523.94it/s]\n",
      "\n",
      "1093800it [01:52, 10712.05it/s]\n",
      "\n",
      "1094884it [01:52, 9762.59it/s] \n",
      "\n",
      "1095886it [01:52, 9188.80it/s]\n",
      "\n",
      "1096914it [01:52, 9464.82it/s]\n",
      "\n",
      "1097880it [01:52, 9275.67it/s]\n",
      "\n",
      "1098822it [01:52, 8747.39it/s]\n",
      "\n",
      "1100063it [01:52, 9574.91it/s]\n",
      "\n",
      "1101155it [01:52, 9942.30it/s]\n",
      "\n",
      "1102187it [01:52, 10023.39it/s]\n",
      "\n",
      "1103238it [01:53, 10164.57it/s]\n",
      "\n",
      "1104320it [01:53, 10323.07it/s]\n",
      "\n",
      "1105453it [01:53, 10605.84it/s]\n",
      "\n",
      "1106523it [01:53, 9206.56it/s] \n",
      "\n",
      "1107484it [01:53, 7457.28it/s]\n",
      "\n",
      "1108693it [01:53, 8408.31it/s]\n",
      "\n",
      "1109863it [01:53, 9183.40it/s]\n",
      "\n",
      "1110981it [01:53, 9678.06it/s]\n",
      "\n",
      "1112124it [01:54, 10144.53it/s]\n",
      "\n",
      "1113309it [01:54, 10573.92it/s]\n",
      "\n",
      "1114510it [01:54, 10937.39it/s]\n",
      "\n",
      "1115637it [01:54, 10906.93it/s]\n",
      "\n",
      "1116751it [01:54, 10879.35it/s]\n",
      "\n",
      "1117908it [01:54, 11046.00it/s]\n",
      "\n",
      "1119025it [01:54, 11050.02it/s]\n",
      "\n",
      "1120167it [01:54, 11125.86it/s]\n",
      "\n",
      "1121293it [01:54, 11132.65it/s]\n",
      "\n",
      "1122411it [01:54, 11080.53it/s]\n",
      "\n",
      "1123529it [01:55, 11077.16it/s]\n",
      "\n",
      "1124639it [01:55, 11083.99it/s]\n",
      "\n",
      "1125749it [01:55, 10703.84it/s]\n",
      "\n",
      "1126877it [01:55, 10839.08it/s]\n",
      "\n",
      "1127965it [01:55, 10505.55it/s]\n",
      "\n",
      "1129118it [01:55, 10793.25it/s]\n",
      "\n",
      "1130236it [01:55, 10874.61it/s]\n",
      "\n",
      "1131452it [01:55, 11230.76it/s]\n",
      "\n",
      "1132581it [01:55, 11082.84it/s]\n",
      "\n",
      "1133694it [01:55, 10998.25it/s]\n",
      "\n",
      "1134797it [01:56, 10909.77it/s]\n",
      "\n",
      "1135891it [01:56, 10918.82it/s]\n",
      "\n",
      "1137051it [01:56, 11082.77it/s]\n",
      "\n",
      "1138162it [01:56, 10992.16it/s]\n",
      "\n",
      "1139263it [01:56, 10867.25it/s]\n",
      "\n",
      "1140359it [01:56, 10894.91it/s]\n",
      "\n",
      "1141450it [01:56, 10613.15it/s]\n",
      "\n",
      "1142514it [01:56, 10526.62it/s]\n",
      "\n",
      "1143569it [01:56, 10408.91it/s]\n",
      "\n",
      "1144659it [01:56, 10520.98it/s]\n",
      "\n",
      "1145713it [01:57, 10402.01it/s]\n",
      "\n",
      "1146764it [01:57, 10403.19it/s]\n",
      "\n",
      "1147839it [01:57, 10504.86it/s]\n",
      "\n",
      "1148918it [01:57, 10557.73it/s]\n",
      "\n",
      "1149975it [01:57, 7255.56it/s] \n",
      "\n",
      "1150841it [01:58, 3898.27it/s]\n",
      "\n",
      "1151503it [01:58, 3196.94it/s]\n",
      "\n",
      "1152034it [01:58, 2105.74it/s]\n",
      "\n",
      "1153034it [01:58, 2759.20it/s]\n",
      "\n",
      "1154048it [01:59, 3526.36it/s]\n",
      "\n",
      "1155142it [01:59, 4420.84it/s]\n",
      "\n",
      "1156179it [01:59, 5339.86it/s]\n",
      "\n",
      "1157238it [01:59, 6261.69it/s]\n",
      "\n",
      "1158272it [01:59, 7102.04it/s]\n",
      "\n",
      "1159283it [01:59, 7780.07it/s]\n",
      "\n",
      "1160313it [01:59, 8396.33it/s]\n",
      "\n",
      "1161305it [01:59, 8709.18it/s]\n",
      "\n",
      "1162331it [01:59, 9122.86it/s]\n",
      "\n",
      "1163415it [01:59, 9552.71it/s]\n",
      "\n",
      "1164438it [02:00, 9718.52it/s]\n",
      "\n",
      "1165455it [02:00, 9821.16it/s]\n",
      "\n",
      "1166469it [02:00, 9391.28it/s]\n",
      "\n",
      "1167435it [02:00, 9360.19it/s]\n",
      "\n",
      "1168477it [02:00, 9628.03it/s]\n",
      "\n",
      "1169521it [02:00, 9858.04it/s]\n",
      "\n",
      "1170559it [02:00, 9980.16it/s]\n",
      "\n",
      "1171567it [02:00, 10009.90it/s]\n",
      "\n",
      "1172574it [02:00, 9880.28it/s] \n",
      "\n",
      "1173586it [02:01, 9950.99it/s]\n",
      "\n",
      "1174599it [02:01, 9974.48it/s]\n",
      "\n",
      "1175599it [02:01, 9863.96it/s]\n",
      "\n",
      "1176588it [02:01, 9842.29it/s]\n",
      "\n",
      "1177599it [02:01, 9921.10it/s]\n",
      "\n",
      "1178631it [02:01, 10008.29it/s]\n",
      "\n",
      "1179633it [02:01, 8939.89it/s] \n",
      "\n",
      "1180549it [02:01, 8697.02it/s]\n",
      "\n",
      "1181436it [02:01, 7504.72it/s]\n",
      "\n",
      "1182412it [02:02, 8063.71it/s]\n",
      "\n",
      "1183278it [02:02, 8210.38it/s]\n",
      "\n",
      "1184396it [02:02, 8899.98it/s]\n",
      "\n",
      "1185542it [02:02, 9539.26it/s]\n",
      "\n",
      "1186678it [02:02, 9994.66it/s]\n",
      "\n",
      "1187754it [02:02, 10212.57it/s]\n",
      "\n",
      "1188882it [02:02, 10481.67it/s]\n",
      "\n",
      "1189978it [02:02, 10620.72it/s]\n",
      "\n",
      "1191054it [02:02, 10536.84it/s]\n",
      "\n",
      "1192118it [02:02, 9917.48it/s] \n",
      "\n",
      "1193322it [02:03, 10444.02it/s]\n",
      "\n",
      "1194384it [02:03, 9992.51it/s] \n",
      "\n",
      "1195464it [02:03, 10192.85it/s]\n",
      "\n",
      "1196526it [02:03, 10287.37it/s]\n",
      "\n",
      "1197565it [02:03, 9848.49it/s] \n",
      "\n",
      "1198662it [02:03, 10131.96it/s]\n",
      "\n",
      "1199735it [02:03, 10304.25it/s]\n",
      "\n",
      "1200773it [02:03, 10235.21it/s]\n",
      "\n",
      "1201802it [02:03, 10251.58it/s]\n",
      "\n",
      "1202924it [02:03, 10494.56it/s]\n",
      "\n",
      "1204013it [02:04, 10579.22it/s]\n",
      "\n",
      "1205074it [02:04, 9990.24it/s] \n",
      "\n",
      "1206082it [02:04, 9727.01it/s]\n",
      "\n",
      "1207165it [02:04, 10005.77it/s]\n",
      "\n",
      "1208173it [02:04, 9968.42it/s] \n",
      "\n",
      "1209176it [02:04, 9839.86it/s]\n",
      "\n",
      "1210242it [02:04, 10072.33it/s]\n",
      "\n",
      "1211254it [02:04, 9793.74it/s] \n",
      "\n",
      "1212238it [02:04, 9778.34it/s]\n",
      "\n",
      "1213220it [02:05, 9703.72it/s]\n",
      "\n",
      "1214193it [02:05, 9241.18it/s]\n",
      "\n",
      "1215124it [02:05, 9234.16it/s]\n",
      "\n",
      "1216052it [02:05, 9084.90it/s]\n",
      "\n",
      "1216965it [02:05, 8938.06it/s]\n",
      "\n",
      "1217938it [02:05, 9135.96it/s]\n",
      "\n",
      "1218855it [02:05, 9118.85it/s]\n",
      "\n",
      "1219770it [02:05, 8612.65it/s]\n",
      "\n",
      "1220917it [02:05, 9308.30it/s]\n",
      "\n",
      "1222149it [02:05, 10020.46it/s]\n",
      "\n",
      "1223182it [02:06, 9879.27it/s] \n",
      "\n",
      "1224261it [02:06, 10135.92it/s]\n",
      "\n",
      "1225292it [02:06, 9644.33it/s] \n",
      "\n",
      "1226274it [02:06, 6985.60it/s]\n",
      "\n",
      "1227089it [02:06, 4556.43it/s]\n",
      "\n",
      "1228184it [02:06, 5515.71it/s]\n",
      "\n",
      "1229187it [02:07, 6376.72it/s]\n",
      "\n",
      "1230167it [02:07, 7107.69it/s]\n",
      "\n",
      "1231181it [02:07, 7808.19it/s]\n",
      "\n",
      "1232184it [02:07, 8343.15it/s]\n",
      "\n",
      "1233218it [02:07, 8833.54it/s]\n",
      "\n",
      "1234214it [02:07, 9118.67it/s]\n",
      "\n",
      "1235248it [02:07, 9427.81it/s]\n",
      "\n",
      "1236237it [02:07, 9318.61it/s]\n",
      "\n",
      "1237244it [02:07, 9531.98it/s]\n",
      "\n",
      "1238221it [02:08, 7641.89it/s]\n",
      "\n",
      "1239235it [02:08, 8093.69it/s]\n",
      "\n",
      "1240106it [02:08, 6508.24it/s]\n",
      "\n",
      "1240850it [02:08, 4982.54it/s]\n",
      "\n",
      "1241467it [02:08, 4794.74it/s]\n",
      "\n",
      "1242031it [02:08, 4297.46it/s]\n",
      "\n",
      "1242953it [02:09, 5108.55it/s]\n",
      "\n",
      "1244117it [02:09, 6142.57it/s]\n",
      "\n",
      "1245201it [02:09, 7046.67it/s]\n",
      "\n",
      "1246348it [02:09, 7968.58it/s]\n",
      "\n",
      "1247495it [02:09, 8751.84it/s]\n",
      "\n",
      "1248682it [02:09, 9500.55it/s]\n",
      "\n",
      "1249806it [02:09, 9936.69it/s]\n",
      "\n",
      "1250884it [02:09, 9895.28it/s]\n",
      "\n",
      "1251933it [02:09, 7418.30it/s]\n",
      "\n",
      "1252808it [02:10, 4458.23it/s]\n",
      "\n",
      "1253960it [02:10, 5455.09it/s]\n",
      "\n",
      "1255159it [02:10, 6510.78it/s]\n",
      "\n",
      "1256089it [02:10, 7040.76it/s]\n",
      "\n",
      "1257001it [02:10, 7392.27it/s]\n",
      "\n",
      "1257890it [02:10, 6946.26it/s]\n",
      "\n",
      "1258695it [02:11, 6890.78it/s]\n",
      "\n",
      "1259792it [02:11, 7756.01it/s]\n",
      "\n",
      "1260803it [02:11, 8317.88it/s]\n",
      "\n",
      "1262005it [02:11, 9164.69it/s]\n",
      "\n",
      "1263083it [02:11, 9202.84it/s]\n",
      "\n",
      "1264187it [02:11, 9660.98it/s]\n",
      "\n",
      "1265355it [02:11, 10189.38it/s]\n",
      "\n",
      "1266413it [02:11, 10273.50it/s]\n",
      "\n",
      "1267468it [02:11, 9288.28it/s] \n",
      "\n",
      "1268435it [02:12, 8506.57it/s]\n",
      "\n",
      "1269326it [02:12, 8623.71it/s]\n",
      "\n",
      "1270487it [02:12, 9018.17it/s]\n",
      "\n",
      "1271569it [02:12, 9467.47it/s]\n",
      "\n",
      "1272539it [02:12, 9508.01it/s]\n",
      "\n",
      "1273665it [02:12, 9947.13it/s]\n",
      "\n",
      "1274840it [02:12, 10399.41it/s]\n",
      "\n",
      "1275976it [02:12, 10640.10it/s]\n",
      "\n",
      "1277110it [02:12, 10809.83it/s]\n",
      "\n",
      "1278201it [02:12, 10839.68it/s]\n",
      "\n",
      "1279332it [02:13, 10944.76it/s]\n",
      "\n",
      "1280432it [02:13, 10401.56it/s]\n",
      "\n",
      "1281482it [02:13, 10041.84it/s]\n",
      "\n",
      "1282718it [02:13, 10613.14it/s]\n",
      "\n",
      "1283856it [02:13, 10832.12it/s]\n",
      "\n",
      "1285083it [02:13, 11196.08it/s]\n",
      "\n",
      "1286251it [02:13, 11304.07it/s]\n",
      "\n",
      "1287390it [02:13, 10782.71it/s]\n",
      "\n",
      "1288509it [02:13, 10869.98it/s]\n",
      "\n",
      "1289673it [02:13, 11090.07it/s]\n",
      "\n",
      "1290930it [02:14, 11464.67it/s]\n",
      "\n",
      "1292085it [02:14, 11388.17it/s]\n",
      "\n",
      "1293230it [02:14, 10886.09it/s]\n",
      "\n",
      "1294448it [02:14, 11213.40it/s]\n",
      "\n",
      "1295600it [02:14, 11303.65it/s]\n",
      "\n",
      "1296737it [02:14, 10625.09it/s]\n",
      "\n",
      "1297813it [02:14, 10478.26it/s]\n",
      "\n",
      "1298961it [02:14, 10759.93it/s]\n",
      "\n",
      "1300046it [02:14, 10474.39it/s]\n",
      "\n",
      "1301322it [02:15, 11069.21it/s]\n",
      "\n",
      "1302444it [02:15, 10579.57it/s]\n",
      "\n",
      "1303682it [02:15, 11062.20it/s]\n",
      "\n",
      "1304866it [02:15, 11252.42it/s]\n",
      "\n",
      "1306004it [02:15, 10964.06it/s]\n",
      "\n",
      "1307186it [02:15, 11175.75it/s]\n",
      "\n",
      "1308312it [02:15, 11200.89it/s]\n",
      "\n",
      "1309438it [02:15, 10737.16it/s]\n",
      "\n",
      "1310663it [02:15, 11119.90it/s]\n",
      "\n",
      "1311824it [02:15, 11229.86it/s]\n",
      "\n",
      "1312954it [02:16, 11184.00it/s]\n",
      "\n",
      "1314078it [02:16, 10750.78it/s]\n",
      "\n",
      "1315224it [02:16, 10922.83it/s]\n",
      "\n",
      "1316474it [02:16, 11352.54it/s]\n",
      "\n",
      "1317618it [02:16, 11311.14it/s]\n",
      "\n",
      "1318816it [02:16, 11470.79it/s]\n",
      "\n",
      "1320071it [02:16, 11774.54it/s]\n",
      "\n",
      "1321254it [02:16, 11721.03it/s]\n",
      "\n",
      "1322435it [02:16, 11747.57it/s]\n",
      "\n",
      "1323634it [02:17, 11784.42it/s]\n",
      "\n",
      "1324820it [02:17, 11806.99it/s]\n",
      "\n",
      "1326092it [02:17, 12032.59it/s]\n",
      "\n",
      "1327400it [02:17, 12293.99it/s]\n",
      "\n",
      "1328633it [02:17, 12195.25it/s]\n",
      "\n",
      "1329855it [02:17, 11882.29it/s]\n",
      "\n",
      "1331116it [02:17, 12056.95it/s]\n",
      "\n",
      "1332325it [02:17, 12066.84it/s]\n",
      "\n",
      "1333534it [02:17, 11621.17it/s]\n",
      "\n",
      "1334702it [02:17, 11501.22it/s]\n",
      "\n",
      "1335911it [02:18, 11638.04it/s]\n",
      "\n",
      "1337078it [02:18, 7164.24it/s] \n",
      "\n",
      "1338009it [02:18, 6544.10it/s]\n",
      "\n",
      "1338827it [02:18, 6944.05it/s]\n",
      "\n",
      "1339641it [02:18, 6965.84it/s]\n",
      "\n",
      "1340421it [02:18, 7137.47it/s]\n",
      "\n",
      "1341194it [02:18, 6988.45it/s]\n",
      "\n",
      "1342061it [02:19, 7420.19it/s]\n",
      "\n",
      "1343070it [02:19, 8040.72it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1344294it [02:19, 8963.25it/s]\n",
      "\n",
      "1345253it [02:19, 9039.10it/s]\n",
      "\n",
      "1346201it [02:19, 9114.12it/s]\n",
      "\n",
      "1347222it [02:19, 9391.38it/s]\n",
      "\n",
      "1348478it [02:19, 10160.35it/s]\n",
      "\n",
      "1349628it [02:19, 10499.45it/s]\n",
      "\n",
      "1350706it [02:19, 10520.10it/s]\n",
      "\n",
      "1351933it [02:19, 10960.87it/s]\n",
      "\n",
      "1353105it [02:20, 11146.18it/s]\n",
      "\n",
      "1354270it [02:20, 10731.00it/s]\n",
      "\n",
      "1355402it [02:20, 10869.76it/s]\n",
      "\n",
      "1356577it [02:20, 11119.66it/s]\n",
      "\n",
      "1357804it [02:20, 11409.54it/s]\n",
      "\n",
      "1358990it [02:20, 11541.04it/s]\n",
      "\n",
      "1360150it [02:20, 11355.01it/s]\n",
      "\n",
      "1361360it [02:20, 11568.69it/s]\n",
      "\n",
      "1362554it [02:20, 11643.48it/s]\n",
      "\n",
      "1363722it [02:21, 11550.68it/s]\n",
      "\n",
      "1364880it [02:21, 11524.95it/s]\n",
      "\n",
      "1366051it [02:21, 11579.84it/s]\n",
      "\n",
      "1367211it [02:21, 11482.67it/s]\n",
      "\n",
      "1368465it [02:21, 11780.65it/s]\n",
      "\n",
      "1369692it [02:21, 11888.66it/s]\n",
      "\n",
      "1370904it [02:21, 11921.83it/s]\n",
      "\n",
      "1372098it [02:21, 11513.24it/s]\n",
      "\n",
      "1373262it [02:21, 11516.70it/s]\n",
      "\n",
      "1374417it [02:21, 11458.07it/s]\n",
      "\n",
      "1375574it [02:22, 11491.41it/s]\n",
      "\n",
      "1376725it [02:22, 10908.59it/s]\n",
      "\n",
      "1377909it [02:22, 11172.25it/s]\n",
      "\n",
      "1379158it [02:22, 11505.54it/s]\n",
      "\n",
      "1380316it [02:22, 11324.85it/s]\n",
      "\n",
      "1381459it [02:22, 11322.45it/s]\n",
      "\n",
      "1382669it [02:22, 11545.01it/s]\n",
      "\n",
      "1383921it [02:22, 11787.80it/s]\n",
      "\n",
      "1385173it [02:22, 11998.30it/s]\n",
      "\n",
      "1386499it [02:22, 12316.45it/s]\n",
      "\n",
      "1387736it [02:23, 12186.66it/s]\n",
      "\n",
      "1388959it [02:23, 11949.32it/s]\n",
      "\n",
      "1390158it [02:23, 11855.05it/s]\n",
      "\n",
      "1391347it [02:23, 11163.65it/s]\n",
      "\n",
      "1392474it [02:23, 9871.52it/s] \n",
      "\n",
      "1393496it [02:23, 8462.29it/s]\n",
      "\n",
      "1394408it [02:23, 8624.88it/s]\n",
      "\n",
      "1395583it [02:23, 9350.36it/s]\n",
      "\n",
      "1396566it [02:24, 9434.62it/s]\n",
      "\n",
      "1397670it [02:24, 9864.97it/s]\n",
      "\n",
      "1398685it [02:24, 7182.16it/s]\n",
      "\n",
      "1399625it [02:24, 7729.25it/s]\n",
      "\n",
      "1400497it [02:24, 7486.72it/s]\n",
      "\n",
      "1401398it [02:24, 7866.08it/s]\n",
      "\n",
      "1402530it [02:24, 8638.83it/s]\n",
      "\n",
      "1403662it [02:24, 9299.62it/s]\n",
      "\n",
      "1404871it [02:24, 9966.72it/s]\n",
      "\n",
      "1406033it [02:25, 10411.10it/s]\n",
      "\n",
      "1407232it [02:25, 10809.99it/s]\n",
      "\n",
      "1408466it [02:25, 11227.61it/s]\n",
      "\n",
      "1409662it [02:25, 11405.02it/s]\n",
      "\n",
      "1410908it [02:25, 11669.39it/s]\n",
      "\n",
      "1412110it [02:25, 11772.40it/s]\n",
      "\n",
      "1413299it [02:25, 11702.85it/s]\n",
      "\n",
      "1414478it [02:25, 11522.53it/s]\n",
      "\n",
      "1415637it [02:25, 11474.12it/s]\n",
      "\n",
      "1416789it [02:25, 11419.52it/s]\n",
      "\n",
      "1418090it [02:26, 11821.96it/s]\n",
      "\n",
      "1419379it [02:26, 12089.21it/s]\n",
      "\n",
      "1420594it [02:26, 11790.16it/s]\n",
      "\n",
      "1421779it [02:26, 11737.87it/s]\n",
      "\n",
      "1422957it [02:26, 11715.42it/s]\n",
      "\n",
      "1424132it [02:26, 11587.02it/s]\n",
      "\n",
      "1425293it [02:26, 6709.47it/s] \n",
      "\n",
      "1426416it [02:27, 7615.49it/s]\n",
      "\n",
      "1427598it [02:27, 8525.25it/s]\n",
      "\n",
      "1428820it [02:27, 9354.15it/s]\n",
      "\n",
      "1429969it [02:27, 9906.60it/s]\n",
      "\n",
      "1431141it [02:27, 10361.28it/s]\n",
      "\n",
      "1432264it [02:27, 10518.03it/s]\n",
      "\n",
      "1433437it [02:27, 10824.44it/s]\n",
      "\n",
      "1434579it [02:27, 10996.48it/s]\n",
      "\n",
      "1435711it [02:27, 11059.06it/s]\n",
      "\n",
      "1436840it [02:27, 11094.55it/s]\n",
      "\n",
      "1438053it [02:28, 11386.13it/s]\n",
      "\n",
      "1439205it [02:28, 10906.72it/s]\n",
      "\n",
      "1440362it [02:28, 11097.57it/s]\n",
      "\n",
      "1441482it [02:28, 8692.55it/s] \n",
      "\n",
      "1442461it [02:28, 8896.95it/s]\n",
      "\n",
      "1443737it [02:28, 9763.27it/s]\n",
      "\n",
      "1444895it [02:28, 10245.47it/s]\n",
      "\n",
      "1446076it [02:28, 10640.67it/s]\n",
      "\n",
      "1447252it [02:28, 10922.92it/s]\n",
      "\n",
      "1448458it [02:29, 11240.87it/s]\n",
      "\n",
      "1449607it [02:29, 11149.78it/s]\n",
      "\n",
      "1450740it [02:29, 10725.97it/s]\n",
      "\n",
      "1451994it [02:29, 11182.58it/s]\n",
      "\n",
      "1453154it [02:29, 11304.61it/s]\n",
      "\n",
      "1454353it [02:29, 11468.85it/s]\n",
      "\n",
      "1455595it [02:29, 11705.35it/s]\n",
      "\n",
      "1456773it [02:29, 11589.19it/s]\n",
      "\n",
      "1457957it [02:29, 11628.94it/s]\n",
      "\n",
      "1459143it [02:29, 11662.81it/s]\n",
      "\n",
      "1460337it [02:30, 11710.05it/s]\n",
      "\n",
      "1461510it [02:30, 10960.64it/s]\n",
      "\n",
      "1462719it [02:30, 11245.18it/s]\n",
      "\n",
      "1463925it [02:30, 11445.16it/s]\n",
      "\n",
      "1465109it [02:30, 11527.06it/s]\n",
      "\n",
      "1466299it [02:30, 11636.46it/s]\n",
      "\n",
      "1467496it [02:30, 11700.15it/s]\n",
      "\n",
      "1468721it [02:30, 11859.84it/s]\n",
      "\n",
      "1469910it [02:30, 11693.78it/s]\n",
      "\n",
      "1471121it [02:31, 11815.61it/s]\n",
      "\n",
      "1472355it [02:31, 11933.47it/s]\n",
      "\n",
      "1473550it [02:31, 11693.10it/s]\n",
      "\n",
      "1474722it [02:31, 11562.63it/s]\n",
      "\n",
      "1475947it [02:31, 11726.83it/s]\n",
      "\n",
      "1477122it [02:31, 11663.89it/s]\n",
      "\n",
      "1478290it [02:31, 11530.49it/s]\n",
      "\n",
      "1479445it [02:31, 11399.70it/s]\n",
      "\n",
      "1480661it [02:31, 11584.41it/s]\n",
      "\n",
      "1481822it [02:31, 11592.07it/s]\n",
      "\n",
      "1482983it [02:32, 11528.36it/s]\n",
      "\n",
      "1484137it [02:32, 10910.39it/s]\n",
      "\n",
      "1485312it [02:32, 11117.75it/s]\n",
      "\n",
      "1486506it [02:32, 11320.00it/s]\n",
      "\n",
      "1487699it [02:32, 11496.34it/s]\n",
      "\n",
      "1488883it [02:32, 11563.35it/s]\n",
      "\n",
      "1490043it [02:32, 10920.53it/s]\n",
      "\n",
      "1491145it [02:32, 10726.36it/s]\n",
      "\n",
      "1492306it [02:32, 10945.95it/s]\n",
      "\n",
      "1493486it [02:33, 11157.16it/s]\n",
      "\n",
      "1494666it [02:33, 11309.92it/s]\n",
      "\n",
      "1495802it [02:33, 11028.06it/s]\n",
      "\n",
      "1496910it [02:33, 10817.18it/s]\n",
      "\n",
      "1497996it [02:33, 9044.18it/s] \n",
      "\n",
      "1498953it [02:33, 8508.96it/s]\n",
      "\n",
      "1499847it [02:33, 8559.45it/s]\n",
      "\n",
      "1500733it [02:33, 7562.44it/s]\n",
      "\n",
      "1501675it [02:33, 8037.95it/s]\n",
      "\n",
      "1502517it [02:34, 8032.27it/s]\n",
      "\n",
      "1503347it [02:34, 7165.48it/s]\n",
      "\n",
      "1504131it [02:34, 7334.68it/s]\n",
      "\n",
      "1505286it [02:34, 8236.48it/s]\n",
      "\n",
      "1506500it [02:34, 9095.33it/s]\n",
      "\n",
      "1507476it [02:34, 9285.02it/s]\n",
      "\n",
      "1508684it [02:34, 9952.92it/s]\n",
      "\n",
      "1509726it [02:34, 9803.83it/s]\n",
      "\n",
      "1510853it [02:34, 10174.36it/s]\n",
      "\n",
      "1511898it [02:35, 9990.79it/s] \n",
      "\n",
      "1512917it [02:35, 9677.50it/s]\n",
      "\n",
      "1514063it [02:35, 10124.28it/s]\n",
      "\n",
      "1515375it [02:35, 10841.84it/s]\n",
      "\n",
      "1516523it [02:35, 11025.71it/s]\n",
      "\n",
      "1517645it [02:35, 11017.99it/s]\n",
      "\n",
      "1518760it [02:35, 11057.26it/s]\n",
      "\n",
      "1519928it [02:35, 11204.66it/s]\n",
      "\n",
      "1521203it [02:35, 11627.44it/s]\n",
      "\n",
      "1522455it [02:35, 11847.82it/s]\n",
      "\n",
      "1523648it [02:36, 10896.42it/s]\n",
      "\n",
      "1524758it [02:36, 10734.19it/s]\n",
      "\n",
      "1525961it [02:36, 11062.05it/s]\n",
      "\n",
      "1527120it [02:36, 11215.31it/s]\n",
      "\n",
      "1528325it [02:36, 11420.76it/s]\n",
      "\n",
      "1529475it [02:36, 9106.33it/s] \n",
      "\n",
      "1530466it [02:36, 9229.10it/s]\n",
      "\n",
      "1531505it [02:36, 9368.37it/s]\n",
      "\n",
      "1532719it [02:36, 10032.27it/s]\n",
      "\n",
      "1533943it [02:37, 10578.68it/s]\n",
      "\n",
      "1535107it [02:37, 10845.79it/s]\n",
      "\n",
      "1536219it [02:37, 10376.06it/s]\n",
      "\n",
      "1537281it [02:37, 9976.91it/s] \n",
      "\n",
      "1538434it [02:37, 10369.01it/s]\n",
      "\n",
      "1539608it [02:37, 10716.04it/s]\n",
      "\n",
      "1540798it [02:37, 11015.05it/s]\n",
      "\n",
      "1541913it [02:37, 10613.23it/s]\n",
      "\n",
      "1542987it [02:37, 10587.94it/s]\n",
      "\n",
      "1544122it [02:38, 10774.82it/s]\n",
      "\n",
      "1545347it [02:38, 11178.67it/s]\n",
      "\n",
      "1546474it [02:38, 7509.73it/s] \n",
      "\n",
      "1547391it [02:38, 6778.75it/s]\n",
      "\n",
      "1548322it [02:38, 7363.25it/s]\n",
      "\n",
      "1549270it [02:38, 7891.89it/s]\n",
      "\n",
      "1550384it [02:38, 8628.29it/s]\n",
      "\n",
      "1551632it [02:38, 9487.00it/s]\n",
      "\n",
      "1552741it [02:39, 9708.68it/s]\n",
      "\n",
      "1553928it [02:39, 10269.65it/s]\n",
      "\n",
      "1555120it [02:39, 10685.88it/s]\n",
      "\n",
      "1556293it [02:39, 10979.06it/s]\n",
      "\n",
      "1557421it [02:40, 4240.30it/s] \n",
      "\n",
      "1558545it [02:40, 5207.25it/s]\n",
      "\n",
      "1559681it [02:40, 6207.31it/s]\n",
      "\n",
      "1560881it [02:40, 7258.46it/s]\n",
      "\n",
      "1562192it [02:40, 8364.61it/s]\n",
      "\n",
      "1563330it [02:40, 9086.94it/s]\n",
      "\n",
      "1564518it [02:40, 9752.43it/s]\n",
      "\n",
      "1565661it [02:40, 10174.36it/s]\n",
      "\n",
      "1566801it [02:40, 10455.61it/s]\n",
      "\n",
      "1567934it [02:40, 10703.42it/s]\n",
      "\n",
      "1569072it [02:41, 10866.58it/s]\n",
      "\n",
      "1570203it [02:41, 10900.52it/s]\n",
      "\n",
      "1571325it [02:41, 10559.84it/s]\n",
      "\n",
      "1572503it [02:41, 10868.34it/s]\n",
      "\n",
      "1573609it [02:41, 10734.28it/s]\n",
      "\n",
      "1574697it [02:41, 9977.05it/s] \n",
      "\n",
      "1575892it [02:41, 10469.38it/s]\n",
      "\n",
      "1576991it [02:41, 10620.31it/s]\n",
      "\n",
      "1578068it [02:41, 10357.09it/s]\n",
      "\n",
      "1579116it [02:42, 9837.54it/s] \n",
      "\n",
      "1580345it [02:42, 10437.31it/s]\n",
      "\n",
      "1581460it [02:42, 10641.36it/s]\n",
      "\n",
      "1582666it [02:42, 10970.43it/s]\n",
      "\n",
      "1583776it [02:42, 10361.55it/s]\n",
      "\n",
      "1584829it [02:42, 9828.45it/s] \n",
      "\n",
      "1585970it [02:42, 10254.87it/s]\n",
      "\n",
      "1587147it [02:42, 10637.89it/s]\n",
      "\n",
      "1588288it [02:42, 10858.32it/s]\n",
      "\n",
      "1589386it [02:42, 10862.21it/s]\n",
      "\n",
      "1590481it [02:43, 9912.58it/s] \n",
      "\n",
      "1591711it [02:43, 10525.47it/s]\n",
      "\n",
      "1592790it [02:43, 10449.43it/s]\n",
      "\n",
      "1593965it [02:43, 10808.32it/s]\n",
      "\n",
      "1595062it [02:43, 10452.89it/s]\n",
      "\n",
      "1596121it [02:43, 9660.81it/s] \n",
      "\n",
      "1597109it [02:43, 9032.05it/s]\n",
      "\n",
      "1598041it [02:43, 9089.88it/s]\n",
      "\n",
      "1598967it [02:43, 9006.90it/s]\n",
      "\n",
      "1600164it [02:44, 9705.77it/s]\n",
      "\n",
      "1601159it [02:44, 9580.07it/s]\n",
      "\n",
      "1602352it [02:44, 10155.74it/s]\n",
      "\n",
      "1603457it [02:44, 10408.44it/s]\n",
      "\n",
      "1604515it [02:44, 9015.47it/s] \n",
      "\n",
      "1605715it [02:44, 9742.38it/s]\n",
      "\n",
      "1606892it [02:44, 10246.49it/s]\n",
      "\n",
      "1608143it [02:44, 10806.53it/s]\n",
      "\n",
      "1609272it [02:44, 10947.16it/s]\n",
      "\n",
      "1610393it [02:45, 10557.47it/s]\n",
      "\n",
      "1611470it [02:45, 10227.04it/s]\n",
      "\n",
      "1612665it [02:45, 10660.78it/s]\n",
      "\n",
      "1613786it [02:45, 10788.58it/s]\n",
      "\n",
      "1615039it [02:45, 11227.71it/s]\n",
      "\n",
      "1616175it [02:45, 10664.18it/s]\n",
      "\n",
      "1617257it [02:45, 10341.91it/s]\n",
      "\n",
      "1618549it [02:45, 10972.41it/s]\n",
      "\n",
      "1619701it [02:45, 11131.14it/s]\n",
      "\n",
      "1620904it [02:46, 11354.13it/s]\n",
      "\n",
      "1622084it [02:46, 11484.31it/s]\n",
      "\n",
      "1623241it [02:46, 10831.07it/s]\n",
      "\n",
      "1624436it [02:46, 11144.11it/s]\n",
      "\n",
      "1625578it [02:46, 11192.46it/s]\n",
      "\n",
      "1626747it [02:46, 11304.33it/s]\n",
      "\n",
      "1627921it [02:46, 11398.31it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1629155it [02:46, 11632.38it/s]\n",
      "\n",
      "1630323it [02:46, 11577.36it/s]\n",
      "\n",
      "1631484it [02:46, 11483.98it/s]\n",
      "\n",
      "1632674it [02:47, 11605.70it/s]\n",
      "\n",
      "1633837it [02:47, 11543.82it/s]\n",
      "\n",
      "1634993it [02:47, 11479.85it/s]\n",
      "\n",
      "1636176it [02:47, 11548.78it/s]\n",
      "\n",
      "1637366it [02:47, 11651.95it/s]\n",
      "\n",
      "1638548it [02:47, 11667.21it/s]\n",
      "\n",
      "1639716it [02:47, 11532.76it/s]\n",
      "\n",
      "1640914it [02:47, 11629.41it/s]\n",
      "\n",
      "1642125it [02:47, 11769.53it/s]\n",
      "\n",
      "1643303it [02:47, 11667.74it/s]\n",
      "\n",
      "1644471it [02:48, 11636.52it/s]\n",
      "\n",
      "1645636it [02:48, 11502.64it/s]\n",
      "\n",
      "1646832it [02:48, 11636.13it/s]\n",
      "\n",
      "1648075it [02:48, 11829.57it/s]\n",
      "\n",
      "1649260it [02:48, 11765.19it/s]\n",
      "\n",
      "1650459it [02:48, 11796.81it/s]\n",
      "\n",
      "1651727it [02:48, 12048.57it/s]\n",
      "\n",
      "1653010it [02:48, 12237.71it/s]\n",
      "\n",
      "1654236it [02:48, 12063.66it/s]\n",
      "\n",
      "1655445it [02:48, 11893.43it/s]\n",
      "\n",
      "1656637it [02:49, 11830.51it/s]\n",
      "\n",
      "1657822it [02:49, 11661.63it/s]\n",
      "\n",
      "1659050it [02:49, 11840.50it/s]\n",
      "\n",
      "1660241it [02:49, 11825.94it/s]\n",
      "\n",
      "1661425it [02:49, 11724.71it/s]\n",
      "\n",
      "1662599it [02:49, 11522.08it/s]\n",
      "\n",
      "1663753it [02:49, 10490.07it/s]\n",
      "\n",
      "1664852it [02:49, 10604.42it/s]\n",
      "\n",
      "1666031it [02:49, 10934.28it/s]\n",
      "\n",
      "1667172it [02:50, 11040.64it/s]\n",
      "\n",
      "1668285it [02:50, 10623.62it/s]\n",
      "\n",
      "1669357it [02:50, 7644.30it/s] \n",
      "\n",
      "1670246it [02:50, 5817.80it/s]\n",
      "\n",
      "1670981it [02:50, 5160.23it/s]\n",
      "\n",
      "1671618it [02:51, 2237.36it/s]\n",
      "\n",
      "1672093it [02:51, 2527.77it/s]\n",
      "\n",
      "1672534it [02:51, 2413.48it/s]\n",
      "\n",
      "1672909it [02:51, 2667.82it/s]\n",
      "\n",
      "1673278it [02:52, 2771.92it/s]\n",
      "\n",
      "1673628it [02:52, 2912.15it/s]\n",
      "\n",
      "1674005it [02:52, 3102.36it/s]\n",
      "\n",
      "1674356it [02:52, 3095.30it/s]\n",
      "\n",
      "1675108it [02:52, 3753.16it/s]\n",
      "\n",
      "1675568it [02:52, 3616.51it/s]\n",
      "\n",
      "1676663it [02:52, 4520.23it/s]\n",
      "\n",
      "1677920it [02:52, 5587.70it/s]\n",
      "\n",
      "1679112it [02:52, 6635.94it/s]\n",
      "\n",
      "1680315it [02:52, 7652.68it/s]\n",
      "\n",
      "1681365it [02:53, 8330.37it/s]\n",
      "\n",
      "1682381it [02:53, 7995.32it/s]\n",
      "\n",
      "1683312it [02:53, 8066.88it/s]\n",
      "\n",
      "1684211it [02:53, 6165.54it/s]\n",
      "\n",
      "1685372it [02:53, 7161.66it/s]\n",
      "\n",
      "1686580it [02:53, 8158.13it/s]\n",
      "\n",
      "1687710it [02:53, 8879.57it/s]\n",
      "\n",
      "1688867it [02:53, 9521.90it/s]\n",
      "\n",
      "1689982it [02:54, 9958.12it/s]\n",
      "\n",
      "1691055it [02:54, 9451.58it/s]\n",
      "\n",
      "1692060it [02:54, 8744.30it/s]\n",
      "\n",
      "1693031it [02:54, 8988.20it/s]\n",
      "\n",
      "1694134it [02:54, 9516.70it/s]\n",
      "\n",
      "1695437it [02:54, 10329.62it/s]\n",
      "\n",
      "1696515it [02:54, 7604.82it/s] \n",
      "\n",
      "1697678it [02:54, 8467.39it/s]\n",
      "\n",
      "1698651it [02:55, 8715.67it/s]\n",
      "\n",
      "1699613it [02:55, 7887.63it/s]\n",
      "\n",
      "1700480it [02:55, 7950.97it/s]\n",
      "\n",
      "1701516it [02:55, 8526.12it/s]\n",
      "\n",
      "1702419it [02:55, 8475.94it/s]\n",
      "\n",
      "1703302it [02:55, 8504.77it/s]\n",
      "\n",
      "1704178it [02:55, 7538.68it/s]\n",
      "\n",
      "1705044it [02:55, 7843.35it/s]\n",
      "\n",
      "1705858it [02:56, 4396.50it/s]\n",
      "\n",
      "1706643it [02:56, 5055.19it/s]\n",
      "\n",
      "1707725it [02:56, 6016.92it/s]\n",
      "\n",
      "1708873it [02:56, 7006.12it/s]\n",
      "\n",
      "1709981it [02:56, 7874.73it/s]\n",
      "\n",
      "1711218it [02:56, 8819.38it/s]\n",
      "\n",
      "1712374it [02:56, 9494.67it/s]\n",
      "\n",
      "1713571it [02:56, 10097.05it/s]\n",
      "\n",
      "1714680it [02:57, 9983.45it/s] \n",
      "\n",
      "1715748it [02:57, 9184.42it/s]\n",
      "\n",
      "1716728it [02:57, 8552.10it/s]\n",
      "\n",
      "1717635it [02:57, 7645.03it/s]\n",
      "\n",
      "1718454it [02:57, 6516.04it/s]\n",
      "\n",
      "1719173it [02:58, 3214.99it/s]\n",
      "\n",
      "1719721it [02:58, 3328.96it/s]\n",
      "\n",
      "1720232it [02:58, 3562.19it/s]\n",
      "\n",
      "1720705it [02:58, 2796.36it/s]\n",
      "\n",
      "1721092it [02:58, 2121.99it/s]\n",
      "\n",
      "1721458it [02:59, 2376.07it/s]\n",
      "\n",
      "1721775it [02:59, 2490.39it/s]\n",
      "\n",
      "1722121it [02:59, 2650.25it/s]\n",
      "\n",
      "1722429it [02:59, 2624.61it/s]\n",
      "\n",
      "1722722it [02:59, 2650.50it/s]\n",
      "\n",
      "1723154it [02:59, 2998.09it/s]\n",
      "\n",
      "1723874it [02:59, 3628.91it/s]\n",
      "\n",
      "1724651it [02:59, 4319.55it/s]\n",
      "\n",
      "1725196it [02:59, 4078.75it/s]\n",
      "\n",
      "1725686it [03:00, 3595.16it/s]\n",
      "\n",
      "1726114it [03:00, 3096.19it/s]\n",
      "\n",
      "1726510it [03:00, 2708.08it/s]\n",
      "\n",
      "1726867it [03:00, 2822.59it/s]\n",
      "\n",
      "1727246it [03:00, 3056.66it/s]\n",
      "\n",
      "1727583it [03:00, 2223.31it/s]\n",
      "\n",
      "1727888it [03:01, 2363.83it/s]\n",
      "\n",
      "1728245it [03:01, 2546.03it/s]\n",
      "\n",
      "1729127it [03:01, 3236.75it/s]\n",
      "\n",
      "1730266it [03:01, 4117.46it/s]\n",
      "\n",
      "1731224it [03:01, 4967.14it/s]\n",
      "\n",
      "1732343it [03:01, 5952.24it/s]\n",
      "\n",
      "1733491it [03:01, 6957.24it/s]\n",
      "\n",
      "1734658it [03:01, 7900.23it/s]\n",
      "\n",
      "1735667it [03:01, 8263.55it/s]\n",
      "\n",
      "1736651it [03:02, 7964.13it/s]\n",
      "\n",
      "1737560it [03:02, 7762.88it/s]\n",
      "\n",
      "1738417it [03:02, 7276.40it/s]\n",
      "\n",
      "1739207it [03:02, 6942.06it/s]\n",
      "\n",
      "1740119it [03:02, 7459.44it/s]\n",
      "\n",
      "1741209it [03:02, 8239.69it/s]\n",
      "\n",
      "1742198it [03:02, 8651.14it/s]\n",
      "\n",
      "1743168it [03:02, 8941.18it/s]\n",
      "\n",
      "1744349it [03:02, 9620.42it/s]\n",
      "\n",
      "1745362it [03:03, 9739.65it/s]\n",
      "\n",
      "1746376it [03:03, 9827.74it/s]\n",
      "\n",
      "1747524it [03:03, 10243.73it/s]\n",
      "\n",
      "1748567it [03:03, 9832.86it/s] \n",
      "\n",
      "1749720it [03:03, 10259.66it/s]\n",
      "\n",
      "1750843it [03:03, 10532.68it/s]\n",
      "\n",
      "1752017it [03:03, 10837.88it/s]\n",
      "\n",
      "1753166it [03:03, 10993.97it/s]\n",
      "\n",
      "1754329it [03:03, 11177.35it/s]\n",
      "\n",
      "1755513it [03:03, 11335.57it/s]\n",
      "\n",
      "1756652it [03:04, 11351.84it/s]\n",
      "\n",
      "1757791it [03:04, 11329.36it/s]\n",
      "\n",
      "1758927it [03:04, 9965.85it/s] \n",
      "\n",
      "1760189it [03:04, 10610.14it/s]\n",
      "\n",
      "1761490it [03:04, 11202.68it/s]\n",
      "\n",
      "1762643it [03:04, 6247.79it/s] \n",
      "\n",
      "1763543it [03:05, 5493.31it/s]\n",
      "\n",
      "1764301it [03:05, 4402.11it/s]\n",
      "\n",
      "1764922it [03:05, 2977.73it/s]\n",
      "\n",
      "1765408it [03:06, 1879.73it/s]\n",
      "\n",
      "1765779it [03:06, 1750.34it/s]\n",
      "\n",
      "1766084it [03:06, 1612.26it/s]\n",
      "\n",
      "1766634it [03:06, 1919.75it/s]\n",
      "\n",
      "1766991it [03:06, 2208.16it/s]\n",
      "\n",
      "1767291it [03:07, 2347.38it/s]\n",
      "\n",
      "1767583it [03:08, 720.32it/s] \n",
      "\n",
      "1767809it [03:08, 876.90it/s]\n",
      "\n",
      "1768163it [03:08, 1131.41it/s]\n",
      "\n",
      "1768410it [03:08, 908.36it/s] \n",
      "\n",
      "1768644it [03:08, 1112.56it/s]\n",
      "\n",
      "1768983it [03:08, 1346.89it/s]\n",
      "\n",
      "1769206it [03:09, 1375.72it/s]\n",
      "\n",
      "1769716it [03:09, 1761.66it/s]\n",
      "\n",
      "1770009it [03:10, 763.57it/s] \n",
      "\n",
      "1770413it [03:10, 998.60it/s]\n",
      "\n",
      "1770670it [03:10, 882.70it/s]\n",
      "\n",
      "1770923it [03:13, 245.17it/s]\n",
      "\n",
      "1771067it [03:13, 306.03it/s]\n",
      "\n",
      "1771229it [03:13, 402.33it/s]\n",
      "\n",
      "1771536it [03:13, 542.46it/s]\n",
      "\n",
      "1772063it [03:13, 741.89it/s]\n",
      "\n",
      "1772345it [03:14, 913.58it/s]\n",
      "\n",
      "1772659it [03:14, 1106.44it/s]\n",
      "\n",
      "1773105it [03:14, 1428.73it/s]\n",
      "\n",
      "1773411it [03:14, 1619.71it/s]\n",
      "\n",
      "1773884it [03:14, 2012.60it/s]\n",
      "\n",
      "1774344it [03:14, 2417.33it/s]\n",
      "\n",
      "1774803it [03:14, 2731.90it/s]\n",
      "\n",
      "1775183it [03:14, 2657.93it/s]\n",
      "\n",
      "1775586it [03:14, 2960.29it/s]\n",
      "\n",
      "1775981it [03:15, 3193.14it/s]\n",
      "\n",
      "1776350it [03:15, 3318.57it/s]\n",
      "\n",
      "1776809it [03:15, 3610.80it/s]\n",
      "\n",
      "1777423it [03:15, 4119.92it/s]\n",
      "\n",
      "1777883it [03:15, 3762.57it/s]\n",
      "\n",
      "1778327it [03:15, 3932.58it/s]\n",
      "\n",
      "1779144it [03:15, 4578.92it/s]\n",
      "\n",
      "1779706it [03:15, 4835.85it/s]\n",
      "\n",
      "1780293it [03:15, 5105.70it/s]\n",
      "\n",
      "1781341it [03:16, 6013.22it/s]\n",
      "\n",
      "1782467it [03:16, 6990.41it/s]\n",
      "\n",
      "1783537it [03:16, 7602.30it/s]\n",
      "\n",
      "1784655it [03:16, 8390.72it/s]\n",
      "\n",
      "1785624it [03:16, 8718.78it/s]\n",
      "\n",
      "1786905it [03:16, 9620.95it/s]\n",
      "\n",
      "1787946it [03:16, 5214.36it/s]\n",
      "\n",
      "1788750it [03:17, 4551.82it/s]\n",
      "\n",
      "1789418it [03:17, 2275.76it/s]\n",
      "\n",
      "1790581it [03:17, 2997.22it/s]\n",
      "\n",
      "1791713it [03:18, 3841.48it/s]\n",
      "\n",
      "1792849it [03:18, 4787.11it/s]\n",
      "\n",
      "1793784it [03:18, 5608.16it/s]\n",
      "\n",
      "1794938it [03:18, 6619.25it/s]\n",
      "\n",
      "1795925it [03:18, 6026.47it/s]\n",
      "\n",
      "1796766it [03:18, 5808.59it/s]\n",
      "\n",
      "1797515it [03:18, 5599.46it/s]\n",
      "\n",
      "1798306it [03:18, 6137.27it/s]\n",
      "\n",
      "1799271it [03:19, 6874.92it/s]\n",
      "\n",
      "1800443it [03:19, 7589.09it/s]\n",
      "\n",
      "1801294it [03:19, 6481.62it/s]\n",
      "\n",
      "1802333it [03:19, 7082.02it/s]\n",
      "\n",
      "1803123it [03:19, 7209.01it/s]\n",
      "\n",
      "1804101it [03:19, 7807.48it/s]\n",
      "\n",
      "1805187it [03:19, 8526.46it/s]\n",
      "\n",
      "1806113it [03:19, 8564.39it/s]\n",
      "\n",
      "1807010it [03:19, 8607.19it/s]\n",
      "\n",
      "1807900it [03:20, 8397.70it/s]\n",
      "\n",
      "1808761it [03:20, 8102.04it/s]\n",
      "\n",
      "1809589it [03:20, 7920.60it/s]\n",
      "\n",
      "1810708it [03:20, 8681.54it/s]\n",
      "\n",
      "1811903it [03:20, 9435.17it/s]\n",
      "\n",
      "1812962it [03:20, 9727.40it/s]\n",
      "\n",
      "1813966it [03:20, 9274.87it/s]\n",
      "\n",
      "1814920it [03:20, 8712.24it/s]\n",
      "\n",
      "1815891it [03:20, 8964.46it/s]\n",
      "\n",
      "1816807it [03:21, 8133.05it/s]\n",
      "\n",
      "1817841it [03:21, 8667.60it/s]\n",
      "\n",
      "1818826it [03:21, 8966.83it/s]\n",
      "\n",
      "1820037it [03:21, 9700.63it/s]\n",
      "\n",
      "1821041it [03:21, 9658.59it/s]\n",
      "\n",
      "1822031it [03:21, 8657.66it/s]\n",
      "\n",
      "1822933it [03:21, 8396.20it/s]\n",
      "\n",
      "1823800it [03:21, 8402.57it/s]\n",
      "\n",
      "1824955it [03:21, 9128.95it/s]\n",
      "\n",
      "1825900it [03:22, 9037.72it/s]\n",
      "\n",
      "1826827it [03:22, 7699.39it/s]\n",
      "\n",
      "1827745it [03:22, 8069.54it/s]\n",
      "\n",
      "1828592it [03:22, 7977.49it/s]\n",
      "\n",
      "1829566it [03:22, 8435.42it/s]\n",
      "\n",
      "1830437it [03:22, 8203.16it/s]\n",
      "\n",
      "1831278it [03:22, 7804.02it/s]\n",
      "\n",
      "1832229it [03:22, 8247.89it/s]\n",
      "\n",
      "1833519it [03:22, 9228.62it/s]\n",
      "\n",
      "1834670it [03:23, 9812.07it/s]\n",
      "\n",
      "1835913it [03:23, 10447.44it/s]\n",
      "\n",
      "1837078it [03:23, 10751.46it/s]\n",
      "\n",
      "1838383it [03:23, 11321.72it/s]\n",
      "\n",
      "1839594it [03:23, 11514.27it/s]\n",
      "\n",
      "1840768it [03:23, 11546.90it/s]\n",
      "\n",
      "1841939it [03:23, 11459.18it/s]\n",
      "\n",
      "1843097it [03:23, 11427.11it/s]\n",
      "\n",
      "1844268it [03:23, 11476.69it/s]\n",
      "\n",
      "1845428it [03:23, 11513.40it/s]\n",
      "\n",
      "1846717it [03:24, 11861.65it/s]\n",
      "\n",
      "1847909it [03:24, 11208.87it/s]\n",
      "\n",
      "1849070it [03:24, 11293.22it/s]\n",
      "\n",
      "1850208it [03:24, 10991.14it/s]\n",
      "\n",
      "1851315it [03:24, 8091.97it/s] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1852240it [03:25, 4463.91it/s]\n",
      "\n",
      "1852953it [03:25, 3431.05it/s]\n",
      "\n",
      "1853519it [03:25, 2624.32it/s]\n",
      "\n",
      "1853966it [03:25, 2465.11it/s]\n",
      "\n",
      "1854344it [03:26, 2369.34it/s]\n",
      "\n",
      "1854674it [03:26, 2564.19it/s]\n",
      "\n",
      "1855000it [03:26, 2443.87it/s]\n",
      "\n",
      "1855295it [03:26, 2098.20it/s]\n",
      "\n",
      "1855628it [03:26, 2350.11it/s]\n",
      "\n",
      "1856170it [03:26, 2831.18it/s]\n",
      "\n",
      "1857390it [03:26, 3675.36it/s]\n",
      "\n",
      "1858588it [03:26, 4635.00it/s]\n",
      "\n",
      "1859685it [03:27, 5606.26it/s]\n",
      "\n",
      "1860610it [03:27, 6344.48it/s]\n",
      "\n",
      "1861790it [03:27, 7366.16it/s]\n",
      "\n",
      "1862802it [03:27, 8001.93it/s]\n",
      "\n",
      "1863975it [03:27, 8845.31it/s]\n",
      "\n",
      "1865183it [03:27, 9595.02it/s]\n",
      "\n",
      "1866347it [03:27, 10102.50it/s]\n",
      "\n",
      "1867546it [03:27, 10603.25it/s]\n",
      "\n",
      "1868681it [03:27, 10259.44it/s]\n",
      "\n",
      "1869762it [03:27, 9957.95it/s] \n",
      "\n",
      "1870923it [03:28, 10374.11it/s]\n",
      "\n",
      "1872119it [03:28, 10774.69it/s]\n",
      "\n",
      "1873369it [03:28, 11240.11it/s]\n",
      "\n",
      "1874644it [03:28, 11622.28it/s]\n",
      "\n",
      "1875827it [03:28, 11513.26it/s]\n",
      "\n",
      "1877026it [03:28, 11618.39it/s]\n",
      "\n",
      "1878318it [03:28, 11980.47it/s]\n",
      "\n",
      "1879527it [03:28, 11941.92it/s]\n",
      "\n",
      "1880729it [03:28, 11720.23it/s]\n",
      "\n",
      "1881963it [03:28, 11899.52it/s]\n",
      "\n",
      "1883158it [03:29, 11670.28it/s]\n",
      "\n",
      "1884330it [03:29, 11512.96it/s]\n",
      "\n",
      "1885485it [03:29, 11489.66it/s]\n",
      "\n",
      "1886637it [03:29, 8828.61it/s] \n",
      "\n",
      "1887775it [03:29, 9465.24it/s]\n",
      "\n",
      "1888801it [03:29, 9121.81it/s]\n",
      "\n",
      "1889999it [03:29, 9825.03it/s]\n",
      "\n",
      "1891266it [03:29, 10508.47it/s]\n",
      "\n",
      "1892370it [03:30, 10420.92it/s]\n",
      "\n",
      "1893694it [03:30, 11103.99it/s]\n",
      "\n",
      "1894950it [03:30, 11504.07it/s]\n",
      "\n",
      "1896131it [03:30, 10372.25it/s]\n",
      "\n",
      "1897211it [03:30, 10496.97it/s]\n",
      "\n",
      "1898541it [03:30, 11177.20it/s]\n",
      "\n",
      "1899692it [03:30, 10953.11it/s]\n",
      "\n",
      "1900941it [03:30, 11372.94it/s]\n",
      "\n",
      "1902100it [03:30, 11403.45it/s]\n",
      "\n",
      "1903256it [03:30, 10838.08it/s]\n",
      "\n",
      "1904537it [03:31, 11362.82it/s]\n",
      "\n",
      "1905692it [03:31, 11317.64it/s]\n",
      "\n",
      "1906837it [03:31, 11256.54it/s]\n",
      "\n",
      "1908069it [03:31, 11523.36it/s]\n",
      "\n",
      "1909230it [03:31, 11514.85it/s]\n",
      "\n",
      "1910442it [03:31, 11656.23it/s]\n",
      "\n",
      "1911612it [03:31, 10098.14it/s]\n",
      "\n",
      "1912866it [03:31, 10697.21it/s]\n",
      "\n",
      "1914162it [03:31, 11259.07it/s]\n",
      "\n",
      "1915431it [03:32, 11653.27it/s]\n",
      "\n",
      "1916626it [03:32, 11706.24it/s]\n",
      "\n",
      "1917816it [03:32, 11167.56it/s]\n",
      "\n",
      "1919047it [03:32, 11455.32it/s]\n",
      "\n",
      "1920211it [03:32, 11510.10it/s]\n",
      "\n",
      "1921373it [03:32, 11144.32it/s]\n",
      "\n",
      "1922524it [03:32, 11218.66it/s]\n",
      "\n",
      "1923653it [03:32, 10851.06it/s]\n",
      "\n",
      "1924856it [03:32, 11148.66it/s]\n",
      "\n",
      "1926020it [03:32, 11258.89it/s]\n",
      "\n",
      "1927152it [03:33, 11243.55it/s]\n",
      "\n",
      "1928281it [03:33, 10682.26it/s]\n",
      "\n",
      "1929551it [03:33, 11187.26it/s]\n",
      "\n",
      "1930682it [03:33, 10593.06it/s]\n",
      "\n",
      "1931757it [03:33, 10244.23it/s]\n",
      "\n",
      "1932939it [03:33, 10642.19it/s]\n",
      "\n",
      "1934017it [03:33, 10169.19it/s]\n",
      "\n",
      "1935186it [03:33, 10553.54it/s]\n",
      "\n",
      "1936426it [03:33, 11017.58it/s]\n",
      "\n",
      "1937599it [03:34, 11189.94it/s]\n",
      "\n",
      "1938729it [03:34, 10681.70it/s]\n",
      "\n",
      "1939862it [03:34, 10868.26it/s]\n",
      "\n",
      "1940990it [03:34, 10956.57it/s]\n",
      "\n",
      "1942093it [03:34, 10629.37it/s]\n",
      "\n",
      "1943163it [03:34, 10432.39it/s]\n",
      "\n",
      "1944212it [03:34, 10205.61it/s]\n",
      "\n",
      "1945468it [03:34, 10785.87it/s]\n",
      "\n",
      "1946724it [03:34, 11263.15it/s]\n",
      "\n",
      "1947865it [03:35, 11273.30it/s]\n",
      "\n",
      "1949069it [03:35, 11460.03it/s]\n",
      "\n",
      "1950332it [03:35, 11754.70it/s]\n",
      "\n",
      "1951631it [03:35, 12066.19it/s]\n",
      "\n",
      "1952980it [03:35, 12460.74it/s]\n",
      "\n",
      "1954235it [03:35, 12160.68it/s]\n",
      "\n",
      "1955459it [03:35, 11796.84it/s]\n",
      "\n",
      "1956647it [03:35, 11716.74it/s]\n",
      "\n",
      "1957825it [03:35, 11700.67it/s]\n",
      "\n",
      "1958999it [03:35, 11608.22it/s]\n",
      "\n",
      "1960163it [03:36, 11118.36it/s]\n",
      "\n",
      "1961443it [03:36, 11543.24it/s]\n",
      "\n",
      "1962633it [03:36, 11613.90it/s]\n",
      "\n",
      "1963801it [03:36, 11230.94it/s]\n",
      "\n",
      "1964982it [03:36, 11398.61it/s]\n",
      "\n",
      "1966128it [03:36, 11382.94it/s]\n",
      "\n",
      "1967271it [03:36, 11363.02it/s]\n",
      "\n",
      "1968417it [03:36, 11358.07it/s]\n",
      "\n",
      "1969682it [03:36, 11717.06it/s]\n",
      "\n",
      "1970858it [03:36, 11625.55it/s]\n",
      "\n",
      "1972152it [03:37, 11990.96it/s]\n",
      "\n",
      "1973357it [03:37, 11937.24it/s]\n",
      "\n",
      "1974555it [03:37, 11704.85it/s]\n",
      "\n",
      "1975756it [03:37, 11760.11it/s]\n",
      "\n",
      "1977045it [03:37, 12077.71it/s]\n",
      "\n",
      "1978257it [03:37, 11439.89it/s]\n",
      "\n",
      "1979424it [03:37, 10956.92it/s]\n",
      "\n",
      "1980593it [03:37, 11167.00it/s]\n",
      "\n",
      "1981727it [03:37, 11185.16it/s]\n",
      "\n",
      "1982852it [03:38, 11137.96it/s]\n",
      "\n",
      "1984087it [03:38, 11443.94it/s]\n",
      "\n",
      "1985304it [03:38, 11652.49it/s]\n",
      "\n",
      "1986474it [03:38, 11562.94it/s]\n",
      "\n",
      "1987634it [03:38, 11437.09it/s]\n",
      "\n",
      "1988789it [03:38, 11436.66it/s]\n",
      "\n",
      "1989935it [03:38, 11208.60it/s]\n",
      "\n",
      "1991059it [03:38, 10923.64it/s]\n",
      "\n",
      "1992155it [03:38, 10316.95it/s]\n",
      "\n",
      "1993267it [03:38, 10545.41it/s]\n",
      "\n",
      "1994330it [03:39, 10205.31it/s]\n",
      "\n",
      "1995475it [03:39, 10520.27it/s]\n",
      "\n",
      "1996720it [03:39, 11033.31it/s]\n",
      "\n",
      "1998006it [03:39, 11493.50it/s]\n",
      "\n",
      "1999251it [03:39, 11764.65it/s]\n",
      "\n",
      "2000439it [03:39, 7665.19it/s] \n",
      "\n",
      "2001528it [03:39, 8393.10it/s]\n",
      "\n",
      "2002595it [03:39, 8967.15it/s]\n",
      "\n",
      "2003740it [03:40, 9567.04it/s]\n",
      "\n",
      "2004895it [03:40, 10060.19it/s]\n",
      "\n",
      "2005974it [03:40, 9901.07it/s] \n",
      "\n",
      "2007085it [03:40, 10206.99it/s]\n",
      "\n",
      "2008409it [03:40, 10933.06it/s]\n",
      "\n",
      "2009556it [03:40, 11056.72it/s]\n",
      "\n",
      "2010827it [03:40, 11474.55it/s]\n",
      "\n",
      "2012000it [03:40, 10905.70it/s]\n",
      "\n",
      "2013163it [03:40, 11081.58it/s]\n",
      "\n",
      "2014310it [03:41, 11195.31it/s]\n",
      "\n",
      "2015442it [03:41, 11165.95it/s]\n",
      "\n",
      "2016598it [03:41, 11281.31it/s]\n",
      "\n",
      "2017791it [03:41, 11435.41it/s]\n",
      "\n",
      "2018940it [03:41, 11316.39it/s]\n",
      "\n",
      "2020182it [03:41, 11593.76it/s]\n",
      "\n",
      "2021346it [03:41, 11173.06it/s]\n",
      "\n",
      "2022623it [03:41, 11608.57it/s]\n",
      "\n",
      "2023793it [03:41, 11105.70it/s]\n",
      "\n",
      "2024915it [03:41, 10724.47it/s]\n",
      "\n",
      "2026180it [03:42, 11237.63it/s]\n",
      "\n",
      "2027318it [03:42, 10646.78it/s]\n",
      "\n",
      "2028470it [03:42, 10863.71it/s]\n",
      "\n",
      "2029668it [03:42, 11176.12it/s]\n",
      "\n",
      "2030797it [03:42, 9807.73it/s] \n",
      "\n",
      "2031827it [03:42, 9921.65it/s]\n",
      "\n",
      "2032847it [03:42, 9773.50it/s]\n",
      "\n",
      "2034017it [03:42, 10254.34it/s]\n",
      "\n",
      "2035241it [03:42, 10750.52it/s]\n",
      "\n",
      "2036500it [03:43, 11213.30it/s]\n",
      "\n",
      "2037641it [03:43, 11042.51it/s]\n",
      "\n",
      "2038778it [03:43, 11138.76it/s]\n",
      "\n",
      "2039902it [03:43, 10783.20it/s]\n",
      "\n",
      "2041059it [03:43, 10976.44it/s]\n",
      "\n",
      "2042240it [03:43, 11213.88it/s]\n",
      "\n",
      "2043474it [03:43, 11497.31it/s]\n",
      "\n",
      "2044631it [03:43, 11450.61it/s]\n",
      "\n",
      "2045808it [03:43, 11510.73it/s]\n",
      "\n",
      "2046963it [03:43, 11488.10it/s]\n",
      "\n",
      "2048282it [03:44, 11950.70it/s]\n",
      "\n",
      "2049484it [03:44, 11900.29it/s]\n",
      "\n",
      "2050710it [03:44, 12005.96it/s]\n",
      "\n",
      "2051914it [03:44, 11532.74it/s]\n",
      "\n",
      "2053074it [03:44, 10963.23it/s]\n",
      "\n",
      "2054256it [03:44, 11206.92it/s]\n",
      "\n",
      "2055521it [03:44, 11572.21it/s]\n",
      "\n",
      "2056688it [03:44, 9434.76it/s] \n",
      "\n",
      "2057892it [03:44, 10064.43it/s]\n",
      "\n",
      "2058960it [03:45, 9955.13it/s] \n",
      "\n",
      "2060349it [03:45, 10854.26it/s]\n",
      "\n",
      "2061489it [03:45, 10409.10it/s]\n",
      "\n",
      "2062625it [03:45, 10647.21it/s]\n",
      "\n",
      "2063721it [03:45, 10432.48it/s]\n",
      "\n",
      "2064787it [03:45, 10169.17it/s]\n",
      "\n",
      "2065822it [03:45, 10192.55it/s]\n",
      "\n",
      "2066854it [03:45, 9906.38it/s] \n",
      "\n",
      "2068006it [03:45, 10313.15it/s]\n",
      "\n",
      "2069157it [03:46, 10645.22it/s]\n",
      "\n",
      "2070409it [03:46, 11116.25it/s]\n",
      "\n",
      "2071534it [03:46, 10559.18it/s]\n",
      "\n",
      "2072723it [03:46, 10896.03it/s]\n",
      "\n",
      "2073843it [03:46, 10953.25it/s]\n",
      "\n",
      "2075005it [03:46, 11145.09it/s]\n",
      "\n",
      "2076127it [03:46, 11035.66it/s]\n",
      "\n",
      "2077236it [03:46, 10399.01it/s]\n",
      "\n",
      "2078288it [03:46, 10342.68it/s]\n",
      "\n",
      "2079331it [03:47, 9868.39it/s] \n",
      "\n",
      "2080369it [03:47, 9987.59it/s]\n",
      "\n",
      "2081376it [03:47, 9952.80it/s]\n",
      "\n",
      "2082384it [03:47, 9730.23it/s]\n",
      "\n",
      "2083474it [03:47, 10026.18it/s]\n",
      "\n",
      "2084483it [03:47, 9839.52it/s] \n",
      "\n",
      "2085530it [03:47, 9991.86it/s]\n",
      "\n",
      "2086534it [03:47, 9576.74it/s]\n",
      "\n",
      "2087664it [03:47, 10009.22it/s]\n",
      "\n",
      "2088678it [03:47, 10018.32it/s]\n",
      "\n",
      "2089687it [03:48, 9527.78it/s] \n",
      "\n",
      "2090817it [03:48, 9971.73it/s]\n",
      "\n",
      "2091909it [03:48, 10238.45it/s]\n",
      "\n",
      "2092944it [03:48, 10061.96it/s]\n",
      "\n",
      "2094053it [03:48, 10320.89it/s]\n",
      "\n",
      "2095093it [03:48, 10132.84it/s]\n",
      "\n",
      "2096431it [03:48, 10901.80it/s]\n",
      "\n",
      "2097542it [03:48, 10931.07it/s]\n",
      "\n",
      "2098700it [03:48, 11086.06it/s]\n",
      "\n",
      "2099820it [03:48, 11086.96it/s]\n",
      "\n",
      "2100937it [03:49, 10758.57it/s]\n",
      "\n",
      "2102134it [03:49, 11064.67it/s]\n",
      "\n",
      "2103248it [03:49, 10462.39it/s]\n",
      "\n",
      "2104560it [03:49, 11111.02it/s]\n",
      "\n",
      "2105760it [03:49, 11331.38it/s]\n",
      "\n",
      "2106908it [03:49, 10797.78it/s]\n",
      "\n",
      "2108004it [03:49, 10324.85it/s]\n",
      "\n",
      "2109150it [03:49, 10641.06it/s]\n",
      "\n",
      "2110320it [03:49, 10907.47it/s]\n",
      "\n",
      "2111505it [03:50, 11142.58it/s]\n",
      "\n",
      "2112629it [03:50, 11171.62it/s]\n",
      "\n",
      "2113829it [03:50, 11375.43it/s]\n",
      "\n",
      "2115043it [03:50, 11594.49it/s]\n",
      "\n",
      "2116285it [03:50, 11796.68it/s]\n",
      "\n",
      "2117469it [03:50, 11739.39it/s]\n",
      "\n",
      "2118646it [03:50, 11147.68it/s]\n",
      "\n",
      "2119770it [03:50, 10201.51it/s]\n",
      "\n",
      "2120954it [03:50, 10643.38it/s]\n",
      "\n",
      "2122107it [03:51, 10863.92it/s]\n",
      "\n",
      "2123209it [03:51, 10595.57it/s]\n",
      "\n",
      "2124363it [03:51, 10651.71it/s]\n",
      "\n",
      "2125521it [03:51, 10883.41it/s]\n",
      "\n",
      "2126617it [03:51, 10438.84it/s]\n",
      "\n",
      "2127670it [03:51, 9932.90it/s] \n",
      "\n",
      "2128847it [03:51, 10393.25it/s]\n",
      "\n",
      "2129900it [03:51, 10221.21it/s]\n",
      "\n",
      "2131101it [03:51, 10670.77it/s]\n",
      "\n",
      "2132362it [03:51, 11186.88it/s]\n",
      "\n",
      "2133496it [03:52, 10692.25it/s]\n",
      "\n",
      "2134609it [03:52, 10819.91it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2135703it [03:52, 10572.41it/s]\n",
      "\n",
      "2136798it [03:52, 10682.92it/s]\n",
      "\n",
      "2137996it [03:52, 11011.12it/s]\n",
      "\n",
      "2139105it [03:52, 10840.51it/s]\n",
      "\n",
      "2140413it [03:52, 11397.60it/s]\n",
      "\n",
      "2141565it [03:52, 10914.08it/s]\n",
      "\n",
      "2142925it [03:52, 11571.83it/s]\n",
      "\n",
      "2144110it [03:53, 11653.90it/s]\n",
      "\n",
      "2145290it [03:53, 10798.19it/s]\n",
      "\n",
      "2146392it [03:53, 10257.09it/s]\n",
      "\n",
      "2147610it [03:53, 10738.57it/s]\n",
      "\n",
      "2148812it [03:53, 11093.36it/s]\n",
      "\n",
      "2149939it [03:53, 10887.35it/s]\n",
      "\n",
      "2151041it [03:53, 10735.21it/s]\n",
      "\n",
      "2152125it [03:53, 10247.36it/s]\n",
      "\n",
      "2153334it [03:53, 10709.82it/s]\n",
      "\n",
      "2154533it [03:54, 11064.22it/s]\n",
      "\n",
      "2155709it [03:54, 11231.88it/s]\n",
      "\n",
      "2156842it [03:54, 10779.03it/s]\n",
      "\n",
      "2157931it [03:54, 10622.24it/s]\n",
      "\n",
      "2159002it [03:54, 10163.38it/s]\n",
      "\n",
      "2160147it [03:54, 10517.94it/s]\n",
      "\n",
      "2161209it [03:54, 10243.14it/s]\n",
      "\n",
      "2162342it [03:54, 10517.29it/s]\n",
      "\n",
      "2163402it [03:54, 10356.56it/s]\n",
      "\n",
      "2164619it [03:54, 10812.30it/s]\n",
      "\n",
      "2165710it [03:55, 10377.38it/s]\n",
      "\n",
      "2166759it [03:55, 10349.28it/s]\n",
      "\n",
      "2168081it [03:55, 11042.72it/s]\n",
      "\n",
      "2169204it [03:55, 10686.37it/s]\n",
      "\n",
      "2170362it [03:55, 10939.63it/s]\n",
      "\n",
      "2171468it [03:55, 10536.33it/s]\n",
      "\n",
      "2172534it [03:55, 10121.38it/s]\n",
      "\n",
      "2173558it [03:55, 9891.77it/s] \n",
      "\n",
      "2174557it [03:55, 9746.80it/s]\n",
      "\n",
      "2175719it [03:56, 10215.12it/s]\n",
      "\n",
      "2176752it [03:56, 9895.84it/s] \n",
      "\n",
      "2177888it [03:56, 10293.86it/s]\n",
      "\n",
      "2179036it [03:56, 10593.74it/s]\n",
      "\n",
      "2180106it [03:56, 4881.34it/s] \n",
      "\n",
      "2180920it [03:57, 3090.00it/s]\n",
      "\n",
      "2181540it [03:57, 3611.94it/s]\n",
      "\n",
      "2182153it [03:57, 3349.72it/s]\n",
      "\n",
      "2182668it [03:57, 3240.60it/s]\n",
      "\n",
      "2183495it [03:57, 3958.08it/s]\n",
      "\n",
      "2184602it [03:58, 4903.08it/s]\n",
      "\n",
      "2185861it [03:58, 5993.97it/s]\n",
      "\n",
      "2186846it [03:58, 6708.34it/s]\n",
      "\n",
      "2188112it [03:58, 7795.36it/s]\n",
      "\n",
      "2189247it [03:58, 8603.72it/s]\n",
      "\n",
      "2190329it [03:58, 9143.80it/s]\n",
      "\n",
      "2191381it [03:58, 9440.44it/s]\n",
      "\n",
      "2192469it [03:58, 9804.08it/s]\n",
      "\n",
      "2193586it [03:58, 10149.70it/s]\n",
      "\n",
      "2194714it [03:58, 10435.22it/s]\n",
      "\n",
      "2195837it [03:59, 10631.31it/s]\n",
      "\n",
      "2196017it [03:59, 9186.20it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2196016 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# load the GloVe vectors in a dictionary:\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open('E://kaggle_train/dataset/glove.840B.300d.txt','rb')\n",
    "for line in tqdm(f):\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function creates a normalized vector for the whole sentence\n",
    "def sent2vec(s):\n",
    "    words = str(s).lower().encode('utf-8').decode('utf-8')\n",
    "    words = word_tokenize(words)\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    words = [w for w in words if w.isalpha()]\n",
    "    M = []\n",
    "    for w in words:\n",
    "        try:\n",
    "            M.append(embeddings_index[w])\n",
    "        except:\n",
    "            continue\n",
    "    M = np.array(M)\n",
    "    v = M.sum(axis=0)\n",
    "    if type(v) != np.ndarray:\n",
    "        return np.zeros(300)\n",
    "    return v / np.sqrt((v ** 2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\len\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                | 0/17621 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                      | 1/17621 [00:00<1:08:25,  4.29it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                        | 8/17621 [00:00<49:08,  5.97it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                      | 85/17621 [00:00<34:22,  8.50it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|                                     | 283/17621 [00:00<23:49, 12.13it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  3%|                                     | 495/17621 [00:00<16:31, 17.28it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  4%|                                    | 753/17621 [00:00<11:25, 24.62it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  6%|                                   | 996/17621 [00:00<07:54, 35.01it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  7%|                                  | 1199/17621 [00:00<05:30, 49.63it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  8%|                                  | 1440/17621 [00:01<03:50, 70.29it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 10%|                                 | 1693/17621 [00:01<02:40, 99.22it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 11%|                                | 1947/17621 [00:01<01:52, 139.38it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 13%|                               | 2214/17621 [00:01<01:19, 194.76it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 14%|                               | 2454/17621 [00:01<00:56, 268.69it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 15%|                              | 2702/17621 [00:01<00:40, 366.82it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 17%|                              | 2944/17621 [00:01<00:30, 489.08it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 18%|                             | 3217/17621 [00:01<00:22, 648.40it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 20%|                             | 3463/17621 [00:01<00:17, 831.43it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 21%|                           | 3730/17621 [00:01<00:13, 1046.67it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 23%|                           | 4002/17621 [00:02<00:10, 1281.75it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 24%|                          | 4275/17621 [00:02<00:08, 1524.35it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 26%|                          | 4537/17621 [00:02<00:07, 1736.09it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 27%|                         | 4837/17621 [00:02<00:06, 1987.26it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 29%|                        | 5141/17621 [00:02<00:05, 2212.81it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 31%|                        | 5426/17621 [00:02<00:05, 2371.90it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 33%|                       | 5735/17621 [00:02<00:04, 2543.36it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 34%|                       | 6041/17621 [00:02<00:04, 2672.04it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 36%|                      | 6339/17621 [00:02<00:04, 2749.90it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 38%|                     | 6697/17621 [00:02<00:03, 2948.18it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 40%|                     | 7010/17621 [00:03<00:03, 2991.87it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 42%|                    | 7322/17621 [00:03<00:03, 2910.50it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 43%|                   | 7623/17621 [00:03<00:03, 2914.04it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 45%|                   | 7921/17621 [00:03<00:03, 2762.22it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 47%|                  | 8204/17621 [00:03<00:03, 2749.77it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 48%|                  | 8493/17621 [00:03<00:03, 2782.33it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 50%|                 | 8782/17621 [00:03<00:03, 2813.78it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 52%|                 | 9087/17621 [00:03<00:02, 2872.57it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 53%|                | 9377/17621 [00:03<00:02, 2863.68it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 55%|               | 9671/17621 [00:04<00:02, 2877.68it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 57%|               | 9976/17621 [00:04<00:02, 2918.89it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 58%|              | 10269/17621 [00:04<00:02, 2896.22it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 60%|             | 10560/17621 [00:04<00:02, 2840.88it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 62%|             | 10845/17621 [00:04<00:02, 2826.69it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 63%|            | 11129/17621 [00:04<00:02, 2648.52it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 65%|            | 11397/17621 [00:04<00:02, 2650.00it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 67%|           | 11728/17621 [00:04<00:02, 2818.61it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 68%|          | 12039/17621 [00:04<00:01, 2892.04it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 70%|          | 12345/17621 [00:04<00:01, 2940.46it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 72%|         | 12642/17621 [00:05<00:01, 2897.47it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 74%|         | 12989/17621 [00:05<00:01, 3048.36it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 75%|        | 13298/17621 [00:05<00:01, 2889.03it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 77%|       | 13592/17621 [00:05<00:01, 2820.55it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 79%|       | 13878/17621 [00:05<00:01, 2782.67it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 80%|      | 14159/17621 [00:05<00:01, 2766.09it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 82%|      | 14460/17621 [00:05<00:01, 2827.02it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 84%|     | 14763/17621 [00:05<00:00, 2876.78it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 86%|     | 15077/17621 [00:05<00:00, 2950.99it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 87%|    | 15378/17621 [00:06<00:00, 2899.82it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 89%|   | 15670/17621 [00:06<00:00, 2821.60it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 91%|   | 15954/17621 [00:06<00:00, 2698.17it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 92%|  | 16233/17621 [00:06<00:00, 2717.12it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 94%|  | 16515/17621 [00:06<00:00, 2747.19it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 95%| | 16793/17621 [00:06<00:00, 2748.77it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 97%| | 17069/17621 [00:06<00:00, 2656.76it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 98%|| 17336/17621 [00:06<00:00, 2652.79it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|| 17621/17621 [00:06<00:00, 2573.16it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                 | 0/1958 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 15%|                               | 303/1958 [00:00<00:00, 3030.00it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 30%|                         | 590/1958 [00:00<00:00, 2970.90it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 45%|                    | 880/1958 [00:00<00:00, 2949.27it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 59%|              | 1164/1958 [00:00<00:00, 2906.66it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 74%|         | 1446/1958 [00:00<00:00, 2871.31it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 92%|   | 1795/1958 [00:00<00:00, 3032.59it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|| 1958/1958 [00:00<00:00, 2957.70it/s]"
     ]
    }
   ],
   "source": [
    "# create sentence vectors using the above function for training and validation set\n",
    "nltk.download('punkt')\n",
    "\n",
    "xtrain_glove = [sent2vec(x) for x in tqdm(xtrain)]\n",
    "xvalid_glove = [sent2vec(x) for x in tqdm(xvalid)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_glove = np.array(xtrain_glove)\n",
    "xvalid_glove = np.array(xvalid_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 1.088 \n"
     ]
    }
   ],
   "source": [
    "# Fitting a simple xgboost on glove features\n",
    "clf = xgb.XGBClassifier(nthread=10, silent=False)\n",
    "clf.fit(xtrain_glove, ytrain)\n",
    "predictions = clf.predict_proba(xvalid_glove)\n",
    "\n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 1.088 \n"
     ]
    }
   ],
   "source": [
    "# Fitting a simple xgboost on glove features\n",
    "clf = xgb.XGBClassifier(max_depth=7, n_estimators=200, colsample_bytree=0.8, \n",
    "                        subsample=0.8, nthread=10, learning_rate=0.1, silent=False)\n",
    "clf.fit(xtrain_glove, ytrain)\n",
    "predictions = clf.predict_proba(xvalid_glove)\n",
    "\n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the data before any neural net:\n",
    "scl = preprocessing.StandardScaler()\n",
    "xtrain_glove_scl = scl.fit_transform(xtrain_glove)\n",
    "xvalid_glove_scl = scl.transform(xvalid_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to binarize the labels for the neural net\n",
    "ytrain_enc = np_utils.to_categorical(ytrain)\n",
    "yvalid_enc = np_utils.to_categorical(yvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Software\\Anaconda\\envs\\py3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From D:\\Software\\Anaconda\\envs\\py3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# create a simple 3 layer sequential neural net\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(300, input_dim=300, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(300, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Software\\Anaconda\\envs\\py3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 17621 samples, validate on 1958 samples\n",
      "Epoch 1/5\n",
      "17621/17621 [==============================] - ETA: 17:22 - loss: 1.09 - ETA: 8:47 - loss: 1.0982 - ETA: 5:56 - loss: 1.097 - ETA: 2:34 - loss: 1.094 - ETA: 1:38 - loss: 1.094 - ETA: 59s - loss: 1.090 - ETA: 40s - loss: 1.09 - ETA: 29s - loss: 1.09 - ETA: 23s - loss: 1.09 - ETA: 19s - loss: 1.09 - ETA: 18s - loss: 1.09 - ETA: 15s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.09 - ETA: 9s - loss: 1.0901 - ETA: 9s - loss: 1.089 - ETA: 8s - loss: 1.089 - ETA: 7s - loss: 1.088 - ETA: 6s - loss: 1.088 - ETA: 6s - loss: 1.088 - ETA: 6s - loss: 1.088 - ETA: 5s - loss: 1.089 - ETA: 5s - loss: 1.090 - ETA: 4s - loss: 1.090 - ETA: 4s - loss: 1.090 - ETA: 4s - loss: 1.090 - ETA: 4s - loss: 1.090 - ETA: 3s - loss: 1.090 - ETA: 3s - loss: 1.089 - ETA: 3s - loss: 1.090 - ETA: 2s - loss: 1.089 - ETA: 2s - loss: 1.089 - ETA: 2s - loss: 1.089 - ETA: 2s - loss: 1.089 - ETA: 1s - loss: 1.089 - ETA: 1s - loss: 1.089 - ETA: 1s - loss: 1.089 - ETA: 1s - loss: 1.089 - ETA: 1s - loss: 1.089 - ETA: 1s - loss: 1.088 - ETA: 1s - loss: 1.089 - ETA: 0s - loss: 1.088 - ETA: 0s - loss: 1.089 - ETA: 0s - loss: 1.089 - ETA: 0s - loss: 1.089 - ETA: 0s - loss: 1.089 - ETA: 0s - loss: 1.088 - ETA: 0s - loss: 1.088 - ETA: 0s - loss: 1.088 - 7s 411us/step - loss: 1.0887 - val_loss: 1.0877\n",
      "Epoch 2/5\n",
      "17621/17621 [==============================] - ETA: 7s - loss: 1.131 - ETA: 8s - loss: 1.107 - ETA: 4s - loss: 1.096 - ETA: 3s - loss: 1.093 - ETA: 3s - loss: 1.094 - ETA: 2s - loss: 1.091 - ETA: 2s - loss: 1.092 - ETA: 2s - loss: 1.091 - ETA: 2s - loss: 1.090 - ETA: 1s - loss: 1.090 - ETA: 2s - loss: 1.090 - ETA: 1s - loss: 1.090 - ETA: 2s - loss: 1.090 - ETA: 2s - loss: 1.089 - ETA: 2s - loss: 1.090 - ETA: 2s - loss: 1.089 - ETA: 2s - loss: 1.088 - ETA: 1s - loss: 1.088 - ETA: 1s - loss: 1.088 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.088 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.088 - ETA: 1s - loss: 1.088 - ETA: 1s - loss: 1.088 - ETA: 1s - loss: 1.088 - ETA: 1s - loss: 1.088 - ETA: 1s - loss: 1.088 - ETA: 1s - loss: 1.088 - ETA: 1s - loss: 1.088 - ETA: 1s - loss: 1.088 - ETA: 1s - loss: 1.088 - ETA: 0s - loss: 1.088 - ETA: 0s - loss: 1.089 - ETA: 0s - loss: 1.089 - ETA: 0s - loss: 1.088 - ETA: 0s - loss: 1.088 - ETA: 0s - loss: 1.088 - ETA: 0s - loss: 1.088 - ETA: 0s - loss: 1.088 - ETA: 0s - loss: 1.088 - ETA: 0s - loss: 1.088 - ETA: 0s - loss: 1.088 - ETA: 0s - loss: 1.088 - ETA: 0s - loss: 1.088 - ETA: 0s - loss: 1.088 - ETA: 0s - loss: 1.088 - ETA: 0s - loss: 1.088 - ETA: 0s - loss: 1.088 - ETA: 0s - loss: 1.088 - 3s 187us/step - loss: 1.0882 - val_loss: 1.0877\n",
      "Epoch 3/5\n",
      "17621/17621 [==============================] - ETA: 12s - loss: 1.06 - ETA: 8s - loss: 1.0590 - ETA: 5s - loss: 1.074 - ETA: 4s - loss: 1.079 - ETA: 4s - loss: 1.079 - ETA: 4s - loss: 1.081 - ETA: 5s - loss: 1.081 - ETA: 5s - loss: 1.084 - ETA: 4s - loss: 1.083 - ETA: 4s - loss: 1.083 - ETA: 4s - loss: 1.082 - ETA: 3s - loss: 1.081 - ETA: 3s - loss: 1.082 - ETA: 3s - loss: 1.084 - ETA: 3s - loss: 1.086 - ETA: 3s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.088 - ETA: 2s - loss: 1.088 - ETA: 2s - loss: 1.088 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.088 - ETA: 2s - loss: 1.088 - ETA: 1s - loss: 1.088 - ETA: 1s - loss: 1.089 - ETA: 1s - loss: 1.089 - ETA: 1s - loss: 1.089 - ETA: 1s - loss: 1.089 - ETA: 1s - loss: 1.089 - ETA: 1s - loss: 1.089 - ETA: 1s - loss: 1.089 - ETA: 1s - loss: 1.089 - ETA: 1s - loss: 1.089 - ETA: 1s - loss: 1.089 - ETA: 1s - loss: 1.089 - ETA: 1s - loss: 1.088 - ETA: 1s - loss: 1.088 - ETA: 0s - loss: 1.088 - ETA: 0s - loss: 1.088 - ETA: 0s - loss: 1.088 - ETA: 0s - loss: 1.088 - ETA: 0s - loss: 1.088 - ETA: 0s - loss: 1.088 - ETA: 0s - loss: 1.088 - ETA: 0s - loss: 1.088 - ETA: 0s - loss: 1.088 - ETA: 0s - loss: 1.088 - ETA: 0s - loss: 1.088 - ETA: 0s - loss: 1.088 - ETA: 0s - loss: 1.088 - ETA: 0s - loss: 1.088 - ETA: 0s - loss: 1.088 - ETA: 0s - loss: 1.088 - 3s 199us/step - loss: 1.0880 - val_loss: 1.0876\n",
      "Epoch 4/5\n",
      "17621/17621 [==============================] - ETA: 12s - loss: 1.10 - ETA: 8s - loss: 1.1029 - ETA: 8s - loss: 1.093 - ETA: 8s - loss: 1.091 - ETA: 8s - loss: 1.090 - ETA: 6s - loss: 1.090 - ETA: 5s - loss: 1.093 - ETA: 4s - loss: 1.092 - ETA: 4s - loss: 1.093 - ETA: 3s - loss: 1.093 - ETA: 3s - loss: 1.093 - ETA: 3s - loss: 1.093 - ETA: 3s - loss: 1.093 - ETA: 3s - loss: 1.092 - ETA: 4s - loss: 1.092 - ETA: 4s - loss: 1.092 - ETA: 4s - loss: 1.092 - ETA: 4s - loss: 1.091 - ETA: 3s - loss: 1.090 - ETA: 3s - loss: 1.090 - ETA: 3s - loss: 1.090 - ETA: 3s - loss: 1.089 - ETA: 3s - loss: 1.089 - ETA: 2s - loss: 1.088 - ETA: 2s - loss: 1.088 - ETA: 2s - loss: 1.088 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.086 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.086 - ETA: 2s - loss: 1.086 - ETA: 2s - loss: 1.086 - ETA: 2s - loss: 1.086 - ETA: 1s - loss: 1.086 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.088 - 4s 203us/step - loss: 1.0879 - val_loss: 1.0876\n",
      "Epoch 5/5\n",
      "17621/17621 [==============================] - ETA: 9s - loss: 1.097 - ETA: 8s - loss: 1.094 - ETA: 4s - loss: 1.093 - ETA: 5s - loss: 1.094 - ETA: 6s - loss: 1.091 - ETA: 5s - loss: 1.093 - ETA: 4s - loss: 1.093 - ETA: 4s - loss: 1.091 - ETA: 3s - loss: 1.090 - ETA: 3s - loss: 1.091 - ETA: 3s - loss: 1.090 - ETA: 4s - loss: 1.090 - ETA: 4s - loss: 1.089 - ETA: 4s - loss: 1.089 - ETA: 4s - loss: 1.088 - ETA: 4s - loss: 1.090 - ETA: 4s - loss: 1.090 - ETA: 3s - loss: 1.090 - ETA: 3s - loss: 1.089 - ETA: 4s - loss: 1.089 - ETA: 4s - loss: 1.089 - ETA: 4s - loss: 1.089 - ETA: 4s - loss: 1.089 - ETA: 4s - loss: 1.088 - ETA: 4s - loss: 1.088 - ETA: 4s - loss: 1.088 - ETA: 3s - loss: 1.089 - ETA: 3s - loss: 1.089 - ETA: 3s - loss: 1.088 - ETA: 3s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.088 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.088 - ETA: 2s - loss: 1.088 - ETA: 2s - loss: 1.089 - ETA: 2s - loss: 1.088 - ETA: 2s - loss: 1.088 - ETA: 2s - loss: 1.088 - ETA: 2s - loss: 1.088 - ETA: 1s - loss: 1.088 - ETA: 1s - loss: 1.088 - ETA: 1s - loss: 1.088 - ETA: 1s - loss: 1.088 - ETA: 1s - loss: 1.088 - ETA: 1s - loss: 1.088 - ETA: 1s - loss: 1.088 - ETA: 1s - loss: 1.088 - ETA: 1s - loss: 1.088 - ETA: 1s - loss: 1.088 - ETA: 1s - loss: 1.088 - ETA: 1s - loss: 1.088 - ETA: 1s - loss: 1.088 - ETA: 1s - loss: 1.088 - ETA: 1s - loss: 1.088 - ETA: 1s - loss: 1.088 - ETA: 0s - loss: 1.088 - ETA: 0s - loss: 1.088 - ETA: 0s - loss: 1.088 - ETA: 0s - loss: 1.089 - ETA: 0s - loss: 1.088 - ETA: 0s - loss: 1.088 - ETA: 0s - loss: 1.088 - ETA: 0s - loss: 1.088 - ETA: 0s - loss: 1.088 - ETA: 0s - loss: 1.088 - ETA: 0s - loss: 1.088 - ETA: 0s - loss: 1.088 - ETA: 0s - loss: 1.088 - 4s 255us/step - loss: 1.0880 - val_loss: 1.0884\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16e17748>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xtrain_glove_scl, y=ytrain_enc, batch_size=64, \n",
    "          epochs=5, verbose=1, \n",
    "          validation_data=(xvalid_glove_scl, yvalid_enc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using keras tokenizer here\n",
    "token = text.Tokenizer(num_words=None)\n",
    "max_len = 70\n",
    "\n",
    "token.fit_on_texts(list(xtrain) + list(xvalid))\n",
    "xtrain_seq = token.texts_to_sequences(xtrain)\n",
    "xvalid_seq = token.texts_to_sequences(xvalid)\n",
    "\n",
    "# zero pad the sequences\n",
    "xtrain_pad = sequence.pad_sequences(xtrain_seq, maxlen=max_len)\n",
    "xvalid_pad = sequence.pad_sequences(xvalid_seq, maxlen=max_len)\n",
    "\n",
    "word_index = token.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                | 0/25943 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                    | 118/25943 [00:00<00:31, 825.17it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 47%|                  | 12136/25943 [00:00<00:11, 1175.29it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 79%|       | 20399/25943 [00:00<00:03, 1668.41it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|| 25943/25943 [00:00<00:00, 60899.08it/s]"
     ]
    }
   ],
   "source": [
    "# create an embedding matrix for the words we have in the dataset\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
    "for word, i in tqdm(word_index.items()):\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple LSTM with glove embeddings and two dense layers\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(word_index) + 1,\n",
    "                     300,\n",
    "                     weights=[embedding_matrix],\n",
    "                     input_length=max_len,\n",
    "                     trainable=False))\n",
    "model.add(SpatialDropout1D(0.3))\n",
    "model.add(LSTM(100, dropout=0.3, recurrent_dropout=0.3))\n",
    "\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.8))\n",
    "\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.8))\n",
    "\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17621 samples, validate on 1958 samples\n",
      "Epoch 1/100\n",
      "17621/17621 [==============================] - ETA: 3:05 - loss: 1.098 - ETA: 1:42 - loss: 1.098 - ETA: 1:13 - loss: 1.098 - ETA: 57s - loss: 1.098 - ETA: 47s - loss: 1.09 - ETA: 40s - loss: 1.09 - ETA: 36s - loss: 1.09 - ETA: 31s - loss: 1.09 - ETA: 28s - loss: 1.09 - ETA: 25s - loss: 1.09 - ETA: 23s - loss: 1.09 - ETA: 21s - loss: 1.09 - ETA: 20s - loss: 1.09 - ETA: 18s - loss: 1.09 - ETA: 17s - loss: 1.09 - ETA: 15s - loss: 1.09 - ETA: 14s - loss: 1.09 - ETA: 13s - loss: 1.09 - ETA: 12s - loss: 1.09 - ETA: 11s - loss: 1.09 - ETA: 10s - loss: 1.09 - ETA: 9s - loss: 1.0974 - ETA: 8s - loss: 1.097 - ETA: 7s - loss: 1.097 - ETA: 6s - loss: 1.097 - ETA: 6s - loss: 1.097 - ETA: 5s - loss: 1.097 - ETA: 4s - loss: 1.097 - ETA: 3s - loss: 1.097 - ETA: 3s - loss: 1.096 - ETA: 2s - loss: 1.096 - ETA: 1s - loss: 1.096 - ETA: 0s - loss: 1.096 - ETA: 0s - loss: 1.096 - 24s 1ms/step - loss: 1.0967 - val_loss: 1.0947\n",
      "Epoch 2/100\n",
      "17621/17621 [==============================] - ETA: 15s - loss: 1.09 - ETA: 16s - loss: 1.09 - ETA: 15s - loss: 1.09 - ETA: 15s - loss: 1.09 - ETA: 14s - loss: 1.09 - ETA: 14s - loss: 1.09 - ETA: 13s - loss: 1.09 - ETA: 13s - loss: 1.09 - ETA: 12s - loss: 1.09 - ETA: 12s - loss: 1.09 - ETA: 11s - loss: 1.09 - ETA: 11s - loss: 1.09 - ETA: 10s - loss: 1.09 - ETA: 10s - loss: 1.09 - ETA: 9s - loss: 1.0937 - ETA: 9s - loss: 1.093 - ETA: 8s - loss: 1.093 - ETA: 8s - loss: 1.093 - ETA: 7s - loss: 1.093 - ETA: 7s - loss: 1.093 - ETA: 6s - loss: 1.093 - ETA: 6s - loss: 1.093 - ETA: 5s - loss: 1.093 - ETA: 5s - loss: 1.093 - ETA: 4s - loss: 1.093 - ETA: 4s - loss: 1.093 - ETA: 3s - loss: 1.093 - ETA: 3s - loss: 1.093 - ETA: 2s - loss: 1.093 - ETA: 2s - loss: 1.093 - ETA: 1s - loss: 1.093 - ETA: 1s - loss: 1.093 - ETA: 0s - loss: 1.093 - ETA: 0s - loss: 1.093 - 19s 1ms/step - loss: 1.0933 - val_loss: 1.0920\n",
      "Epoch 3/100\n",
      "17621/17621 [==============================] - ETA: 20s - loss: 1.09 - ETA: 17s - loss: 1.09 - ETA: 18s - loss: 1.09 - ETA: 17s - loss: 1.09 - ETA: 16s - loss: 1.09 - ETA: 17s - loss: 1.09 - ETA: 17s - loss: 1.09 - ETA: 16s - loss: 1.09 - ETA: 15s - loss: 1.09 - ETA: 15s - loss: 1.09 - ETA: 14s - loss: 1.09 - ETA: 13s - loss: 1.09 - ETA: 13s - loss: 1.09 - ETA: 12s - loss: 1.09 - ETA: 11s - loss: 1.09 - ETA: 11s - loss: 1.09 - ETA: 10s - loss: 1.09 - ETA: 9s - loss: 1.0913 - ETA: 9s - loss: 1.091 - ETA: 8s - loss: 1.091 - ETA: 7s - loss: 1.091 - ETA: 7s - loss: 1.091 - ETA: 6s - loss: 1.091 - ETA: 5s - loss: 1.091 - ETA: 5s - loss: 1.091 - ETA: 4s - loss: 1.091 - ETA: 4s - loss: 1.091 - ETA: 3s - loss: 1.091 - ETA: 3s - loss: 1.091 - ETA: 2s - loss: 1.091 - ETA: 1s - loss: 1.090 - ETA: 1s - loss: 1.090 - ETA: 0s - loss: 1.090 - ETA: 0s - loss: 1.091 - 20s 1ms/step - loss: 1.0910 - val_loss: 1.0901\n",
      "Epoch 4/100\n",
      "17621/17621 [==============================] - ETA: 14s - loss: 1.09 - ETA: 15s - loss: 1.08 - ETA: 14s - loss: 1.09 - ETA: 14s - loss: 1.09 - ETA: 14s - loss: 1.09 - ETA: 13s - loss: 1.09 - ETA: 13s - loss: 1.09 - ETA: 12s - loss: 1.09 - ETA: 12s - loss: 1.09 - ETA: 11s - loss: 1.09 - ETA: 11s - loss: 1.09 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.09 - ETA: 10s - loss: 1.09 - ETA: 9s - loss: 1.0899 - ETA: 9s - loss: 1.089 - ETA: 8s - loss: 1.090 - ETA: 8s - loss: 1.089 - ETA: 7s - loss: 1.089 - ETA: 7s - loss: 1.089 - ETA: 6s - loss: 1.090 - ETA: 6s - loss: 1.090 - ETA: 5s - loss: 1.089 - ETA: 5s - loss: 1.089 - ETA: 4s - loss: 1.089 - ETA: 4s - loss: 1.089 - ETA: 3s - loss: 1.089 - ETA: 3s - loss: 1.089 - ETA: 2s - loss: 1.089 - ETA: 2s - loss: 1.089 - ETA: 1s - loss: 1.089 - ETA: 1s - loss: 1.089 - ETA: 0s - loss: 1.089 - ETA: 0s - loss: 1.089 - 18s 1ms/step - loss: 1.0895 - val_loss: 1.0889\n",
      "Epoch 5/100\n",
      "17621/17621 [==============================] - ETA: 15s - loss: 1.08 - ETA: 16s - loss: 1.08 - ETA: 15s - loss: 1.08 - ETA: 15s - loss: 1.08 - ETA: 15s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0881 - ETA: 9s - loss: 1.087 - ETA: 8s - loss: 1.087 - ETA: 8s - loss: 1.087 - ETA: 7s - loss: 1.087 - ETA: 7s - loss: 1.088 - ETA: 6s - loss: 1.088 - ETA: 6s - loss: 1.088 - ETA: 5s - loss: 1.088 - ETA: 5s - loss: 1.088 - ETA: 4s - loss: 1.088 - ETA: 4s - loss: 1.088 - ETA: 3s - loss: 1.088 - ETA: 3s - loss: 1.088 - ETA: 2s - loss: 1.088 - ETA: 2s - loss: 1.088 - ETA: 1s - loss: 1.088 - ETA: 1s - loss: 1.088 - ETA: 0s - loss: 1.088 - ETA: 0s - loss: 1.088 - 19s 1ms/step - loss: 1.0886 - val_loss: 1.0883\n",
      "Epoch 6/100\n",
      "17621/17621 [==============================] - ETA: 21s - loss: 1.09 - ETA: 17s - loss: 1.09 - ETA: 17s - loss: 1.09 - ETA: 16s - loss: 1.09 - ETA: 15s - loss: 1.09 - ETA: 14s - loss: 1.09 - ETA: 14s - loss: 1.09 - ETA: 13s - loss: 1.09 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0893 - ETA: 9s - loss: 1.089 - ETA: 8s - loss: 1.089 - ETA: 8s - loss: 1.089 - ETA: 7s - loss: 1.089 - ETA: 7s - loss: 1.089 - ETA: 6s - loss: 1.089 - ETA: 5s - loss: 1.089 - ETA: 5s - loss: 1.089 - ETA: 4s - loss: 1.088 - ETA: 4s - loss: 1.088 - ETA: 3s - loss: 1.089 - ETA: 3s - loss: 1.088 - ETA: 2s - loss: 1.088 - ETA: 2s - loss: 1.088 - ETA: 1s - loss: 1.088 - ETA: 1s - loss: 1.088 - ETA: 0s - loss: 1.088 - ETA: 0s - loss: 1.088 - 18s 1ms/step - loss: 1.0881 - val_loss: 1.0879\n",
      "Epoch 7/100\n",
      "17621/17621 [==============================] - ETA: 13s - loss: 1.09 - ETA: 15s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0871 - ETA: 9s - loss: 1.087 - ETA: 8s - loss: 1.087 - ETA: 8s - loss: 1.086 - ETA: 7s - loss: 1.086 - ETA: 7s - loss: 1.086 - ETA: 6s - loss: 1.086 - ETA: 6s - loss: 1.086 - ETA: 5s - loss: 1.086 - ETA: 4s - loss: 1.086 - ETA: 4s - loss: 1.086 - ETA: 3s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 19s 1ms/step - loss: 1.0878 - val_loss: 1.0877\n",
      "Epoch 8/100\n",
      "17621/17621 [==============================] - ETA: 18s - loss: 1.07 - ETA: 16s - loss: 1.08 - ETA: 16s - loss: 1.08 - ETA: 15s - loss: 1.08 - ETA: 15s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0865 - ETA: 9s - loss: 1.086 - ETA: 8s - loss: 1.086 - ETA: 8s - loss: 1.086 - ETA: 7s - loss: 1.086 - ETA: 6s - loss: 1.087 - ETA: 6s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 2s - loss: 1.088 - ETA: 2s - loss: 1.088 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 19s 1ms/step - loss: 1.0876 - val_loss: 1.0876\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17621/17621 [==============================] - ETA: 20s - loss: 1.08 - ETA: 16s - loss: 1.08 - ETA: 16s - loss: 1.08 - ETA: 15s - loss: 1.08 - ETA: 16s - loss: 1.08 - ETA: 15s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 15s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0861 - ETA: 8s - loss: 1.086 - ETA: 8s - loss: 1.086 - ETA: 7s - loss: 1.086 - ETA: 6s - loss: 1.086 - ETA: 6s - loss: 1.086 - ETA: 5s - loss: 1.086 - ETA: 5s - loss: 1.086 - ETA: 4s - loss: 1.086 - ETA: 3s - loss: 1.086 - ETA: 3s - loss: 1.086 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 21s 1ms/step - loss: 1.0876 - val_loss: 1.0876\n",
      "Epoch 10/100\n",
      "17621/17621 [==============================] - ETA: 17s - loss: 1.08 - ETA: 16s - loss: 1.08 - ETA: 15s - loss: 1.08 - ETA: 15s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 14s - loss: 1.09 - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0865 - ETA: 9s - loss: 1.086 - ETA: 8s - loss: 1.086 - ETA: 8s - loss: 1.086 - ETA: 7s - loss: 1.086 - ETA: 7s - loss: 1.086 - ETA: 6s - loss: 1.086 - ETA: 6s - loss: 1.086 - ETA: 5s - loss: 1.086 - ETA: 5s - loss: 1.086 - ETA: 4s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 3s - loss: 1.088 - ETA: 3s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.088 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 19s 1ms/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 11/100\n",
      "17621/17621 [==============================] - ETA: 14s - loss: 1.09 - ETA: 16s - loss: 1.09 - ETA: 15s - loss: 1.09 - ETA: 15s - loss: 1.09 - ETA: 15s - loss: 1.08 - ETA: 14s - loss: 1.09 - ETA: 13s - loss: 1.09 - ETA: 13s - loss: 1.09 - ETA: 12s - loss: 1.09 - ETA: 12s - loss: 1.09 - ETA: 11s - loss: 1.09 - ETA: 11s - loss: 1.09 - ETA: 11s - loss: 1.09 - ETA: 10s - loss: 1.09 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0897 - ETA: 8s - loss: 1.089 - ETA: 8s - loss: 1.089 - ETA: 7s - loss: 1.089 - ETA: 7s - loss: 1.089 - ETA: 6s - loss: 1.088 - ETA: 6s - loss: 1.088 - ETA: 5s - loss: 1.088 - ETA: 5s - loss: 1.088 - ETA: 4s - loss: 1.088 - ETA: 4s - loss: 1.088 - ETA: 3s - loss: 1.088 - ETA: 3s - loss: 1.088 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 19s 1ms/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 12/100\n",
      "17621/17621 [==============================] - ETA: 16s - loss: 1.08 - ETA: 17s - loss: 1.08 - ETA: 15s - loss: 1.09 - ETA: 15s - loss: 1.09 - ETA: 14s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0894 - ETA: 9s - loss: 1.089 - ETA: 8s - loss: 1.088 - ETA: 8s - loss: 1.088 - ETA: 7s - loss: 1.088 - ETA: 7s - loss: 1.088 - ETA: 6s - loss: 1.088 - ETA: 6s - loss: 1.088 - ETA: 5s - loss: 1.088 - ETA: 5s - loss: 1.088 - ETA: 4s - loss: 1.088 - ETA: 4s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 20s 1ms/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 13/100\n",
      "17621/17621 [==============================] - ETA: 20s - loss: 1.08 - ETA: 18s - loss: 1.08 - ETA: 17s - loss: 1.08 - ETA: 16s - loss: 1.08 - ETA: 16s - loss: 1.08 - ETA: 15s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 15s - loss: 1.08 - ETA: 16s - loss: 1.08 - ETA: 16s - loss: 1.08 - ETA: 15s - loss: 1.08 - ETA: 15s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0857 - ETA: 8s - loss: 1.085 - ETA: 7s - loss: 1.086 - ETA: 7s - loss: 1.086 - ETA: 6s - loss: 1.086 - ETA: 5s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 21s 1ms/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 14/100\n",
      "17621/17621 [==============================] - ETA: 18s - loss: 1.09 - ETA: 15s - loss: 1.08 - ETA: 16s - loss: 1.08 - ETA: 15s - loss: 1.08 - ETA: 15s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0881 - ETA: 9s - loss: 1.087 - ETA: 8s - loss: 1.088 - ETA: 8s - loss: 1.088 - ETA: 7s - loss: 1.089 - ETA: 7s - loss: 1.089 - ETA: 6s - loss: 1.088 - ETA: 6s - loss: 1.088 - ETA: 5s - loss: 1.088 - ETA: 5s - loss: 1.088 - ETA: 4s - loss: 1.088 - ETA: 4s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.088 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 18s 1ms/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 15/100\n",
      "17621/17621 [==============================] - ETA: 19s - loss: 1.09 - ETA: 16s - loss: 1.09 - ETA: 17s - loss: 1.08 - ETA: 15s - loss: 1.08 - ETA: 15s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0893 - ETA: 9s - loss: 1.089 - ETA: 8s - loss: 1.089 - ETA: 8s - loss: 1.089 - ETA: 7s - loss: 1.089 - ETA: 6s - loss: 1.088 - ETA: 6s - loss: 1.088 - ETA: 5s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 18s 1ms/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 16/100\n",
      "17621/17621 [==============================] - ETA: 19s - loss: 1.08 - ETA: 16s - loss: 1.08 - ETA: 16s - loss: 1.08 - ETA: 15s - loss: 1.08 - ETA: 15s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0880 - ETA: 9s - loss: 1.088 - ETA: 8s - loss: 1.088 - ETA: 8s - loss: 1.087 - ETA: 7s - loss: 1.087 - ETA: 7s - loss: 1.087 - ETA: 6s - loss: 1.087 - ETA: 6s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 18s 1ms/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17621/17621 [==============================] - ETA: 19s - loss: 1.08 - ETA: 16s - loss: 1.08 - ETA: 16s - loss: 1.08 - ETA: 15s - loss: 1.09 - ETA: 15s - loss: 1.09 - ETA: 14s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0896 - ETA: 9s - loss: 1.089 - ETA: 8s - loss: 1.089 - ETA: 8s - loss: 1.089 - ETA: 7s - loss: 1.088 - ETA: 7s - loss: 1.088 - ETA: 6s - loss: 1.088 - ETA: 6s - loss: 1.087 - ETA: 5s - loss: 1.088 - ETA: 5s - loss: 1.088 - ETA: 4s - loss: 1.088 - ETA: 4s - loss: 1.088 - ETA: 3s - loss: 1.088 - ETA: 3s - loss: 1.088 - ETA: 2s - loss: 1.088 - ETA: 2s - loss: 1.088 - ETA: 1s - loss: 1.088 - ETA: 0s - loss: 1.088 - ETA: 0s - loss: 1.087 - 21s 1ms/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 18/100\n",
      "17621/17621 [==============================] - ETA: 21s - loss: 1.09 - ETA: 27s - loss: 1.09 - ETA: 26s - loss: 1.08 - ETA: 24s - loss: 1.08 - ETA: 21s - loss: 1.08 - ETA: 21s - loss: 1.09 - ETA: 19s - loss: 1.08 - ETA: 19s - loss: 1.09 - ETA: 18s - loss: 1.08 - ETA: 16s - loss: 1.08 - ETA: 15s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0886 - ETA: 9s - loss: 1.088 - ETA: 8s - loss: 1.088 - ETA: 7s - loss: 1.087 - ETA: 7s - loss: 1.088 - ETA: 6s - loss: 1.088 - ETA: 6s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 25s 1ms/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 19/100\n",
      "17621/17621 [==============================] - ETA: 38s - loss: 1.08 - ETA: 28s - loss: 1.08 - ETA: 26s - loss: 1.08 - ETA: 22s - loss: 1.08 - ETA: 21s - loss: 1.08 - ETA: 19s - loss: 1.08 - ETA: 19s - loss: 1.08 - ETA: 18s - loss: 1.08 - ETA: 17s - loss: 1.08 - ETA: 15s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0877 - ETA: 8s - loss: 1.087 - ETA: 7s - loss: 1.087 - ETA: 7s - loss: 1.087 - ETA: 6s - loss: 1.088 - ETA: 6s - loss: 1.088 - ETA: 5s - loss: 1.088 - ETA: 4s - loss: 1.088 - ETA: 4s - loss: 1.088 - ETA: 3s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 2s - loss: 1.088 - ETA: 1s - loss: 1.088 - ETA: 1s - loss: 1.088 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 20s 1ms/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 20/100\n",
      "17621/17621 [==============================] - ETA: 18s - loss: 1.07 - ETA: 17s - loss: 1.08 - ETA: 19s - loss: 1.08 - ETA: 18s - loss: 1.08 - ETA: 17s - loss: 1.08 - ETA: 16s - loss: 1.08 - ETA: 15s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0869 - ETA: 9s - loss: 1.086 - ETA: 8s - loss: 1.087 - ETA: 8s - loss: 1.087 - ETA: 7s - loss: 1.087 - ETA: 7s - loss: 1.087 - ETA: 6s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 5s - loss: 1.086 - ETA: 4s - loss: 1.087 - ETA: 4s - loss: 1.088 - ETA: 3s - loss: 1.088 - ETA: 3s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 22s 1ms/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 21/100\n",
      "17621/17621 [==============================] - ETA: 38s - loss: 1.08 - ETA: 33s - loss: 1.08 - ETA: 27s - loss: 1.08 - ETA: 23s - loss: 1.08 - ETA: 21s - loss: 1.08 - ETA: 19s - loss: 1.08 - ETA: 18s - loss: 1.08 - ETA: 16s - loss: 1.08 - ETA: 16s - loss: 1.08 - ETA: 15s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0856 - ETA: 8s - loss: 1.085 - ETA: 8s - loss: 1.085 - ETA: 7s - loss: 1.086 - ETA: 6s - loss: 1.086 - ETA: 6s - loss: 1.086 - ETA: 5s - loss: 1.086 - ETA: 5s - loss: 1.087 - ETA: 4s - loss: 1.086 - ETA: 4s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 20s 1ms/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 22/100\n",
      "17621/17621 [==============================] - ETA: 14s - loss: 1.10 - ETA: 16s - loss: 1.09 - ETA: 15s - loss: 1.09 - ETA: 15s - loss: 1.09 - ETA: 14s - loss: 1.09 - ETA: 14s - loss: 1.09 - ETA: 13s - loss: 1.09 - ETA: 13s - loss: 1.09 - ETA: 12s - loss: 1.09 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0884 - ETA: 9s - loss: 1.088 - ETA: 8s - loss: 1.088 - ETA: 7s - loss: 1.088 - ETA: 7s - loss: 1.088 - ETA: 6s - loss: 1.088 - ETA: 6s - loss: 1.088 - ETA: 5s - loss: 1.089 - ETA: 5s - loss: 1.089 - ETA: 4s - loss: 1.089 - ETA: 4s - loss: 1.089 - ETA: 3s - loss: 1.088 - ETA: 3s - loss: 1.088 - ETA: 3s - loss: 1.088 - ETA: 2s - loss: 1.088 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 17s 949us/step - loss: 1.0876 - val_loss: 1.0875\n",
      "Epoch 23/100\n",
      "17621/17621 [==============================] - ETA: 15s - loss: 1.07 - ETA: 14s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0873 - ETA: 9s - loss: 1.087 - ETA: 8s - loss: 1.086 - ETA: 8s - loss: 1.086 - ETA: 8s - loss: 1.086 - ETA: 7s - loss: 1.086 - ETA: 7s - loss: 1.086 - ETA: 6s - loss: 1.086 - ETA: 6s - loss: 1.086 - ETA: 5s - loss: 1.086 - ETA: 5s - loss: 1.087 - ETA: 4s - loss: 1.086 - ETA: 4s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 3s - loss: 1.088 - ETA: 2s - loss: 1.088 - ETA: 2s - loss: 1.088 - ETA: 1s - loss: 1.088 - ETA: 1s - loss: 1.088 - ETA: 1s - loss: 1.088 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 16s 888us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 24/100\n",
      "17621/17621 [==============================] - ETA: 14s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.09 - ETA: 12s - loss: 1.09 - ETA: 12s - loss: 1.09 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0900 - ETA: 9s - loss: 1.089 - ETA: 8s - loss: 1.088 - ETA: 8s - loss: 1.088 - ETA: 8s - loss: 1.088 - ETA: 7s - loss: 1.088 - ETA: 7s - loss: 1.087 - ETA: 6s - loss: 1.087 - ETA: 6s - loss: 1.088 - ETA: 6s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 4s - loss: 1.088 - ETA: 4s - loss: 1.088 - ETA: 3s - loss: 1.088 - ETA: 3s - loss: 1.088 - ETA: 2s - loss: 1.088 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 17s 939us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17621/17621 [==============================] - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 16s - loss: 1.08 - ETA: 16s - loss: 1.08 - ETA: 16s - loss: 1.08 - ETA: 15s - loss: 1.08 - ETA: 15s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0867 - ETA: 9s - loss: 1.086 - ETA: 8s - loss: 1.087 - ETA: 7s - loss: 1.086 - ETA: 7s - loss: 1.086 - ETA: 6s - loss: 1.086 - ETA: 6s - loss: 1.086 - ETA: 5s - loss: 1.086 - ETA: 5s - loss: 1.086 - ETA: 4s - loss: 1.086 - ETA: 4s - loss: 1.086 - ETA: 3s - loss: 1.086 - ETA: 3s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 17s 961us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 26/100\n",
      "17621/17621 [==============================] - ETA: 14s - loss: 1.09 - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.09 - ETA: 13s - loss: 1.09 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0882 - ETA: 9s - loss: 1.088 - ETA: 8s - loss: 1.089 - ETA: 8s - loss: 1.088 - ETA: 7s - loss: 1.088 - ETA: 7s - loss: 1.087 - ETA: 6s - loss: 1.088 - ETA: 6s - loss: 1.087 - ETA: 6s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 15s 876us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 27/100\n",
      "17621/17621 [==============================] - ETA: 14s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0882 - ETA: 9s - loss: 1.087 - ETA: 9s - loss: 1.087 - ETA: 8s - loss: 1.087 - ETA: 8s - loss: 1.087 - ETA: 7s - loss: 1.088 - ETA: 7s - loss: 1.088 - ETA: 6s - loss: 1.088 - ETA: 6s - loss: 1.088 - ETA: 6s - loss: 1.088 - ETA: 5s - loss: 1.088 - ETA: 5s - loss: 1.088 - ETA: 4s - loss: 1.088 - ETA: 4s - loss: 1.088 - ETA: 4s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 3s - loss: 1.088 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.088 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 15s 877us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 28/100\n",
      "17621/17621 [==============================] - ETA: 14s - loss: 1.09 - ETA: 14s - loss: 1.09 - ETA: 13s - loss: 1.09 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0879 - ETA: 9s - loss: 1.086 - ETA: 8s - loss: 1.086 - ETA: 8s - loss: 1.086 - ETA: 7s - loss: 1.086 - ETA: 7s - loss: 1.085 - ETA: 6s - loss: 1.085 - ETA: 6s - loss: 1.086 - ETA: 6s - loss: 1.086 - ETA: 5s - loss: 1.086 - ETA: 5s - loss: 1.086 - ETA: 4s - loss: 1.086 - ETA: 4s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 3s - loss: 1.086 - ETA: 3s - loss: 1.086 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 16s 894us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 29/100\n",
      "17621/17621 [==============================] - ETA: 15s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 16s - loss: 1.08 - ETA: 15s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0870 - ETA: 9s - loss: 1.086 - ETA: 8s - loss: 1.086 - ETA: 8s - loss: 1.087 - ETA: 7s - loss: 1.087 - ETA: 7s - loss: 1.086 - ETA: 6s - loss: 1.086 - ETA: 6s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 5s - loss: 1.088 - ETA: 4s - loss: 1.087 - ETA: 4s - loss: 1.088 - ETA: 3s - loss: 1.088 - ETA: 3s - loss: 1.087 - ETA: 3s - loss: 1.088 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 17s 940us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 30/100\n",
      "17621/17621 [==============================] - ETA: 13s - loss: 1.09 - ETA: 13s - loss: 1.09 - ETA: 13s - loss: 1.09 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0881 - ETA: 9s - loss: 1.088 - ETA: 8s - loss: 1.089 - ETA: 8s - loss: 1.089 - ETA: 8s - loss: 1.089 - ETA: 7s - loss: 1.089 - ETA: 7s - loss: 1.089 - ETA: 6s - loss: 1.089 - ETA: 6s - loss: 1.088 - ETA: 5s - loss: 1.088 - ETA: 5s - loss: 1.088 - ETA: 5s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.088 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 15s 848us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 31/100\n",
      "17621/17621 [==============================] - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.09 - ETA: 13s - loss: 1.09 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0882 - ETA: 9s - loss: 1.088 - ETA: 8s - loss: 1.088 - ETA: 8s - loss: 1.087 - ETA: 8s - loss: 1.087 - ETA: 7s - loss: 1.086 - ETA: 7s - loss: 1.086 - ETA: 6s - loss: 1.086 - ETA: 6s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 4s - loss: 1.088 - ETA: 4s - loss: 1.087 - ETA: 3s - loss: 1.088 - ETA: 3s - loss: 1.088 - ETA: 3s - loss: 1.088 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.088 - ETA: 1s - loss: 1.088 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 15s 846us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 32/100\n",
      "17621/17621 [==============================] - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.07 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0860 - ETA: 9s - loss: 1.087 - ETA: 8s - loss: 1.087 - ETA: 8s - loss: 1.086 - ETA: 8s - loss: 1.086 - ETA: 7s - loss: 1.087 - ETA: 7s - loss: 1.087 - ETA: 6s - loss: 1.087 - ETA: 6s - loss: 1.086 - ETA: 5s - loss: 1.086 - ETA: 5s - loss: 1.086 - ETA: 5s - loss: 1.086 - ETA: 4s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 3s - loss: 1.086 - ETA: 3s - loss: 1.086 - ETA: 2s - loss: 1.086 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 15s 843us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17621/17621 [==============================] - ETA: 14s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0879 - ETA: 9s - loss: 1.087 - ETA: 8s - loss: 1.088 - ETA: 8s - loss: 1.088 - ETA: 8s - loss: 1.088 - ETA: 7s - loss: 1.087 - ETA: 7s - loss: 1.087 - ETA: 6s - loss: 1.087 - ETA: 6s - loss: 1.087 - ETA: 6s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 4s - loss: 1.086 - ETA: 3s - loss: 1.086 - ETA: 3s - loss: 1.086 - ETA: 3s - loss: 1.086 - ETA: 2s - loss: 1.086 - ETA: 2s - loss: 1.086 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 15s 850us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 34/100\n",
      "17621/17621 [==============================] - ETA: 13s - loss: 1.09 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0860 - ETA: 9s - loss: 1.085 - ETA: 8s - loss: 1.086 - ETA: 8s - loss: 1.086 - ETA: 8s - loss: 1.086 - ETA: 7s - loss: 1.086 - ETA: 7s - loss: 1.086 - ETA: 6s - loss: 1.086 - ETA: 6s - loss: 1.086 - ETA: 5s - loss: 1.086 - ETA: 5s - loss: 1.086 - ETA: 5s - loss: 1.086 - ETA: 4s - loss: 1.086 - ETA: 4s - loss: 1.086 - ETA: 3s - loss: 1.086 - ETA: 3s - loss: 1.086 - ETA: 3s - loss: 1.086 - ETA: 2s - loss: 1.086 - ETA: 2s - loss: 1.086 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 16s 891us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 35/100\n",
      "17621/17621 [==============================] - ETA: 14s - loss: 1.09 - ETA: 16s - loss: 1.08 - ETA: 15s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 15s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 15s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0872 - ETA: 9s - loss: 1.087 - ETA: 8s - loss: 1.086 - ETA: 7s - loss: 1.087 - ETA: 6s - loss: 1.087 - ETA: 6s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 19s 1ms/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 36/100\n",
      "17621/17621 [==============================] - ETA: 14s - loss: 1.08 - ETA: 13s - loss: 1.09 - ETA: 13s - loss: 1.09 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0888 - ETA: 9s - loss: 1.088 - ETA: 9s - loss: 1.087 - ETA: 8s - loss: 1.088 - ETA: 8s - loss: 1.088 - ETA: 7s - loss: 1.088 - ETA: 7s - loss: 1.087 - ETA: 6s - loss: 1.087 - ETA: 6s - loss: 1.088 - ETA: 6s - loss: 1.088 - ETA: 5s - loss: 1.088 - ETA: 5s - loss: 1.088 - ETA: 4s - loss: 1.088 - ETA: 4s - loss: 1.088 - ETA: 3s - loss: 1.088 - ETA: 3s - loss: 1.088 - ETA: 3s - loss: 1.088 - ETA: 2s - loss: 1.088 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 15s 854us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 37/100\n",
      "17621/17621 [==============================] - ETA: 14s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0881 - ETA: 9s - loss: 1.088 - ETA: 9s - loss: 1.087 - ETA: 8s - loss: 1.088 - ETA: 8s - loss: 1.087 - ETA: 7s - loss: 1.088 - ETA: 7s - loss: 1.088 - ETA: 6s - loss: 1.088 - ETA: 6s - loss: 1.088 - ETA: 6s - loss: 1.089 - ETA: 5s - loss: 1.088 - ETA: 5s - loss: 1.088 - ETA: 4s - loss: 1.088 - ETA: 4s - loss: 1.089 - ETA: 3s - loss: 1.089 - ETA: 3s - loss: 1.089 - ETA: 3s - loss: 1.088 - ETA: 2s - loss: 1.088 - ETA: 2s - loss: 1.088 - ETA: 1s - loss: 1.088 - ETA: 1s - loss: 1.088 - ETA: 1s - loss: 1.088 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 15s 870us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 38/100\n",
      "17621/17621 [==============================] - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.09 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0879 - ETA: 9s - loss: 1.087 - ETA: 8s - loss: 1.086 - ETA: 8s - loss: 1.086 - ETA: 8s - loss: 1.086 - ETA: 7s - loss: 1.087 - ETA: 7s - loss: 1.087 - ETA: 6s - loss: 1.088 - ETA: 6s - loss: 1.088 - ETA: 6s - loss: 1.088 - ETA: 5s - loss: 1.088 - ETA: 5s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 15s 861us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 39/100\n",
      "17621/17621 [==============================] - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0871 - ETA: 9s - loss: 1.086 - ETA: 8s - loss: 1.086 - ETA: 8s - loss: 1.086 - ETA: 8s - loss: 1.087 - ETA: 7s - loss: 1.087 - ETA: 7s - loss: 1.087 - ETA: 6s - loss: 1.087 - ETA: 6s - loss: 1.087 - ETA: 6s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 5s - loss: 1.088 - ETA: 4s - loss: 1.088 - ETA: 4s - loss: 1.088 - ETA: 3s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 15s 856us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 40/100\n",
      "17621/17621 [==============================] - ETA: 13s - loss: 1.09 - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.09 - ETA: 12s - loss: 1.09 - ETA: 11s - loss: 1.09 - ETA: 11s - loss: 1.09 - ETA: 10s - loss: 1.09 - ETA: 10s - loss: 1.09 - ETA: 10s - loss: 1.09 - ETA: 9s - loss: 1.0918 - ETA: 9s - loss: 1.090 - ETA: 8s - loss: 1.090 - ETA: 8s - loss: 1.090 - ETA: 8s - loss: 1.089 - ETA: 7s - loss: 1.089 - ETA: 7s - loss: 1.089 - ETA: 6s - loss: 1.088 - ETA: 6s - loss: 1.088 - ETA: 6s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 15s 861us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17621/17621 [==============================] - ETA: 13s - loss: 1.07 - ETA: 14s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0897 - ETA: 9s - loss: 1.089 - ETA: 9s - loss: 1.089 - ETA: 8s - loss: 1.089 - ETA: 8s - loss: 1.088 - ETA: 7s - loss: 1.088 - ETA: 7s - loss: 1.088 - ETA: 6s - loss: 1.089 - ETA: 6s - loss: 1.088 - ETA: 6s - loss: 1.088 - ETA: 5s - loss: 1.089 - ETA: 5s - loss: 1.088 - ETA: 4s - loss: 1.088 - ETA: 4s - loss: 1.088 - ETA: 3s - loss: 1.088 - ETA: 3s - loss: 1.088 - ETA: 3s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 15s 862us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 42/100\n",
      "17621/17621 [==============================] - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.09 - ETA: 12s - loss: 1.09 - ETA: 12s - loss: 1.09 - ETA: 12s - loss: 1.09 - ETA: 11s - loss: 1.09 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0864 - ETA: 9s - loss: 1.085 - ETA: 8s - loss: 1.085 - ETA: 8s - loss: 1.085 - ETA: 7s - loss: 1.085 - ETA: 7s - loss: 1.086 - ETA: 7s - loss: 1.086 - ETA: 6s - loss: 1.086 - ETA: 6s - loss: 1.086 - ETA: 5s - loss: 1.087 - ETA: 5s - loss: 1.086 - ETA: 5s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 3s - loss: 1.088 - ETA: 3s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 15s 839us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 43/100\n",
      "17621/17621 [==============================] - ETA: 13s - loss: 1.09 - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0861 - ETA: 9s - loss: 1.086 - ETA: 8s - loss: 1.086 - ETA: 8s - loss: 1.086 - ETA: 7s - loss: 1.086 - ETA: 7s - loss: 1.087 - ETA: 7s - loss: 1.086 - ETA: 6s - loss: 1.086 - ETA: 6s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 5s - loss: 1.086 - ETA: 4s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 15s 843us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 44/100\n",
      "17621/17621 [==============================] - ETA: 13s - loss: 1.09 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.09 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0882 - ETA: 9s - loss: 1.087 - ETA: 9s - loss: 1.087 - ETA: 8s - loss: 1.088 - ETA: 8s - loss: 1.088 - ETA: 7s - loss: 1.088 - ETA: 7s - loss: 1.088 - ETA: 7s - loss: 1.088 - ETA: 6s - loss: 1.087 - ETA: 6s - loss: 1.088 - ETA: 5s - loss: 1.087 - ETA: 5s - loss: 1.086 - ETA: 5s - loss: 1.086 - ETA: 4s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 15s 839us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 45/100\n",
      "17621/17621 [==============================] - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0881 - ETA: 9s - loss: 1.087 - ETA: 8s - loss: 1.087 - ETA: 8s - loss: 1.087 - ETA: 8s - loss: 1.086 - ETA: 7s - loss: 1.086 - ETA: 7s - loss: 1.086 - ETA: 6s - loss: 1.086 - ETA: 6s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 5s - loss: 1.088 - ETA: 4s - loss: 1.088 - ETA: 4s - loss: 1.088 - ETA: 3s - loss: 1.088 - ETA: 3s - loss: 1.088 - ETA: 3s - loss: 1.088 - ETA: 2s - loss: 1.088 - ETA: 2s - loss: 1.088 - ETA: 1s - loss: 1.088 - ETA: 1s - loss: 1.088 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 15s 848us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 46/100\n",
      "17621/17621 [==============================] - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.09 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0886 - ETA: 9s - loss: 1.088 - ETA: 9s - loss: 1.088 - ETA: 8s - loss: 1.088 - ETA: 8s - loss: 1.088 - ETA: 7s - loss: 1.088 - ETA: 7s - loss: 1.087 - ETA: 7s - loss: 1.087 - ETA: 6s - loss: 1.087 - ETA: 6s - loss: 1.087 - ETA: 5s - loss: 1.088 - ETA: 5s - loss: 1.088 - ETA: 5s - loss: 1.088 - ETA: 4s - loss: 1.088 - ETA: 4s - loss: 1.088 - ETA: 3s - loss: 1.088 - ETA: 3s - loss: 1.088 - ETA: 3s - loss: 1.088 - ETA: 2s - loss: 1.088 - ETA: 2s - loss: 1.088 - ETA: 1s - loss: 1.088 - ETA: 1s - loss: 1.088 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 15s 843us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 47/100\n",
      "17621/17621 [==============================] - ETA: 16s - loss: 1.08 - ETA: 16s - loss: 1.08 - ETA: 15s - loss: 1.08 - ETA: 15s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 13s - loss: 1.09 - ETA: 12s - loss: 1.09 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.09 - ETA: 10s - loss: 1.09 - ETA: 10s - loss: 1.09 - ETA: 9s - loss: 1.0909 - ETA: 9s - loss: 1.090 - ETA: 8s - loss: 1.089 - ETA: 8s - loss: 1.088 - ETA: 7s - loss: 1.089 - ETA: 7s - loss: 1.088 - ETA: 6s - loss: 1.088 - ETA: 6s - loss: 1.088 - ETA: 6s - loss: 1.088 - ETA: 5s - loss: 1.088 - ETA: 5s - loss: 1.087 - ETA: 4s - loss: 1.088 - ETA: 4s - loss: 1.088 - ETA: 3s - loss: 1.088 - ETA: 3s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.088 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 16s 931us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 48/100\n",
      "17621/17621 [==============================] - ETA: 14s - loss: 1.09 - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0888 - ETA: 9s - loss: 1.088 - ETA: 9s - loss: 1.088 - ETA: 8s - loss: 1.088 - ETA: 8s - loss: 1.088 - ETA: 7s - loss: 1.088 - ETA: 7s - loss: 1.087 - ETA: 6s - loss: 1.087 - ETA: 6s - loss: 1.087 - ETA: 6s - loss: 1.088 - ETA: 5s - loss: 1.087 - ETA: 5s - loss: 1.088 - ETA: 4s - loss: 1.087 - ETA: 4s - loss: 1.088 - ETA: 3s - loss: 1.087 - ETA: 3s - loss: 1.088 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.088 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.088 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 16s 929us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17621/17621 [==============================] - ETA: 14s - loss: 1.09 - ETA: 13s - loss: 1.09 - ETA: 13s - loss: 1.09 - ETA: 12s - loss: 1.09 - ETA: 12s - loss: 1.09 - ETA: 12s - loss: 1.09 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0892 - ETA: 9s - loss: 1.089 - ETA: 9s - loss: 1.088 - ETA: 8s - loss: 1.088 - ETA: 8s - loss: 1.088 - ETA: 7s - loss: 1.088 - ETA: 7s - loss: 1.088 - ETA: 6s - loss: 1.088 - ETA: 6s - loss: 1.088 - ETA: 5s - loss: 1.088 - ETA: 5s - loss: 1.088 - ETA: 4s - loss: 1.088 - ETA: 4s - loss: 1.088 - ETA: 3s - loss: 1.088 - ETA: 3s - loss: 1.088 - ETA: 2s - loss: 1.088 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 16s 909us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 50/100\n",
      "17621/17621 [==============================] - ETA: 14s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 17s - loss: 1.08 - ETA: 17s - loss: 1.08 - ETA: 15s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0869 - ETA: 9s - loss: 1.086 - ETA: 8s - loss: 1.086 - ETA: 8s - loss: 1.086 - ETA: 8s - loss: 1.087 - ETA: 7s - loss: 1.087 - ETA: 7s - loss: 1.087 - ETA: 6s - loss: 1.087 - ETA: 6s - loss: 1.086 - ETA: 5s - loss: 1.086 - ETA: 5s - loss: 1.086 - ETA: 4s - loss: 1.086 - ETA: 4s - loss: 1.086 - ETA: 3s - loss: 1.086 - ETA: 3s - loss: 1.086 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.086 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 18s 994us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 51/100\n",
      "17621/17621 [==============================] - ETA: 23s - loss: 1.09 - ETA: 17s - loss: 1.08 - ETA: 17s - loss: 1.08 - ETA: 16s - loss: 1.08 - ETA: 16s - loss: 1.08 - ETA: 15s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0848 - ETA: 9s - loss: 1.085 - ETA: 8s - loss: 1.085 - ETA: 7s - loss: 1.085 - ETA: 7s - loss: 1.086 - ETA: 7s - loss: 1.086 - ETA: 6s - loss: 1.086 - ETA: 6s - loss: 1.086 - ETA: 5s - loss: 1.086 - ETA: 5s - loss: 1.086 - ETA: 4s - loss: 1.086 - ETA: 4s - loss: 1.086 - ETA: 4s - loss: 1.086 - ETA: 3s - loss: 1.086 - ETA: 3s - loss: 1.086 - ETA: 2s - loss: 1.086 - ETA: 2s - loss: 1.086 - ETA: 1s - loss: 1.086 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 18s 1ms/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 52/100\n",
      "17621/17621 [==============================] - ETA: 21s - loss: 1.08 - ETA: 17s - loss: 1.08 - ETA: 17s - loss: 1.08 - ETA: 15s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.09 - ETA: 9s - loss: 1.0897 - ETA: 9s - loss: 1.090 - ETA: 8s - loss: 1.089 - ETA: 8s - loss: 1.089 - ETA: 7s - loss: 1.089 - ETA: 6s - loss: 1.088 - ETA: 6s - loss: 1.088 - ETA: 5s - loss: 1.088 - ETA: 5s - loss: 1.088 - ETA: 4s - loss: 1.088 - ETA: 4s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 18s 999us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 53/100\n",
      "17621/17621 [==============================] - ETA: 15s - loss: 1.08 - ETA: 16s - loss: 1.08 - ETA: 15s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0872 - ETA: 9s - loss: 1.087 - ETA: 8s - loss: 1.086 - ETA: 8s - loss: 1.086 - ETA: 7s - loss: 1.086 - ETA: 7s - loss: 1.086 - ETA: 6s - loss: 1.086 - ETA: 6s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 5s - loss: 1.086 - ETA: 4s - loss: 1.086 - ETA: 4s - loss: 1.086 - ETA: 3s - loss: 1.086 - ETA: 3s - loss: 1.086 - ETA: 2s - loss: 1.086 - ETA: 2s - loss: 1.086 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 16s 924us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 54/100\n",
      "17621/17621 [==============================] - ETA: 14s - loss: 1.09 - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0887 - ETA: 9s - loss: 1.089 - ETA: 8s - loss: 1.089 - ETA: 8s - loss: 1.089 - ETA: 7s - loss: 1.089 - ETA: 7s - loss: 1.088 - ETA: 6s - loss: 1.088 - ETA: 6s - loss: 1.088 - ETA: 5s - loss: 1.088 - ETA: 5s - loss: 1.088 - ETA: 4s - loss: 1.088 - ETA: 4s - loss: 1.087 - ETA: 3s - loss: 1.088 - ETA: 3s - loss: 1.088 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 17s 987us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 55/100\n",
      "17621/17621 [==============================] - ETA: 15s - loss: 1.09 - ETA: 17s - loss: 1.08 - ETA: 16s - loss: 1.08 - ETA: 15s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0876 - ETA: 9s - loss: 1.088 - ETA: 8s - loss: 1.088 - ETA: 8s - loss: 1.088 - ETA: 7s - loss: 1.088 - ETA: 7s - loss: 1.089 - ETA: 6s - loss: 1.088 - ETA: 6s - loss: 1.088 - ETA: 5s - loss: 1.088 - ETA: 5s - loss: 1.088 - ETA: 5s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 16s 894us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 56/100\n",
      "17621/17621 [==============================] - ETA: 15s - loss: 1.09 - ETA: 14s - loss: 1.09 - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0865 - ETA: 9s - loss: 1.086 - ETA: 8s - loss: 1.087 - ETA: 8s - loss: 1.086 - ETA: 7s - loss: 1.087 - ETA: 7s - loss: 1.087 - ETA: 7s - loss: 1.087 - ETA: 7s - loss: 1.087 - ETA: 6s - loss: 1.087 - ETA: 6s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 16s 931us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17621/17621 [==============================] - ETA: 17s - loss: 1.07 - ETA: 15s - loss: 1.07 - ETA: 14s - loss: 1.07 - ETA: 15s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.09 - ETA: 9s - loss: 1.0899 - ETA: 9s - loss: 1.089 - ETA: 8s - loss: 1.089 - ETA: 8s - loss: 1.089 - ETA: 7s - loss: 1.089 - ETA: 7s - loss: 1.089 - ETA: 6s - loss: 1.089 - ETA: 6s - loss: 1.089 - ETA: 5s - loss: 1.089 - ETA: 5s - loss: 1.089 - ETA: 4s - loss: 1.089 - ETA: 4s - loss: 1.088 - ETA: 3s - loss: 1.088 - ETA: 3s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 16s 924us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 58/100\n",
      "17621/17621 [==============================] - ETA: 15s - loss: 1.09 - ETA: 15s - loss: 1.09 - ETA: 15s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0870 - ETA: 9s - loss: 1.086 - ETA: 8s - loss: 1.086 - ETA: 8s - loss: 1.087 - ETA: 7s - loss: 1.086 - ETA: 7s - loss: 1.086 - ETA: 6s - loss: 1.086 - ETA: 6s - loss: 1.086 - ETA: 5s - loss: 1.086 - ETA: 5s - loss: 1.086 - ETA: 4s - loss: 1.086 - ETA: 4s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 17s 945us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 59/100\n",
      "17621/17621 [==============================] - ETA: 14s - loss: 1.09 - ETA: 15s - loss: 1.09 - ETA: 14s - loss: 1.09 - ETA: 14s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0874 - ETA: 9s - loss: 1.086 - ETA: 9s - loss: 1.087 - ETA: 8s - loss: 1.087 - ETA: 8s - loss: 1.087 - ETA: 7s - loss: 1.088 - ETA: 7s - loss: 1.088 - ETA: 6s - loss: 1.088 - ETA: 6s - loss: 1.088 - ETA: 5s - loss: 1.088 - ETA: 5s - loss: 1.087 - ETA: 4s - loss: 1.088 - ETA: 4s - loss: 1.088 - ETA: 3s - loss: 1.088 - ETA: 3s - loss: 1.088 - ETA: 2s - loss: 1.088 - ETA: 2s - loss: 1.088 - ETA: 2s - loss: 1.088 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 16s 925us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 60/100\n",
      "17621/17621 [==============================] - ETA: 14s - loss: 1.09 - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.09 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0852 - ETA: 9s - loss: 1.087 - ETA: 8s - loss: 1.087 - ETA: 8s - loss: 1.087 - ETA: 7s - loss: 1.087 - ETA: 7s - loss: 1.087 - ETA: 7s - loss: 1.086 - ETA: 6s - loss: 1.087 - ETA: 6s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.086 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 16s 883us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 61/100\n",
      "17621/17621 [==============================] - ETA: 14s - loss: 1.09 - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.09 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0877 - ETA: 9s - loss: 1.088 - ETA: 8s - loss: 1.087 - ETA: 7s - loss: 1.087 - ETA: 7s - loss: 1.087 - ETA: 6s - loss: 1.086 - ETA: 6s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 3s - loss: 1.086 - ETA: 3s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 17s 985us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 62/100\n",
      "17621/17621 [==============================] - ETA: 14s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0883 - ETA: 8s - loss: 1.088 - ETA: 8s - loss: 1.089 - ETA: 7s - loss: 1.089 - ETA: 7s - loss: 1.089 - ETA: 6s - loss: 1.089 - ETA: 6s - loss: 1.088 - ETA: 5s - loss: 1.088 - ETA: 5s - loss: 1.088 - ETA: 4s - loss: 1.088 - ETA: 4s - loss: 1.088 - ETA: 4s - loss: 1.088 - ETA: 3s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 17s 974us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 63/100\n",
      "17621/17621 [==============================] - ETA: 14s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0891 - ETA: 9s - loss: 1.088 - ETA: 8s - loss: 1.088 - ETA: 8s - loss: 1.088 - ETA: 7s - loss: 1.088 - ETA: 7s - loss: 1.088 - ETA: 6s - loss: 1.088 - ETA: 6s - loss: 1.088 - ETA: 6s - loss: 1.088 - ETA: 5s - loss: 1.089 - ETA: 5s - loss: 1.088 - ETA: 4s - loss: 1.088 - ETA: 4s - loss: 1.088 - ETA: 3s - loss: 1.088 - ETA: 3s - loss: 1.088 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 16s 909us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 64/100\n",
      "17621/17621 [==============================] - ETA: 19s - loss: 1.09 - ETA: 17s - loss: 1.08 - ETA: 15s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0857 - ETA: 9s - loss: 1.086 - ETA: 8s - loss: 1.087 - ETA: 8s - loss: 1.087 - ETA: 8s - loss: 1.087 - ETA: 7s - loss: 1.088 - ETA: 7s - loss: 1.087 - ETA: 6s - loss: 1.086 - ETA: 6s - loss: 1.086 - ETA: 5s - loss: 1.086 - ETA: 5s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 16s 918us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17621/17621 [==============================] - ETA: 14s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0847 - ETA: 9s - loss: 1.085 - ETA: 8s - loss: 1.085 - ETA: 8s - loss: 1.085 - ETA: 8s - loss: 1.085 - ETA: 7s - loss: 1.085 - ETA: 7s - loss: 1.086 - ETA: 6s - loss: 1.085 - ETA: 6s - loss: 1.085 - ETA: 5s - loss: 1.085 - ETA: 5s - loss: 1.085 - ETA: 4s - loss: 1.085 - ETA: 4s - loss: 1.086 - ETA: 4s - loss: 1.086 - ETA: 3s - loss: 1.086 - ETA: 3s - loss: 1.086 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.086 - ETA: 1s - loss: 1.086 - ETA: 1s - loss: 1.086 - ETA: 1s - loss: 1.086 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 16s 896us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 66/100\n",
      "17621/17621 [==============================] - ETA: 14s - loss: 1.09 - ETA: 14s - loss: 1.09 - ETA: 14s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0873 - ETA: 9s - loss: 1.088 - ETA: 8s - loss: 1.088 - ETA: 8s - loss: 1.088 - ETA: 7s - loss: 1.088 - ETA: 7s - loss: 1.088 - ETA: 6s - loss: 1.088 - ETA: 6s - loss: 1.088 - ETA: 6s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 16s 912us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 67/100\n",
      "17621/17621 [==============================] - ETA: 14s - loss: 1.09 - ETA: 14s - loss: 1.09 - ETA: 13s - loss: 1.09 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0869 - ETA: 9s - loss: 1.087 - ETA: 8s - loss: 1.087 - ETA: 8s - loss: 1.087 - ETA: 8s - loss: 1.087 - ETA: 7s - loss: 1.087 - ETA: 7s - loss: 1.086 - ETA: 6s - loss: 1.086 - ETA: 6s - loss: 1.086 - ETA: 5s - loss: 1.086 - ETA: 5s - loss: 1.086 - ETA: 4s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 17s 952us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 68/100\n",
      "17621/17621 [==============================] - ETA: 15s - loss: 1.08 - ETA: 15s - loss: 1.08 - ETA: 14s - loss: 1.07 - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0857 - ETA: 9s - loss: 1.085 - ETA: 8s - loss: 1.084 - ETA: 8s - loss: 1.085 - ETA: 8s - loss: 1.085 - ETA: 7s - loss: 1.086 - ETA: 7s - loss: 1.086 - ETA: 6s - loss: 1.086 - ETA: 6s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.088 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 16s 897us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 69/100\n",
      "17621/17621 [==============================] - ETA: 15s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0858 - ETA: 9s - loss: 1.086 - ETA: 8s - loss: 1.086 - ETA: 8s - loss: 1.085 - ETA: 7s - loss: 1.086 - ETA: 7s - loss: 1.086 - ETA: 6s - loss: 1.086 - ETA: 6s - loss: 1.087 - ETA: 5s - loss: 1.086 - ETA: 5s - loss: 1.086 - ETA: 5s - loss: 1.086 - ETA: 4s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 3s - loss: 1.086 - ETA: 2s - loss: 1.086 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 16s 908us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 70/100\n",
      "17621/17621 [==============================] - ETA: 15s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0865 - ETA: 9s - loss: 1.087 - ETA: 8s - loss: 1.086 - ETA: 8s - loss: 1.086 - ETA: 7s - loss: 1.086 - ETA: 7s - loss: 1.085 - ETA: 7s - loss: 1.085 - ETA: 6s - loss: 1.085 - ETA: 6s - loss: 1.085 - ETA: 5s - loss: 1.086 - ETA: 5s - loss: 1.085 - ETA: 4s - loss: 1.086 - ETA: 4s - loss: 1.086 - ETA: 3s - loss: 1.086 - ETA: 3s - loss: 1.086 - ETA: 2s - loss: 1.086 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.086 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 17s 951us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 71/100\n",
      "17621/17621 [==============================] - ETA: 16s - loss: 1.09 - ETA: 15s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0870 - ETA: 9s - loss: 1.086 - ETA: 8s - loss: 1.087 - ETA: 8s - loss: 1.087 - ETA: 7s - loss: 1.087 - ETA: 7s - loss: 1.087 - ETA: 6s - loss: 1.087 - ETA: 6s - loss: 1.087 - ETA: 5s - loss: 1.086 - ETA: 5s - loss: 1.086 - ETA: 4s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 17s 944us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 72/100\n",
      "17621/17621 [==============================] - ETA: 18s - loss: 1.08 - ETA: 17s - loss: 1.08 - ETA: 20s - loss: 1.08 - ETA: 18s - loss: 1.08 - ETA: 17s - loss: 1.08 - ETA: 15s - loss: 1.08 - ETA: 16s - loss: 1.08 - ETA: 16s - loss: 1.08 - ETA: 16s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0856 - ETA: 9s - loss: 1.086 - ETA: 8s - loss: 1.086 - ETA: 8s - loss: 1.086 - ETA: 7s - loss: 1.086 - ETA: 6s - loss: 1.087 - ETA: 6s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 4s - loss: 1.088 - ETA: 3s - loss: 1.088 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.088 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 19s 1ms/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17621/17621 [==============================] - ETA: 16s - loss: 1.08 - ETA: 15s - loss: 1.09 - ETA: 15s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0893 - ETA: 9s - loss: 1.089 - ETA: 8s - loss: 1.088 - ETA: 8s - loss: 1.088 - ETA: 7s - loss: 1.088 - ETA: 7s - loss: 1.088 - ETA: 6s - loss: 1.087 - ETA: 6s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 18s 1ms/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 74/100\n",
      "17621/17621 [==============================] - ETA: 17s - loss: 1.09 - ETA: 17s - loss: 1.09 - ETA: 15s - loss: 1.09 - ETA: 14s - loss: 1.09 - ETA: 15s - loss: 1.09 - ETA: 17s - loss: 1.09 - ETA: 17s - loss: 1.09 - ETA: 16s - loss: 1.09 - ETA: 14s - loss: 1.09 - ETA: 14s - loss: 1.09 - ETA: 13s - loss: 1.09 - ETA: 12s - loss: 1.09 - ETA: 11s - loss: 1.09 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0891 - ETA: 9s - loss: 1.089 - ETA: 8s - loss: 1.088 - ETA: 7s - loss: 1.088 - ETA: 7s - loss: 1.088 - ETA: 6s - loss: 1.087 - ETA: 6s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 2s - loss: 1.086 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.088 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 18s 1ms/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 75/100\n",
      "17621/17621 [==============================] - ETA: 14s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.09 - ETA: 12s - loss: 1.09 - ETA: 12s - loss: 1.09 - ETA: 12s - loss: 1.09 - ETA: 12s - loss: 1.09 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0893 - ETA: 9s - loss: 1.089 - ETA: 8s - loss: 1.088 - ETA: 8s - loss: 1.089 - ETA: 7s - loss: 1.088 - ETA: 7s - loss: 1.089 - ETA: 6s - loss: 1.088 - ETA: 6s - loss: 1.088 - ETA: 5s - loss: 1.088 - ETA: 5s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 4s - loss: 1.088 - ETA: 3s - loss: 1.088 - ETA: 3s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 17s 976us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 76/100\n",
      "17621/17621 [==============================] - ETA: 13s - loss: 1.09 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0852 - ETA: 9s - loss: 1.086 - ETA: 8s - loss: 1.086 - ETA: 8s - loss: 1.086 - ETA: 8s - loss: 1.086 - ETA: 7s - loss: 1.085 - ETA: 7s - loss: 1.084 - ETA: 6s - loss: 1.085 - ETA: 6s - loss: 1.085 - ETA: 5s - loss: 1.086 - ETA: 5s - loss: 1.086 - ETA: 5s - loss: 1.086 - ETA: 4s - loss: 1.087 - ETA: 4s - loss: 1.086 - ETA: 3s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 16s 924us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 77/100\n",
      "17621/17621 [==============================] - ETA: 14s - loss: 1.09 - ETA: 13s - loss: 1.09 - ETA: 14s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0866 - ETA: 9s - loss: 1.086 - ETA: 8s - loss: 1.087 - ETA: 8s - loss: 1.087 - ETA: 7s - loss: 1.087 - ETA: 7s - loss: 1.086 - ETA: 7s - loss: 1.087 - ETA: 6s - loss: 1.087 - ETA: 6s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 5s - loss: 1.086 - ETA: 4s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 3s - loss: 1.086 - ETA: 3s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.086 - ETA: 1s - loss: 1.086 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 16s 923us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 78/100\n",
      "17621/17621 [==============================] - ETA: 14s - loss: 1.09 - ETA: 14s - loss: 1.09 - ETA: 14s - loss: 1.09 - ETA: 13s - loss: 1.09 - ETA: 13s - loss: 1.09 - ETA: 12s - loss: 1.09 - ETA: 12s - loss: 1.09 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0886 - ETA: 9s - loss: 1.088 - ETA: 9s - loss: 1.088 - ETA: 8s - loss: 1.088 - ETA: 8s - loss: 1.088 - ETA: 7s - loss: 1.087 - ETA: 7s - loss: 1.088 - ETA: 6s - loss: 1.088 - ETA: 6s - loss: 1.087 - ETA: 5s - loss: 1.088 - ETA: 5s - loss: 1.088 - ETA: 5s - loss: 1.088 - ETA: 4s - loss: 1.088 - ETA: 4s - loss: 1.088 - ETA: 3s - loss: 1.088 - ETA: 3s - loss: 1.088 - ETA: 2s - loss: 1.088 - ETA: 2s - loss: 1.088 - ETA: 1s - loss: 1.088 - ETA: 1s - loss: 1.088 - ETA: 1s - loss: 1.088 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 16s 901us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 79/100\n",
      "17621/17621 [==============================] - ETA: 14s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.09 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0893 - ETA: 9s - loss: 1.089 - ETA: 8s - loss: 1.089 - ETA: 8s - loss: 1.089 - ETA: 7s - loss: 1.088 - ETA: 7s - loss: 1.087 - ETA: 7s - loss: 1.087 - ETA: 6s - loss: 1.087 - ETA: 6s - loss: 1.087 - ETA: 6s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 5s - loss: 1.086 - ETA: 4s - loss: 1.086 - ETA: 4s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 3s - loss: 1.086 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 16s 903us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 80/100\n",
      "17621/17621 [==============================] - ETA: 13s - loss: 1.09 - ETA: 14s - loss: 1.09 - ETA: 13s - loss: 1.09 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.09 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0882 - ETA: 9s - loss: 1.087 - ETA: 8s - loss: 1.087 - ETA: 8s - loss: 1.087 - ETA: 8s - loss: 1.087 - ETA: 7s - loss: 1.087 - ETA: 7s - loss: 1.087 - ETA: 6s - loss: 1.086 - ETA: 6s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 5s - loss: 1.086 - ETA: 4s - loss: 1.086 - ETA: 4s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 3s - loss: 1.086 - ETA: 3s - loss: 1.087 - ETA: 2s - loss: 1.086 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.086 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 16s 910us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17621/17621 [==============================] - ETA: 15s - loss: 1.08 - ETA: 14s - loss: 1.07 - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0855 - ETA: 9s - loss: 1.085 - ETA: 8s - loss: 1.086 - ETA: 8s - loss: 1.086 - ETA: 8s - loss: 1.086 - ETA: 7s - loss: 1.087 - ETA: 7s - loss: 1.086 - ETA: 6s - loss: 1.087 - ETA: 6s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 4s - loss: 1.086 - ETA: 4s - loss: 1.086 - ETA: 4s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.086 - ETA: 1s - loss: 1.086 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 16s 886us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 82/100\n",
      "17621/17621 [==============================] - ETA: 14s - loss: 1.08 - ETA: 13s - loss: 1.09 - ETA: 13s - loss: 1.09 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.09 - ETA: 11s - loss: 1.09 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0889 - ETA: 9s - loss: 1.089 - ETA: 8s - loss: 1.089 - ETA: 8s - loss: 1.089 - ETA: 8s - loss: 1.088 - ETA: 7s - loss: 1.088 - ETA: 7s - loss: 1.089 - ETA: 6s - loss: 1.089 - ETA: 6s - loss: 1.089 - ETA: 5s - loss: 1.089 - ETA: 5s - loss: 1.089 - ETA: 4s - loss: 1.088 - ETA: 4s - loss: 1.088 - ETA: 4s - loss: 1.088 - ETA: 3s - loss: 1.088 - ETA: 3s - loss: 1.088 - ETA: 2s - loss: 1.088 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 16s 893us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 83/100\n",
      "17621/17621 [==============================] - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.09 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0855 - ETA: 9s - loss: 1.084 - ETA: 9s - loss: 1.085 - ETA: 8s - loss: 1.085 - ETA: 8s - loss: 1.085 - ETA: 7s - loss: 1.086 - ETA: 7s - loss: 1.086 - ETA: 7s - loss: 1.086 - ETA: 6s - loss: 1.087 - ETA: 6s - loss: 1.088 - ETA: 5s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 16s 889us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 84/100\n",
      "17621/17621 [==============================] - ETA: 15s - loss: 1.08 - ETA: 15s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0865 - ETA: 9s - loss: 1.086 - ETA: 9s - loss: 1.086 - ETA: 8s - loss: 1.086 - ETA: 8s - loss: 1.086 - ETA: 7s - loss: 1.086 - ETA: 7s - loss: 1.087 - ETA: 6s - loss: 1.087 - ETA: 6s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 5s - loss: 1.086 - ETA: 4s - loss: 1.086 - ETA: 4s - loss: 1.086 - ETA: 3s - loss: 1.086 - ETA: 3s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 16s 898us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 85/100\n",
      "17621/17621 [==============================] - ETA: 15s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0877 - ETA: 9s - loss: 1.087 - ETA: 8s - loss: 1.087 - ETA: 8s - loss: 1.088 - ETA: 7s - loss: 1.089 - ETA: 7s - loss: 1.088 - ETA: 7s - loss: 1.088 - ETA: 6s - loss: 1.088 - ETA: 6s - loss: 1.088 - ETA: 5s - loss: 1.088 - ETA: 5s - loss: 1.088 - ETA: 4s - loss: 1.088 - ETA: 4s - loss: 1.088 - ETA: 4s - loss: 1.088 - ETA: 3s - loss: 1.088 - ETA: 3s - loss: 1.088 - ETA: 2s - loss: 1.088 - ETA: 2s - loss: 1.088 - ETA: 1s - loss: 1.088 - ETA: 1s - loss: 1.088 - ETA: 1s - loss: 1.088 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 16s 882us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 86/100\n",
      "17621/17621 [==============================] - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0882 - ETA: 9s - loss: 1.088 - ETA: 8s - loss: 1.088 - ETA: 8s - loss: 1.088 - ETA: 7s - loss: 1.088 - ETA: 7s - loss: 1.088 - ETA: 7s - loss: 1.088 - ETA: 6s - loss: 1.088 - ETA: 6s - loss: 1.088 - ETA: 5s - loss: 1.088 - ETA: 5s - loss: 1.088 - ETA: 4s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 4s - loss: 1.088 - ETA: 3s - loss: 1.088 - ETA: 3s - loss: 1.088 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 16s 885us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 87/100\n",
      "17621/17621 [==============================] - ETA: 14s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 13s - loss: 1.09 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0878 - ETA: 9s - loss: 1.087 - ETA: 8s - loss: 1.088 - ETA: 8s - loss: 1.088 - ETA: 8s - loss: 1.088 - ETA: 7s - loss: 1.087 - ETA: 7s - loss: 1.087 - ETA: 6s - loss: 1.088 - ETA: 6s - loss: 1.088 - ETA: 5s - loss: 1.088 - ETA: 5s - loss: 1.088 - ETA: 4s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 4s - loss: 1.088 - ETA: 3s - loss: 1.088 - ETA: 3s - loss: 1.088 - ETA: 2s - loss: 1.088 - ETA: 2s - loss: 1.088 - ETA: 1s - loss: 1.088 - ETA: 1s - loss: 1.088 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 16s 891us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 88/100\n",
      "17621/17621 [==============================] - ETA: 13s - loss: 1.10 - ETA: 13s - loss: 1.09 - ETA: 13s - loss: 1.09 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.09 - ETA: 10s - loss: 1.09 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0884 - ETA: 9s - loss: 1.088 - ETA: 8s - loss: 1.088 - ETA: 8s - loss: 1.088 - ETA: 7s - loss: 1.087 - ETA: 7s - loss: 1.087 - ETA: 7s - loss: 1.087 - ETA: 6s - loss: 1.087 - ETA: 6s - loss: 1.087 - ETA: 5s - loss: 1.088 - ETA: 5s - loss: 1.088 - ETA: 4s - loss: 1.088 - ETA: 4s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 2s - loss: 1.088 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.088 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 16s 885us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17621/17621 [==============================] - ETA: 13s - loss: 1.10 - ETA: 13s - loss: 1.09 - ETA: 13s - loss: 1.09 - ETA: 13s - loss: 1.09 - ETA: 12s - loss: 1.09 - ETA: 12s - loss: 1.09 - ETA: 11s - loss: 1.09 - ETA: 11s - loss: 1.09 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.09 - ETA: 10s - loss: 1.09 - ETA: 9s - loss: 1.0895 - ETA: 9s - loss: 1.089 - ETA: 8s - loss: 1.089 - ETA: 8s - loss: 1.090 - ETA: 7s - loss: 1.089 - ETA: 7s - loss: 1.089 - ETA: 7s - loss: 1.088 - ETA: 6s - loss: 1.088 - ETA: 6s - loss: 1.088 - ETA: 5s - loss: 1.089 - ETA: 5s - loss: 1.088 - ETA: 4s - loss: 1.088 - ETA: 4s - loss: 1.088 - ETA: 4s - loss: 1.088 - ETA: 3s - loss: 1.088 - ETA: 3s - loss: 1.088 - ETA: 2s - loss: 1.088 - ETA: 2s - loss: 1.088 - ETA: 1s - loss: 1.088 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 16s 886us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 90/100\n",
      "17621/17621 [==============================] - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.07 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0870 - ETA: 9s - loss: 1.087 - ETA: 9s - loss: 1.087 - ETA: 8s - loss: 1.086 - ETA: 8s - loss: 1.087 - ETA: 7s - loss: 1.087 - ETA: 7s - loss: 1.086 - ETA: 7s - loss: 1.087 - ETA: 6s - loss: 1.087 - ETA: 6s - loss: 1.087 - ETA: 5s - loss: 1.086 - ETA: 5s - loss: 1.086 - ETA: 4s - loss: 1.086 - ETA: 4s - loss: 1.086 - ETA: 4s - loss: 1.086 - ETA: 3s - loss: 1.087 - ETA: 3s - loss: 1.086 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 16s 888us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 91/100\n",
      "17621/17621 [==============================] - ETA: 13s - loss: 1.09 - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0878 - ETA: 9s - loss: 1.088 - ETA: 8s - loss: 1.088 - ETA: 8s - loss: 1.087 - ETA: 7s - loss: 1.087 - ETA: 7s - loss: 1.088 - ETA: 7s - loss: 1.087 - ETA: 6s - loss: 1.087 - ETA: 6s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 4s - loss: 1.088 - ETA: 4s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 16s 887us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 92/100\n",
      "17621/17621 [==============================] - ETA: 14s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0874 - ETA: 9s - loss: 1.087 - ETA: 8s - loss: 1.087 - ETA: 8s - loss: 1.087 - ETA: 7s - loss: 1.086 - ETA: 7s - loss: 1.086 - ETA: 7s - loss: 1.087 - ETA: 6s - loss: 1.087 - ETA: 6s - loss: 1.086 - ETA: 5s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 4s - loss: 1.088 - ETA: 4s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 3s - loss: 1.088 - ETA: 2s - loss: 1.088 - ETA: 2s - loss: 1.088 - ETA: 1s - loss: 1.088 - ETA: 1s - loss: 1.088 - ETA: 1s - loss: 1.088 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 16s 893us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 93/100\n",
      "17621/17621 [==============================] - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.09 - ETA: 13s - loss: 1.09 - ETA: 13s - loss: 1.09 - ETA: 12s - loss: 1.09 - ETA: 12s - loss: 1.09 - ETA: 11s - loss: 1.09 - ETA: 11s - loss: 1.09 - ETA: 10s - loss: 1.09 - ETA: 10s - loss: 1.09 - ETA: 10s - loss: 1.09 - ETA: 9s - loss: 1.0903 - ETA: 9s - loss: 1.089 - ETA: 8s - loss: 1.089 - ETA: 8s - loss: 1.090 - ETA: 7s - loss: 1.089 - ETA: 7s - loss: 1.089 - ETA: 7s - loss: 1.089 - ETA: 6s - loss: 1.089 - ETA: 6s - loss: 1.089 - ETA: 5s - loss: 1.089 - ETA: 5s - loss: 1.089 - ETA: 4s - loss: 1.088 - ETA: 4s - loss: 1.088 - ETA: 4s - loss: 1.088 - ETA: 3s - loss: 1.088 - ETA: 3s - loss: 1.088 - ETA: 2s - loss: 1.088 - ETA: 2s - loss: 1.088 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 16s 902us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 94/100\n",
      "17621/17621 [==============================] - ETA: 17s - loss: 1.08 - ETA: 16s - loss: 1.08 - ETA: 16s - loss: 1.08 - ETA: 15s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0855 - ETA: 9s - loss: 1.085 - ETA: 8s - loss: 1.086 - ETA: 8s - loss: 1.086 - ETA: 7s - loss: 1.086 - ETA: 7s - loss: 1.087 - ETA: 6s - loss: 1.086 - ETA: 6s - loss: 1.086 - ETA: 5s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 16s 919us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 95/100\n",
      "17621/17621 [==============================] - ETA: 14s - loss: 1.07 - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0861 - ETA: 9s - loss: 1.086 - ETA: 8s - loss: 1.086 - ETA: 8s - loss: 1.086 - ETA: 7s - loss: 1.087 - ETA: 7s - loss: 1.086 - ETA: 6s - loss: 1.087 - ETA: 6s - loss: 1.087 - ETA: 6s - loss: 1.087 - ETA: 5s - loss: 1.088 - ETA: 5s - loss: 1.088 - ETA: 4s - loss: 1.088 - ETA: 4s - loss: 1.088 - ETA: 3s - loss: 1.088 - ETA: 3s - loss: 1.088 - ETA: 2s - loss: 1.088 - ETA: 2s - loss: 1.088 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.088 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 16s 909us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 96/100\n",
      "17621/17621 [==============================] - ETA: 14s - loss: 1.09 - ETA: 13s - loss: 1.09 - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0873 - ETA: 9s - loss: 1.087 - ETA: 8s - loss: 1.086 - ETA: 8s - loss: 1.086 - ETA: 8s - loss: 1.086 - ETA: 7s - loss: 1.086 - ETA: 7s - loss: 1.086 - ETA: 6s - loss: 1.086 - ETA: 6s - loss: 1.085 - ETA: 5s - loss: 1.086 - ETA: 5s - loss: 1.086 - ETA: 4s - loss: 1.086 - ETA: 4s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 16s 895us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17621/17621 [==============================] - ETA: 14s - loss: 1.09 - ETA: 13s - loss: 1.09 - ETA: 13s - loss: 1.09 - ETA: 12s - loss: 1.09 - ETA: 12s - loss: 1.09 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0886 - ETA: 9s - loss: 1.088 - ETA: 8s - loss: 1.088 - ETA: 8s - loss: 1.088 - ETA: 7s - loss: 1.088 - ETA: 7s - loss: 1.088 - ETA: 7s - loss: 1.088 - ETA: 6s - loss: 1.088 - ETA: 6s - loss: 1.088 - ETA: 5s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 4s - loss: 1.086 - ETA: 3s - loss: 1.086 - ETA: 3s - loss: 1.086 - ETA: 2s - loss: 1.086 - ETA: 2s - loss: 1.086 - ETA: 1s - loss: 1.086 - ETA: 1s - loss: 1.086 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 16s 888us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 98/100\n",
      "17621/17621 [==============================] - ETA: 13s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0863 - ETA: 9s - loss: 1.086 - ETA: 8s - loss: 1.086 - ETA: 8s - loss: 1.085 - ETA: 7s - loss: 1.085 - ETA: 7s - loss: 1.086 - ETA: 7s - loss: 1.085 - ETA: 6s - loss: 1.086 - ETA: 6s - loss: 1.086 - ETA: 5s - loss: 1.086 - ETA: 5s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 4s - loss: 1.086 - ETA: 3s - loss: 1.086 - ETA: 3s - loss: 1.086 - ETA: 2s - loss: 1.086 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 16s 892us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 99/100\n",
      "17621/17621 [==============================] - ETA: 13s - loss: 1.10 - ETA: 13s - loss: 1.09 - ETA: 13s - loss: 1.09 - ETA: 13s - loss: 1.09 - ETA: 12s - loss: 1.09 - ETA: 12s - loss: 1.09 - ETA: 12s - loss: 1.09 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0872 - ETA: 9s - loss: 1.086 - ETA: 9s - loss: 1.086 - ETA: 8s - loss: 1.086 - ETA: 8s - loss: 1.086 - ETA: 7s - loss: 1.086 - ETA: 7s - loss: 1.086 - ETA: 6s - loss: 1.087 - ETA: 6s - loss: 1.086 - ETA: 5s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 16s 914us/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 100/100\n",
      "17621/17621 [==============================] - ETA: 14s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0857 - ETA: 9s - loss: 1.086 - ETA: 8s - loss: 1.086 - ETA: 8s - loss: 1.087 - ETA: 8s - loss: 1.087 - ETA: 7s - loss: 1.087 - ETA: 7s - loss: 1.087 - ETA: 6s - loss: 1.087 - ETA: 6s - loss: 1.088 - ETA: 5s - loss: 1.088 - ETA: 5s - loss: 1.088 - ETA: 5s - loss: 1.088 - ETA: 4s - loss: 1.088 - ETA: 4s - loss: 1.088 - ETA: 3s - loss: 1.088 - ETA: 3s - loss: 1.088 - ETA: 2s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - ETA: 0s - loss: 1.087 - 16s 888us/step - loss: 1.0875 - val_loss: 1.0875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xf02b32b0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xtrain_pad, y=ytrain_enc, batch_size=512, epochs=100, verbose=1, validation_data=(xvalid_pad, yvalid_enc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17621 samples, validate on 1958 samples\n",
      "Epoch 1/100\n",
      "17621/17621 [==============================] - ETA: 2:14 - loss: 1.098 - ETA: 1:25 - loss: 1.098 - ETA: 1:07 - loss: 1.098 - ETA: 57s - loss: 1.098 - ETA: 51s - loss: 1.09 - ETA: 47s - loss: 1.09 - ETA: 43s - loss: 1.09 - ETA: 40s - loss: 1.09 - ETA: 37s - loss: 1.09 - ETA: 35s - loss: 1.09 - ETA: 33s - loss: 1.09 - ETA: 31s - loss: 1.09 - ETA: 29s - loss: 1.09 - ETA: 28s - loss: 1.09 - ETA: 27s - loss: 1.09 - ETA: 25s - loss: 1.09 - ETA: 24s - loss: 1.09 - ETA: 22s - loss: 1.09 - ETA: 20s - loss: 1.09 - ETA: 19s - loss: 1.09 - ETA: 18s - loss: 1.09 - ETA: 16s - loss: 1.09 - ETA: 15s - loss: 1.09 - ETA: 13s - loss: 1.09 - ETA: 12s - loss: 1.09 - ETA: 11s - loss: 1.09 - ETA: 9s - loss: 1.0971 - ETA: 8s - loss: 1.097 - ETA: 6s - loss: 1.097 - ETA: 5s - loss: 1.097 - ETA: 4s - loss: 1.096 - ETA: 3s - loss: 1.096 - ETA: 1s - loss: 1.096 - ETA: 0s - loss: 1.096 - 46s 3ms/step - loss: 1.0966 - val_loss: 1.0947\n",
      "Epoch 2/100\n",
      "17621/17621 [==============================] - ETA: 39s - loss: 1.09 - ETA: 37s - loss: 1.09 - ETA: 36s - loss: 1.09 - ETA: 35s - loss: 1.09 - ETA: 33s - loss: 1.09 - ETA: 32s - loss: 1.09 - ETA: 31s - loss: 1.09 - ETA: 31s - loss: 1.09 - ETA: 30s - loss: 1.09 - ETA: 29s - loss: 1.09 - ETA: 28s - loss: 1.09 - ETA: 26s - loss: 1.09 - ETA: 25s - loss: 1.09 - ETA: 24s - loss: 1.09 - ETA: 23s - loss: 1.09 - ETA: 22s - loss: 1.09 - ETA: 20s - loss: 1.09 - ETA: 19s - loss: 1.09 - ETA: 18s - loss: 1.09 - ETA: 17s - loss: 1.09 - ETA: 15s - loss: 1.09 - ETA: 14s - loss: 1.09 - ETA: 13s - loss: 1.09 - ETA: 12s - loss: 1.09 - ETA: 11s - loss: 1.09 - ETA: 9s - loss: 1.0938 - ETA: 8s - loss: 1.093 - ETA: 7s - loss: 1.093 - ETA: 6s - loss: 1.093 - ETA: 5s - loss: 1.093 - ETA: 4s - loss: 1.093 - ETA: 2s - loss: 1.093 - ETA: 1s - loss: 1.093 - ETA: 0s - loss: 1.093 - 42s 2ms/step - loss: 1.0933 - val_loss: 1.0920\n",
      "Epoch 3/100\n",
      "17621/17621 [==============================] - ETA: 39s - loss: 1.09 - ETA: 37s - loss: 1.09 - ETA: 36s - loss: 1.09 - ETA: 35s - loss: 1.09 - ETA: 33s - loss: 1.09 - ETA: 32s - loss: 1.09 - ETA: 31s - loss: 1.09 - ETA: 30s - loss: 1.09 - ETA: 29s - loss: 1.09 - ETA: 28s - loss: 1.09 - ETA: 27s - loss: 1.09 - ETA: 26s - loss: 1.09 - ETA: 25s - loss: 1.09 - ETA: 23s - loss: 1.09 - ETA: 22s - loss: 1.09 - ETA: 21s - loss: 1.09 - ETA: 20s - loss: 1.09 - ETA: 19s - loss: 1.09 - ETA: 17s - loss: 1.09 - ETA: 16s - loss: 1.09 - ETA: 15s - loss: 1.09 - ETA: 14s - loss: 1.09 - ETA: 13s - loss: 1.09 - ETA: 12s - loss: 1.09 - ETA: 10s - loss: 1.09 - ETA: 9s - loss: 1.0917 - ETA: 8s - loss: 1.091 - ETA: 7s - loss: 1.091 - ETA: 6s - loss: 1.091 - ETA: 5s - loss: 1.091 - ETA: 3s - loss: 1.091 - ETA: 2s - loss: 1.090 - ETA: 1s - loss: 1.091 - ETA: 0s - loss: 1.091 - 42s 2ms/step - loss: 1.0910 - val_loss: 1.0902\n",
      "Epoch 4/100\n",
      "17621/17621 [==============================] - ETA: 37s - loss: 1.09 - ETA: 40s - loss: 1.09 - ETA: 38s - loss: 1.09 - ETA: 36s - loss: 1.09 - ETA: 35s - loss: 1.08 - ETA: 33s - loss: 1.08 - ETA: 32s - loss: 1.08 - ETA: 31s - loss: 1.08 - ETA: 30s - loss: 1.08 - ETA: 29s - loss: 1.08 - ETA: 27s - loss: 1.08 - ETA: 26s - loss: 1.08 - ETA: 25s - loss: 1.08 - ETA: 24s - loss: 1.08 - ETA: 23s - loss: 1.08 - ETA: 22s - loss: 1.08 - ETA: 21s - loss: 1.08 - ETA: 20s - loss: 1.08 - ETA: 18s - loss: 1.08 - ETA: 17s - loss: 1.08 - ETA: 16s - loss: 1.08 - ETA: 15s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0896 - ETA: 7s - loss: 1.089 - ETA: 6s - loss: 1.089 - ETA: 5s - loss: 1.089 - ETA: 4s - loss: 1.089 - ETA: 2s - loss: 1.089 - ETA: 1s - loss: 1.089 - ETA: 0s - loss: 1.089 - 43s 2ms/step - loss: 1.0896 - val_loss: 1.0890\n",
      "Epoch 5/100\n",
      "17621/17621 [==============================] - ETA: 37s - loss: 1.08 - ETA: 36s - loss: 1.08 - ETA: 35s - loss: 1.08 - ETA: 34s - loss: 1.08 - ETA: 34s - loss: 1.08 - ETA: 33s - loss: 1.08 - ETA: 32s - loss: 1.08 - ETA: 31s - loss: 1.08 - ETA: 30s - loss: 1.08 - ETA: 28s - loss: 1.08 - ETA: 27s - loss: 1.08 - ETA: 26s - loss: 1.08 - ETA: 25s - loss: 1.08 - ETA: 24s - loss: 1.08 - ETA: 23s - loss: 1.08 - ETA: 22s - loss: 1.08 - ETA: 21s - loss: 1.08 - ETA: 19s - loss: 1.09 - ETA: 18s - loss: 1.08 - ETA: 17s - loss: 1.08 - ETA: 16s - loss: 1.08 - ETA: 15s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0889 - ETA: 7s - loss: 1.088 - ETA: 6s - loss: 1.088 - ETA: 5s - loss: 1.089 - ETA: 4s - loss: 1.089 - ETA: 2s - loss: 1.088 - ETA: 1s - loss: 1.088 - ETA: 0s - loss: 1.088 - 43s 2ms/step - loss: 1.0887 - val_loss: 1.0884\n",
      "Epoch 6/100\n",
      "17621/17621 [==============================] - ETA: 36s - loss: 1.08 - ETA: 35s - loss: 1.08 - ETA: 34s - loss: 1.08 - ETA: 33s - loss: 1.08 - ETA: 32s - loss: 1.08 - ETA: 30s - loss: 1.08 - ETA: 29s - loss: 1.08 - ETA: 28s - loss: 1.08 - ETA: 27s - loss: 1.08 - ETA: 26s - loss: 1.08 - ETA: 25s - loss: 1.08 - ETA: 24s - loss: 1.08 - ETA: 23s - loss: 1.08 - ETA: 22s - loss: 1.08 - ETA: 22s - loss: 1.08 - ETA: 21s - loss: 1.08 - ETA: 20s - loss: 1.08 - ETA: 19s - loss: 1.08 - ETA: 17s - loss: 1.08 - ETA: 16s - loss: 1.08 - ETA: 15s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0873 - ETA: 8s - loss: 1.087 - ETA: 7s - loss: 1.087 - ETA: 6s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 2s - loss: 1.088 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.088 - 44s 2ms/step - loss: 1.0881 - val_loss: 1.0879\n",
      "Epoch 7/100\n",
      "17621/17621 [==============================] - ETA: 39s - loss: 1.08 - ETA: 51s - loss: 1.08 - ETA: 46s - loss: 1.08 - ETA: 42s - loss: 1.08 - ETA: 39s - loss: 1.08 - ETA: 39s - loss: 1.08 - ETA: 38s - loss: 1.08 - ETA: 35s - loss: 1.08 - ETA: 34s - loss: 1.08 - ETA: 32s - loss: 1.08 - ETA: 30s - loss: 1.08 - ETA: 29s - loss: 1.08 - ETA: 27s - loss: 1.08 - ETA: 26s - loss: 1.08 - ETA: 25s - loss: 1.08 - ETA: 23s - loss: 1.08 - ETA: 22s - loss: 1.08 - ETA: 21s - loss: 1.08 - ETA: 19s - loss: 1.08 - ETA: 18s - loss: 1.08 - ETA: 17s - loss: 1.08 - ETA: 16s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0877 - ETA: 8s - loss: 1.088 - ETA: 6s - loss: 1.088 - ETA: 5s - loss: 1.088 - ETA: 4s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - 46s 3ms/step - loss: 1.0878 - val_loss: 1.0877\n",
      "Epoch 8/100\n",
      "17621/17621 [==============================] - ETA: 1:04 - loss: 1.096 - ETA: 57s - loss: 1.092 - ETA: 54s - loss: 1.09 - ETA: 49s - loss: 1.09 - ETA: 44s - loss: 1.09 - ETA: 41s - loss: 1.09 - ETA: 38s - loss: 1.09 - ETA: 36s - loss: 1.08 - ETA: 34s - loss: 1.08 - ETA: 32s - loss: 1.08 - ETA: 30s - loss: 1.08 - ETA: 28s - loss: 1.08 - ETA: 27s - loss: 1.08 - ETA: 25s - loss: 1.08 - ETA: 24s - loss: 1.08 - ETA: 22s - loss: 1.08 - ETA: 21s - loss: 1.08 - ETA: 20s - loss: 1.08 - ETA: 18s - loss: 1.08 - ETA: 17s - loss: 1.08 - ETA: 16s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 9s - loss: 1.0880 - ETA: 8s - loss: 1.087 - ETA: 7s - loss: 1.087 - ETA: 6s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - 42s 2ms/step - loss: 1.0877 - val_loss: 1.0876\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17621/17621 [==============================] - ETA: 40s - loss: 1.08 - ETA: 38s - loss: 1.08 - ETA: 35s - loss: 1.08 - ETA: 35s - loss: 1.08 - ETA: 33s - loss: 1.08 - ETA: 32s - loss: 1.08 - ETA: 31s - loss: 1.08 - ETA: 29s - loss: 1.08 - ETA: 28s - loss: 1.08 - ETA: 27s - loss: 1.08 - ETA: 26s - loss: 1.08 - ETA: 25s - loss: 1.08 - ETA: 23s - loss: 1.08 - ETA: 22s - loss: 1.08 - ETA: 21s - loss: 1.08 - ETA: 20s - loss: 1.08 - ETA: 19s - loss: 1.08 - ETA: 18s - loss: 1.08 - ETA: 17s - loss: 1.08 - ETA: 16s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0884 - ETA: 8s - loss: 1.088 - ETA: 7s - loss: 1.088 - ETA: 6s - loss: 1.088 - ETA: 4s - loss: 1.088 - ETA: 3s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - 40s 2ms/step - loss: 1.0876 - val_loss: 1.0876\n",
      "Epoch 10/100\n",
      "17621/17621 [==============================] - ETA: 1:05 - loss: 1.082 - ETA: 51s - loss: 1.089 - ETA: 44s - loss: 1.09 - ETA: 40s - loss: 1.09 - ETA: 38s - loss: 1.08 - ETA: 36s - loss: 1.08 - ETA: 34s - loss: 1.08 - ETA: 32s - loss: 1.08 - ETA: 31s - loss: 1.08 - ETA: 33s - loss: 1.08 - ETA: 31s - loss: 1.08 - ETA: 30s - loss: 1.08 - ETA: 29s - loss: 1.08 - ETA: 27s - loss: 1.08 - ETA: 26s - loss: 1.08 - ETA: 25s - loss: 1.08 - ETA: 23s - loss: 1.08 - ETA: 22s - loss: 1.08 - ETA: 20s - loss: 1.08 - ETA: 19s - loss: 1.08 - ETA: 17s - loss: 1.08 - ETA: 16s - loss: 1.08 - ETA: 15s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 9s - loss: 1.0877 - ETA: 8s - loss: 1.087 - ETA: 7s - loss: 1.087 - ETA: 5s - loss: 1.088 - ETA: 4s - loss: 1.088 - ETA: 3s - loss: 1.088 - ETA: 1s - loss: 1.088 - ETA: 0s - loss: 1.087 - 48s 3ms/step - loss: 1.0876 - val_loss: 1.0876\n",
      "Epoch 11/100\n",
      "17621/17621 [==============================] - ETA: 37s - loss: 1.08 - ETA: 36s - loss: 1.08 - ETA: 36s - loss: 1.08 - ETA: 34s - loss: 1.08 - ETA: 33s - loss: 1.08 - ETA: 32s - loss: 1.08 - ETA: 30s - loss: 1.08 - ETA: 29s - loss: 1.08 - ETA: 28s - loss: 1.08 - ETA: 27s - loss: 1.08 - ETA: 25s - loss: 1.08 - ETA: 24s - loss: 1.08 - ETA: 23s - loss: 1.08 - ETA: 22s - loss: 1.08 - ETA: 21s - loss: 1.08 - ETA: 20s - loss: 1.08 - ETA: 19s - loss: 1.08 - ETA: 18s - loss: 1.08 - ETA: 16s - loss: 1.08 - ETA: 15s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0873 - ETA: 8s - loss: 1.087 - ETA: 7s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - 40s 2ms/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 12/100\n",
      "17621/17621 [==============================] - ETA: 43s - loss: 1.08 - ETA: 39s - loss: 1.08 - ETA: 38s - loss: 1.08 - ETA: 36s - loss: 1.08 - ETA: 34s - loss: 1.08 - ETA: 33s - loss: 1.08 - ETA: 32s - loss: 1.08 - ETA: 32s - loss: 1.08 - ETA: 31s - loss: 1.08 - ETA: 29s - loss: 1.08 - ETA: 28s - loss: 1.08 - ETA: 26s - loss: 1.08 - ETA: 25s - loss: 1.08 - ETA: 24s - loss: 1.08 - ETA: 22s - loss: 1.08 - ETA: 21s - loss: 1.08 - ETA: 20s - loss: 1.08 - ETA: 19s - loss: 1.08 - ETA: 17s - loss: 1.08 - ETA: 16s - loss: 1.08 - ETA: 15s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0873 - ETA: 8s - loss: 1.087 - ETA: 7s - loss: 1.087 - ETA: 6s - loss: 1.087 - ETA: 5s - loss: 1.088 - ETA: 3s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - 41s 2ms/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 13/100\n",
      "17621/17621 [==============================] - ETA: 37s - loss: 1.08 - ETA: 36s - loss: 1.08 - ETA: 35s - loss: 1.08 - ETA: 33s - loss: 1.08 - ETA: 33s - loss: 1.08 - ETA: 32s - loss: 1.08 - ETA: 30s - loss: 1.08 - ETA: 29s - loss: 1.08 - ETA: 28s - loss: 1.08 - ETA: 27s - loss: 1.08 - ETA: 26s - loss: 1.08 - ETA: 25s - loss: 1.08 - ETA: 24s - loss: 1.08 - ETA: 23s - loss: 1.08 - ETA: 21s - loss: 1.08 - ETA: 20s - loss: 1.08 - ETA: 19s - loss: 1.08 - ETA: 18s - loss: 1.08 - ETA: 17s - loss: 1.08 - ETA: 16s - loss: 1.08 - ETA: 15s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0878 - ETA: 8s - loss: 1.087 - ETA: 7s - loss: 1.087 - ETA: 6s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - 40s 2ms/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 14/100\n",
      "17621/17621 [==============================] - ETA: 39s - loss: 1.08 - ETA: 37s - loss: 1.08 - ETA: 35s - loss: 1.08 - ETA: 34s - loss: 1.08 - ETA: 32s - loss: 1.08 - ETA: 31s - loss: 1.09 - ETA: 30s - loss: 1.09 - ETA: 29s - loss: 1.09 - ETA: 28s - loss: 1.09 - ETA: 27s - loss: 1.09 - ETA: 26s - loss: 1.08 - ETA: 25s - loss: 1.08 - ETA: 24s - loss: 1.08 - ETA: 22s - loss: 1.08 - ETA: 21s - loss: 1.08 - ETA: 20s - loss: 1.08 - ETA: 19s - loss: 1.08 - ETA: 18s - loss: 1.08 - ETA: 17s - loss: 1.08 - ETA: 16s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0877 - ETA: 8s - loss: 1.087 - ETA: 7s - loss: 1.087 - ETA: 6s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - 41s 2ms/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 15/100\n",
      "17621/17621 [==============================] - ETA: 36s - loss: 1.08 - ETA: 35s - loss: 1.08 - ETA: 34s - loss: 1.08 - ETA: 33s - loss: 1.08 - ETA: 32s - loss: 1.09 - ETA: 30s - loss: 1.09 - ETA: 29s - loss: 1.09 - ETA: 28s - loss: 1.09 - ETA: 27s - loss: 1.09 - ETA: 26s - loss: 1.09 - ETA: 25s - loss: 1.09 - ETA: 24s - loss: 1.09 - ETA: 23s - loss: 1.08 - ETA: 22s - loss: 1.08 - ETA: 21s - loss: 1.08 - ETA: 20s - loss: 1.08 - ETA: 19s - loss: 1.08 - ETA: 17s - loss: 1.08 - ETA: 16s - loss: 1.08 - ETA: 15s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0886 - ETA: 8s - loss: 1.088 - ETA: 7s - loss: 1.088 - ETA: 5s - loss: 1.088 - ETA: 4s - loss: 1.088 - ETA: 3s - loss: 1.088 - ETA: 2s - loss: 1.088 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - 40s 2ms/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 16/100\n",
      "17621/17621 [==============================] - ETA: 40s - loss: 1.08 - ETA: 39s - loss: 1.08 - ETA: 36s - loss: 1.08 - ETA: 35s - loss: 1.08 - ETA: 34s - loss: 1.08 - ETA: 33s - loss: 1.09 - ETA: 34s - loss: 1.08 - ETA: 32s - loss: 1.08 - ETA: 31s - loss: 1.08 - ETA: 29s - loss: 1.08 - ETA: 28s - loss: 1.08 - ETA: 26s - loss: 1.08 - ETA: 25s - loss: 1.08 - ETA: 24s - loss: 1.08 - ETA: 22s - loss: 1.08 - ETA: 21s - loss: 1.08 - ETA: 20s - loss: 1.08 - ETA: 19s - loss: 1.08 - ETA: 18s - loss: 1.08 - ETA: 16s - loss: 1.08 - ETA: 15s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0874 - ETA: 8s - loss: 1.087 - ETA: 7s - loss: 1.087 - ETA: 6s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - 41s 2ms/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17621/17621 [==============================] - ETA: 36s - loss: 1.09 - ETA: 35s - loss: 1.09 - ETA: 34s - loss: 1.09 - ETA: 33s - loss: 1.09 - ETA: 32s - loss: 1.09 - ETA: 31s - loss: 1.08 - ETA: 30s - loss: 1.08 - ETA: 29s - loss: 1.08 - ETA: 28s - loss: 1.08 - ETA: 26s - loss: 1.08 - ETA: 25s - loss: 1.08 - ETA: 24s - loss: 1.08 - ETA: 23s - loss: 1.08 - ETA: 22s - loss: 1.08 - ETA: 21s - loss: 1.08 - ETA: 20s - loss: 1.08 - ETA: 19s - loss: 1.08 - ETA: 18s - loss: 1.08 - ETA: 16s - loss: 1.08 - ETA: 16s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 9s - loss: 1.0874 - ETA: 8s - loss: 1.087 - ETA: 7s - loss: 1.087 - ETA: 6s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 1s - loss: 1.087 - ETA: 0s - loss: 1.087 - 42s 2ms/step - loss: 1.0875 - val_loss: 1.0875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x106e5af98>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A simple LSTM with glove embeddings and two dense layers\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(word_index) + 1,\n",
    "                     300,\n",
    "                     weights=[embedding_matrix],\n",
    "                     input_length=max_len,\n",
    "                     trainable=False))\n",
    "model.add(SpatialDropout1D(0.3))\n",
    "model.add(LSTM(300, dropout=0.3, recurrent_dropout=0.3))\n",
    "\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.8))\n",
    "\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.8))\n",
    "\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "# Fit the model with early stopping callback\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
    "model.fit(xtrain_pad, y=ytrain_enc, batch_size=512, epochs=100, \n",
    "          verbose=1, validation_data=(xvalid_pad, yvalid_enc), callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17621 samples, validate on 1958 samples\n",
      "Epoch 1/100\n",
      "17621/17621 [==============================] - ETA: 4:45 - loss: 1.098 - ETA: 3:17 - loss: 1.098 - ETA: 2:38 - loss: 1.098 - ETA: 2:12 - loss: 1.098 - ETA: 1:56 - loss: 1.098 - ETA: 1:44 - loss: 1.098 - ETA: 1:34 - loss: 1.098 - ETA: 1:26 - loss: 1.098 - ETA: 1:20 - loss: 1.098 - ETA: 1:15 - loss: 1.098 - ETA: 1:10 - loss: 1.097 - ETA: 1:06 - loss: 1.097 - ETA: 1:02 - loss: 1.097 - ETA: 58s - loss: 1.097 - ETA: 55s - loss: 1.09 - ETA: 51s - loss: 1.09 - ETA: 48s - loss: 1.09 - ETA: 45s - loss: 1.09 - ETA: 41s - loss: 1.09 - ETA: 38s - loss: 1.09 - ETA: 35s - loss: 1.09 - ETA: 32s - loss: 1.09 - ETA: 29s - loss: 1.09 - ETA: 27s - loss: 1.09 - ETA: 24s - loss: 1.09 - ETA: 21s - loss: 1.09 - ETA: 18s - loss: 1.09 - ETA: 16s - loss: 1.09 - ETA: 13s - loss: 1.09 - ETA: 11s - loss: 1.09 - ETA: 8s - loss: 1.0968 - ETA: 6s - loss: 1.096 - ETA: 3s - loss: 1.096 - ETA: 1s - loss: 1.096 - 89s 5ms/step - loss: 1.0966 - val_loss: 1.0946\n",
      "Epoch 2/100\n",
      "17621/17621 [==============================] - ETA: 1:12 - loss: 1.095 - ETA: 1:10 - loss: 1.095 - ETA: 1:07 - loss: 1.094 - ETA: 1:05 - loss: 1.094 - ETA: 1:03 - loss: 1.094 - ETA: 1:01 - loss: 1.094 - ETA: 59s - loss: 1.094 - ETA: 57s - loss: 1.09 - ETA: 54s - loss: 1.09 - ETA: 52s - loss: 1.09 - ETA: 50s - loss: 1.09 - ETA: 48s - loss: 1.09 - ETA: 46s - loss: 1.09 - ETA: 44s - loss: 1.09 - ETA: 42s - loss: 1.09 - ETA: 39s - loss: 1.09 - ETA: 37s - loss: 1.09 - ETA: 35s - loss: 1.09 - ETA: 33s - loss: 1.09 - ETA: 31s - loss: 1.09 - ETA: 29s - loss: 1.09 - ETA: 27s - loss: 1.09 - ETA: 25s - loss: 1.09 - ETA: 23s - loss: 1.09 - ETA: 20s - loss: 1.09 - ETA: 18s - loss: 1.09 - ETA: 16s - loss: 1.09 - ETA: 14s - loss: 1.09 - ETA: 11s - loss: 1.09 - ETA: 9s - loss: 1.0934 - ETA: 7s - loss: 1.093 - ETA: 5s - loss: 1.093 - ETA: 3s - loss: 1.093 - ETA: 0s - loss: 1.093 - 79s 4ms/step - loss: 1.0933 - val_loss: 1.0918\n",
      "Epoch 3/100\n",
      "17621/17621 [==============================] - ETA: 1:13 - loss: 1.093 - ETA: 1:10 - loss: 1.092 - ETA: 1:08 - loss: 1.092 - ETA: 1:06 - loss: 1.092 - ETA: 1:03 - loss: 1.092 - ETA: 1:01 - loss: 1.091 - ETA: 59s - loss: 1.091 - ETA: 57s - loss: 1.09 - ETA: 55s - loss: 1.09 - ETA: 53s - loss: 1.09 - ETA: 51s - loss: 1.09 - ETA: 48s - loss: 1.09 - ETA: 46s - loss: 1.09 - ETA: 44s - loss: 1.09 - ETA: 42s - loss: 1.09 - ETA: 40s - loss: 1.09 - ETA: 37s - loss: 1.09 - ETA: 35s - loss: 1.09 - ETA: 33s - loss: 1.09 - ETA: 31s - loss: 1.09 - ETA: 29s - loss: 1.09 - ETA: 26s - loss: 1.09 - ETA: 24s - loss: 1.09 - ETA: 22s - loss: 1.09 - ETA: 20s - loss: 1.09 - ETA: 18s - loss: 1.09 - ETA: 16s - loss: 1.09 - ETA: 13s - loss: 1.09 - ETA: 11s - loss: 1.09 - ETA: 9s - loss: 1.0911 - ETA: 7s - loss: 1.091 - ETA: 5s - loss: 1.090 - ETA: 3s - loss: 1.090 - ETA: 0s - loss: 1.090 - 78s 4ms/step - loss: 1.0909 - val_loss: 1.0900\n",
      "Epoch 4/100\n",
      "17621/17621 [==============================] - ETA: 1:13 - loss: 1.088 - ETA: 1:11 - loss: 1.090 - ETA: 1:08 - loss: 1.088 - ETA: 1:05 - loss: 1.088 - ETA: 1:03 - loss: 1.089 - ETA: 1:01 - loss: 1.089 - ETA: 59s - loss: 1.089 - ETA: 57s - loss: 1.09 - ETA: 55s - loss: 1.09 - ETA: 52s - loss: 1.09 - ETA: 50s - loss: 1.09 - ETA: 48s - loss: 1.09 - ETA: 46s - loss: 1.09 - ETA: 44s - loss: 1.09 - ETA: 42s - loss: 1.08 - ETA: 39s - loss: 1.08 - ETA: 37s - loss: 1.08 - ETA: 35s - loss: 1.08 - ETA: 33s - loss: 1.08 - ETA: 31s - loss: 1.08 - ETA: 29s - loss: 1.08 - ETA: 26s - loss: 1.09 - ETA: 24s - loss: 1.08 - ETA: 22s - loss: 1.08 - ETA: 20s - loss: 1.08 - ETA: 18s - loss: 1.08 - ETA: 16s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 9s - loss: 1.0893 - ETA: 7s - loss: 1.089 - ETA: 5s - loss: 1.089 - ETA: 3s - loss: 1.089 - ETA: 0s - loss: 1.089 - 78s 4ms/step - loss: 1.0895 - val_loss: 1.0889\n",
      "Epoch 5/100\n",
      "17621/17621 [==============================] - ETA: 1:12 - loss: 1.098 - ETA: 1:10 - loss: 1.091 - ETA: 1:07 - loss: 1.087 - ETA: 1:05 - loss: 1.088 - ETA: 1:03 - loss: 1.089 - ETA: 1:01 - loss: 1.089 - ETA: 59s - loss: 1.089 - ETA: 56s - loss: 1.09 - ETA: 54s - loss: 1.09 - ETA: 52s - loss: 1.09 - ETA: 50s - loss: 1.09 - ETA: 48s - loss: 1.09 - ETA: 46s - loss: 1.08 - ETA: 44s - loss: 1.08 - ETA: 41s - loss: 1.08 - ETA: 39s - loss: 1.08 - ETA: 37s - loss: 1.08 - ETA: 35s - loss: 1.08 - ETA: 33s - loss: 1.08 - ETA: 31s - loss: 1.08 - ETA: 29s - loss: 1.08 - ETA: 26s - loss: 1.08 - ETA: 24s - loss: 1.08 - ETA: 22s - loss: 1.08 - ETA: 20s - loss: 1.08 - ETA: 18s - loss: 1.08 - ETA: 16s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 9s - loss: 1.0887 - ETA: 7s - loss: 1.088 - ETA: 5s - loss: 1.088 - ETA: 3s - loss: 1.088 - ETA: 0s - loss: 1.088 - 78s 4ms/step - loss: 1.0886 - val_loss: 1.0883\n",
      "Epoch 6/100\n",
      "17621/17621 [==============================] - ETA: 1:11 - loss: 1.089 - ETA: 1:10 - loss: 1.086 - ETA: 1:08 - loss: 1.089 - ETA: 1:05 - loss: 1.089 - ETA: 1:03 - loss: 1.089 - ETA: 1:01 - loss: 1.089 - ETA: 59s - loss: 1.088 - ETA: 57s - loss: 1.08 - ETA: 55s - loss: 1.08 - ETA: 52s - loss: 1.08 - ETA: 50s - loss: 1.08 - ETA: 48s - loss: 1.08 - ETA: 46s - loss: 1.08 - ETA: 44s - loss: 1.08 - ETA: 42s - loss: 1.08 - ETA: 40s - loss: 1.08 - ETA: 38s - loss: 1.08 - ETA: 35s - loss: 1.08 - ETA: 33s - loss: 1.08 - ETA: 31s - loss: 1.08 - ETA: 29s - loss: 1.08 - ETA: 27s - loss: 1.08 - ETA: 24s - loss: 1.08 - ETA: 22s - loss: 1.08 - ETA: 20s - loss: 1.08 - ETA: 18s - loss: 1.08 - ETA: 16s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 9s - loss: 1.0884 - ETA: 7s - loss: 1.088 - ETA: 5s - loss: 1.088 - ETA: 3s - loss: 1.088 - ETA: 0s - loss: 1.088 - 79s 4ms/step - loss: 1.0881 - val_loss: 1.0879\n",
      "Epoch 7/100\n",
      "17621/17621 [==============================] - ETA: 1:13 - loss: 1.089 - ETA: 1:10 - loss: 1.087 - ETA: 1:08 - loss: 1.085 - ETA: 1:06 - loss: 1.086 - ETA: 1:03 - loss: 1.086 - ETA: 1:01 - loss: 1.086 - ETA: 59s - loss: 1.085 - ETA: 57s - loss: 1.08 - ETA: 55s - loss: 1.08 - ETA: 52s - loss: 1.08 - ETA: 50s - loss: 1.08 - ETA: 48s - loss: 1.08 - ETA: 46s - loss: 1.08 - ETA: 44s - loss: 1.08 - ETA: 42s - loss: 1.08 - ETA: 39s - loss: 1.08 - ETA: 37s - loss: 1.08 - ETA: 35s - loss: 1.08 - ETA: 33s - loss: 1.08 - ETA: 31s - loss: 1.08 - ETA: 29s - loss: 1.08 - ETA: 26s - loss: 1.08 - ETA: 24s - loss: 1.08 - ETA: 22s - loss: 1.08 - ETA: 20s - loss: 1.08 - ETA: 18s - loss: 1.08 - ETA: 16s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 9s - loss: 1.0881 - ETA: 7s - loss: 1.088 - ETA: 5s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 0s - loss: 1.087 - 78s 4ms/step - loss: 1.0878 - val_loss: 1.0877\n",
      "Epoch 8/100\n",
      "17621/17621 [==============================] - ETA: 1:13 - loss: 1.073 - ETA: 1:11 - loss: 1.082 - ETA: 1:09 - loss: 1.084 - ETA: 1:06 - loss: 1.086 - ETA: 1:04 - loss: 1.087 - ETA: 1:01 - loss: 1.088 - ETA: 59s - loss: 1.087 - ETA: 57s - loss: 1.08 - ETA: 55s - loss: 1.09 - ETA: 53s - loss: 1.09 - ETA: 50s - loss: 1.09 - ETA: 48s - loss: 1.09 - ETA: 46s - loss: 1.09 - ETA: 44s - loss: 1.09 - ETA: 42s - loss: 1.08 - ETA: 40s - loss: 1.08 - ETA: 38s - loss: 1.08 - ETA: 36s - loss: 1.08 - ETA: 33s - loss: 1.08 - ETA: 31s - loss: 1.08 - ETA: 29s - loss: 1.08 - ETA: 27s - loss: 1.08 - ETA: 25s - loss: 1.08 - ETA: 22s - loss: 1.08 - ETA: 20s - loss: 1.08 - ETA: 18s - loss: 1.08 - ETA: 16s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 9s - loss: 1.0881 - ETA: 7s - loss: 1.088 - ETA: 5s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 0s - loss: 1.087 - 80s 5ms/step - loss: 1.0877 - val_loss: 1.0876\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17621/17621 [==============================] - ETA: 1:13 - loss: 1.095 - ETA: 1:11 - loss: 1.086 - ETA: 1:08 - loss: 1.085 - ETA: 1:06 - loss: 1.087 - ETA: 1:04 - loss: 1.087 - ETA: 1:02 - loss: 1.085 - ETA: 59s - loss: 1.086 - ETA: 57s - loss: 1.08 - ETA: 55s - loss: 1.08 - ETA: 53s - loss: 1.08 - ETA: 50s - loss: 1.08 - ETA: 48s - loss: 1.08 - ETA: 46s - loss: 1.08 - ETA: 44s - loss: 1.08 - ETA: 42s - loss: 1.08 - ETA: 40s - loss: 1.08 - ETA: 37s - loss: 1.08 - ETA: 35s - loss: 1.08 - ETA: 33s - loss: 1.08 - ETA: 31s - loss: 1.08 - ETA: 29s - loss: 1.08 - ETA: 27s - loss: 1.08 - ETA: 24s - loss: 1.08 - ETA: 22s - loss: 1.08 - ETA: 20s - loss: 1.08 - ETA: 18s - loss: 1.08 - ETA: 16s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 9s - loss: 1.0883 - ETA: 7s - loss: 1.088 - ETA: 5s - loss: 1.088 - ETA: 3s - loss: 1.087 - ETA: 0s - loss: 1.087 - 79s 4ms/step - loss: 1.0876 - val_loss: 1.0876\n",
      "Epoch 10/100\n",
      "17621/17621 [==============================] - ETA: 1:13 - loss: 1.084 - ETA: 1:11 - loss: 1.080 - ETA: 1:08 - loss: 1.085 - ETA: 1:06 - loss: 1.084 - ETA: 1:04 - loss: 1.085 - ETA: 1:02 - loss: 1.085 - ETA: 1:00 - loss: 1.087 - ETA: 57s - loss: 1.087 - ETA: 55s - loss: 1.08 - ETA: 53s - loss: 1.08 - ETA: 51s - loss: 1.08 - ETA: 48s - loss: 1.08 - ETA: 46s - loss: 1.08 - ETA: 44s - loss: 1.08 - ETA: 42s - loss: 1.08 - ETA: 40s - loss: 1.08 - ETA: 37s - loss: 1.08 - ETA: 35s - loss: 1.08 - ETA: 33s - loss: 1.08 - ETA: 31s - loss: 1.08 - ETA: 29s - loss: 1.08 - ETA: 27s - loss: 1.08 - ETA: 24s - loss: 1.08 - ETA: 22s - loss: 1.08 - ETA: 20s - loss: 1.08 - ETA: 18s - loss: 1.08 - ETA: 16s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 9s - loss: 1.0879 - ETA: 7s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 0s - loss: 1.087 - 78s 4ms/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 11/100\n",
      "17621/17621 [==============================] - ETA: 1:13 - loss: 1.072 - ETA: 1:11 - loss: 1.080 - ETA: 1:08 - loss: 1.078 - ETA: 1:06 - loss: 1.082 - ETA: 1:04 - loss: 1.083 - ETA: 1:01 - loss: 1.085 - ETA: 59s - loss: 1.085 - ETA: 57s - loss: 1.08 - ETA: 55s - loss: 1.08 - ETA: 53s - loss: 1.08 - ETA: 51s - loss: 1.08 - ETA: 49s - loss: 1.08 - ETA: 46s - loss: 1.08 - ETA: 44s - loss: 1.08 - ETA: 42s - loss: 1.08 - ETA: 40s - loss: 1.08 - ETA: 38s - loss: 1.08 - ETA: 35s - loss: 1.08 - ETA: 33s - loss: 1.08 - ETA: 31s - loss: 1.08 - ETA: 29s - loss: 1.08 - ETA: 27s - loss: 1.08 - ETA: 24s - loss: 1.08 - ETA: 22s - loss: 1.08 - ETA: 20s - loss: 1.08 - ETA: 18s - loss: 1.08 - ETA: 16s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 9s - loss: 1.0878 - ETA: 7s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 0s - loss: 1.087 - 78s 4ms/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 12/100\n",
      "17621/17621 [==============================] - ETA: 1:12 - loss: 1.081 - ETA: 1:10 - loss: 1.086 - ETA: 1:08 - loss: 1.082 - ETA: 1:05 - loss: 1.085 - ETA: 1:03 - loss: 1.084 - ETA: 1:01 - loss: 1.085 - ETA: 59s - loss: 1.086 - ETA: 57s - loss: 1.08 - ETA: 54s - loss: 1.08 - ETA: 52s - loss: 1.08 - ETA: 50s - loss: 1.08 - ETA: 48s - loss: 1.08 - ETA: 46s - loss: 1.08 - ETA: 44s - loss: 1.08 - ETA: 42s - loss: 1.08 - ETA: 39s - loss: 1.08 - ETA: 37s - loss: 1.08 - ETA: 35s - loss: 1.08 - ETA: 33s - loss: 1.08 - ETA: 31s - loss: 1.08 - ETA: 29s - loss: 1.08 - ETA: 26s - loss: 1.08 - ETA: 24s - loss: 1.08 - ETA: 22s - loss: 1.08 - ETA: 20s - loss: 1.08 - ETA: 18s - loss: 1.08 - ETA: 16s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 9s - loss: 1.0876 - ETA: 7s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 0s - loss: 1.087 - 78s 4ms/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 13/100\n",
      "17621/17621 [==============================] - ETA: 1:13 - loss: 1.081 - ETA: 1:11 - loss: 1.079 - ETA: 1:09 - loss: 1.084 - ETA: 1:06 - loss: 1.086 - ETA: 1:04 - loss: 1.087 - ETA: 1:02 - loss: 1.087 - ETA: 1:02 - loss: 1.086 - ETA: 1:00 - loss: 1.087 - ETA: 1:00 - loss: 1.089 - ETA: 1:00 - loss: 1.090 - ETA: 58s - loss: 1.090 - ETA: 55s - loss: 1.08 - ETA: 52s - loss: 1.08 - ETA: 49s - loss: 1.08 - ETA: 46s - loss: 1.08 - ETA: 44s - loss: 1.08 - ETA: 41s - loss: 1.08 - ETA: 38s - loss: 1.08 - ETA: 36s - loss: 1.08 - ETA: 33s - loss: 1.08 - ETA: 31s - loss: 1.08 - ETA: 29s - loss: 1.08 - ETA: 26s - loss: 1.08 - ETA: 24s - loss: 1.08 - ETA: 21s - loss: 1.08 - ETA: 19s - loss: 1.08 - ETA: 17s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 7s - loss: 1.0871 - ETA: 5s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 0s - loss: 1.087 - 82s 5ms/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 14/100\n",
      "17621/17621 [==============================] - ETA: 1:13 - loss: 1.086 - ETA: 1:10 - loss: 1.087 - ETA: 1:08 - loss: 1.086 - ETA: 1:05 - loss: 1.085 - ETA: 1:03 - loss: 1.083 - ETA: 1:01 - loss: 1.083 - ETA: 59s - loss: 1.084 - ETA: 57s - loss: 1.08 - ETA: 55s - loss: 1.08 - ETA: 53s - loss: 1.08 - ETA: 51s - loss: 1.08 - ETA: 48s - loss: 1.08 - ETA: 46s - loss: 1.08 - ETA: 44s - loss: 1.08 - ETA: 42s - loss: 1.08 - ETA: 40s - loss: 1.08 - ETA: 37s - loss: 1.08 - ETA: 35s - loss: 1.08 - ETA: 33s - loss: 1.08 - ETA: 31s - loss: 1.08 - ETA: 29s - loss: 1.08 - ETA: 26s - loss: 1.08 - ETA: 24s - loss: 1.08 - ETA: 22s - loss: 1.08 - ETA: 20s - loss: 1.08 - ETA: 18s - loss: 1.08 - ETA: 16s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 9s - loss: 1.0865 - ETA: 7s - loss: 1.086 - ETA: 5s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 0s - loss: 1.087 - 78s 4ms/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 15/100\n",
      "17621/17621 [==============================] - ETA: 1:10 - loss: 1.083 - ETA: 1:08 - loss: 1.089 - ETA: 1:06 - loss: 1.094 - ETA: 1:04 - loss: 1.094 - ETA: 1:03 - loss: 1.094 - ETA: 1:01 - loss: 1.092 - ETA: 58s - loss: 1.090 - ETA: 56s - loss: 1.09 - ETA: 54s - loss: 1.08 - ETA: 52s - loss: 1.08 - ETA: 50s - loss: 1.08 - ETA: 48s - loss: 1.08 - ETA: 46s - loss: 1.08 - ETA: 43s - loss: 1.08 - ETA: 41s - loss: 1.08 - ETA: 39s - loss: 1.08 - ETA: 37s - loss: 1.08 - ETA: 35s - loss: 1.08 - ETA: 33s - loss: 1.08 - ETA: 31s - loss: 1.08 - ETA: 28s - loss: 1.08 - ETA: 26s - loss: 1.08 - ETA: 24s - loss: 1.08 - ETA: 22s - loss: 1.08 - ETA: 20s - loss: 1.08 - ETA: 18s - loss: 1.08 - ETA: 16s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 9s - loss: 1.0876 - ETA: 7s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 0s - loss: 1.087 - 78s 4ms/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 16/100\n",
      "17621/17621 [==============================] - ETA: 1:13 - loss: 1.092 - ETA: 1:10 - loss: 1.085 - ETA: 1:07 - loss: 1.083 - ETA: 1:05 - loss: 1.084 - ETA: 1:06 - loss: 1.085 - ETA: 1:11 - loss: 1.087 - ETA: 1:08 - loss: 1.087 - ETA: 1:06 - loss: 1.086 - ETA: 1:04 - loss: 1.086 - ETA: 1:01 - loss: 1.085 - ETA: 58s - loss: 1.086 - ETA: 56s - loss: 1.08 - ETA: 53s - loss: 1.08 - ETA: 51s - loss: 1.08 - ETA: 49s - loss: 1.08 - ETA: 46s - loss: 1.08 - ETA: 44s - loss: 1.08 - ETA: 41s - loss: 1.08 - ETA: 38s - loss: 1.08 - ETA: 36s - loss: 1.08 - ETA: 33s - loss: 1.08 - ETA: 31s - loss: 1.08 - ETA: 28s - loss: 1.08 - ETA: 25s - loss: 1.08 - ETA: 23s - loss: 1.08 - ETA: 20s - loss: 1.08 - ETA: 18s - loss: 1.08 - ETA: 15s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 8s - loss: 1.0871 - ETA: 5s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 1s - loss: 1.087 - 89s 5ms/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17621/17621 [==============================] - ETA: 1:19 - loss: 1.093 - ETA: 1:18 - loss: 1.087 - ETA: 1:15 - loss: 1.083 - ETA: 1:13 - loss: 1.087 - ETA: 1:11 - loss: 1.089 - ETA: 1:08 - loss: 1.088 - ETA: 1:06 - loss: 1.088 - ETA: 1:04 - loss: 1.089 - ETA: 1:02 - loss: 1.090 - ETA: 1:02 - loss: 1.090 - ETA: 58s - loss: 1.091 - ETA: 56s - loss: 1.09 - ETA: 53s - loss: 1.09 - ETA: 50s - loss: 1.08 - ETA: 48s - loss: 1.08 - ETA: 45s - loss: 1.08 - ETA: 42s - loss: 1.08 - ETA: 39s - loss: 1.08 - ETA: 37s - loss: 1.08 - ETA: 34s - loss: 1.08 - ETA: 32s - loss: 1.08 - ETA: 29s - loss: 1.08 - ETA: 27s - loss: 1.08 - ETA: 24s - loss: 1.08 - ETA: 22s - loss: 1.08 - ETA: 19s - loss: 1.08 - ETA: 17s - loss: 1.08 - ETA: 15s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 7s - loss: 1.0881 - ETA: 5s - loss: 1.088 - ETA: 3s - loss: 1.087 - ETA: 0s - loss: 1.087 - 83s 5ms/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 18/100\n",
      "17621/17621 [==============================] - ETA: 1:13 - loss: 1.092 - ETA: 1:10 - loss: 1.094 - ETA: 1:08 - loss: 1.091 - ETA: 1:06 - loss: 1.092 - ETA: 1:04 - loss: 1.090 - ETA: 1:02 - loss: 1.089 - ETA: 59s - loss: 1.089 - ETA: 57s - loss: 1.08 - ETA: 55s - loss: 1.08 - ETA: 52s - loss: 1.09 - ETA: 50s - loss: 1.08 - ETA: 48s - loss: 1.08 - ETA: 46s - loss: 1.08 - ETA: 44s - loss: 1.09 - ETA: 42s - loss: 1.09 - ETA: 39s - loss: 1.09 - ETA: 37s - loss: 1.09 - ETA: 35s - loss: 1.09 - ETA: 33s - loss: 1.09 - ETA: 31s - loss: 1.08 - ETA: 29s - loss: 1.08 - ETA: 26s - loss: 1.08 - ETA: 24s - loss: 1.08 - ETA: 22s - loss: 1.08 - ETA: 20s - loss: 1.08 - ETA: 18s - loss: 1.08 - ETA: 16s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 9s - loss: 1.0872 - ETA: 7s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 0s - loss: 1.087 - 78s 4ms/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 19/100\n",
      "17621/17621 [==============================] - ETA: 1:11 - loss: 1.086 - ETA: 1:09 - loss: 1.084 - ETA: 1:07 - loss: 1.086 - ETA: 1:05 - loss: 1.087 - ETA: 1:03 - loss: 1.086 - ETA: 1:01 - loss: 1.088 - ETA: 59s - loss: 1.089 - ETA: 57s - loss: 1.08 - ETA: 55s - loss: 1.08 - ETA: 53s - loss: 1.09 - ETA: 50s - loss: 1.08 - ETA: 48s - loss: 1.08 - ETA: 46s - loss: 1.08 - ETA: 44s - loss: 1.08 - ETA: 42s - loss: 1.08 - ETA: 40s - loss: 1.08 - ETA: 37s - loss: 1.08 - ETA: 35s - loss: 1.08 - ETA: 33s - loss: 1.08 - ETA: 31s - loss: 1.08 - ETA: 29s - loss: 1.08 - ETA: 27s - loss: 1.08 - ETA: 24s - loss: 1.08 - ETA: 22s - loss: 1.08 - ETA: 20s - loss: 1.08 - ETA: 18s - loss: 1.08 - ETA: 16s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 9s - loss: 1.0881 - ETA: 7s - loss: 1.088 - ETA: 5s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 0s - loss: 1.087 - 78s 4ms/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 20/100\n",
      "17621/17621 [==============================] - ETA: 1:14 - loss: 1.071 - ETA: 1:12 - loss: 1.075 - ETA: 1:08 - loss: 1.078 - ETA: 1:06 - loss: 1.081 - ETA: 1:04 - loss: 1.085 - ETA: 1:02 - loss: 1.085 - ETA: 59s - loss: 1.085 - ETA: 57s - loss: 1.08 - ETA: 55s - loss: 1.08 - ETA: 53s - loss: 1.08 - ETA: 50s - loss: 1.08 - ETA: 48s - loss: 1.08 - ETA: 46s - loss: 1.08 - ETA: 44s - loss: 1.08 - ETA: 42s - loss: 1.08 - ETA: 39s - loss: 1.08 - ETA: 37s - loss: 1.08 - ETA: 35s - loss: 1.08 - ETA: 33s - loss: 1.08 - ETA: 31s - loss: 1.08 - ETA: 29s - loss: 1.08 - ETA: 26s - loss: 1.08 - ETA: 24s - loss: 1.08 - ETA: 22s - loss: 1.08 - ETA: 20s - loss: 1.08 - ETA: 18s - loss: 1.08 - ETA: 16s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 9s - loss: 1.0874 - ETA: 7s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 0s - loss: 1.087 - 79s 4ms/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 21/100\n",
      "17621/17621 [==============================] - ETA: 1:19 - loss: 1.081 - ETA: 1:14 - loss: 1.091 - ETA: 1:10 - loss: 1.087 - ETA: 1:07 - loss: 1.085 - ETA: 1:05 - loss: 1.085 - ETA: 1:02 - loss: 1.086 - ETA: 1:00 - loss: 1.086 - ETA: 58s - loss: 1.087 - ETA: 56s - loss: 1.08 - ETA: 53s - loss: 1.08 - ETA: 51s - loss: 1.08 - ETA: 49s - loss: 1.08 - ETA: 47s - loss: 1.08 - ETA: 44s - loss: 1.08 - ETA: 42s - loss: 1.08 - ETA: 40s - loss: 1.08 - ETA: 38s - loss: 1.08 - ETA: 36s - loss: 1.08 - ETA: 34s - loss: 1.08 - ETA: 31s - loss: 1.08 - ETA: 29s - loss: 1.08 - ETA: 27s - loss: 1.08 - ETA: 25s - loss: 1.08 - ETA: 22s - loss: 1.08 - ETA: 20s - loss: 1.08 - ETA: 18s - loss: 1.08 - ETA: 16s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 9s - loss: 1.0878 - ETA: 7s - loss: 1.087 - ETA: 5s - loss: 1.087 - ETA: 3s - loss: 1.087 - ETA: 0s - loss: 1.087 - 79s 4ms/step - loss: 1.0875 - val_loss: 1.0875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c03cb6a0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A simple bidirectional LSTM with glove embeddings and two dense layers\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(word_index) + 1,\n",
    "                     300,\n",
    "                     weights=[embedding_matrix],\n",
    "                     input_length=max_len,\n",
    "                     trainable=False))\n",
    "model.add(SpatialDropout1D(0.3))\n",
    "model.add(Bidirectional(LSTM(300, dropout=0.3, recurrent_dropout=0.3)))\n",
    "\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.8))\n",
    "\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.8))\n",
    "\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "# Fit the model with early stopping callback\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
    "model.fit(xtrain_pad, y=ytrain_enc, batch_size=512, epochs=100, \n",
    "          verbose=1, validation_data=(xvalid_pad, yvalid_enc), callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17621 samples, validate on 1958 samples\n",
      "Epoch 1/100\n",
      "17621/17621 [==============================] - ETA: 4:50 - loss: 1.098 - ETA: 3:01 - loss: 1.098 - ETA: 2:33 - loss: 1.098 - ETA: 2:06 - loss: 1.098 - ETA: 1:50 - loss: 1.098 - ETA: 1:46 - loss: 1.098 - ETA: 1:37 - loss: 1.098 - ETA: 1:29 - loss: 1.098 - ETA: 1:21 - loss: 1.098 - ETA: 1:15 - loss: 1.098 - ETA: 1:10 - loss: 1.098 - ETA: 1:05 - loss: 1.098 - ETA: 1:00 - loss: 1.097 - ETA: 56s - loss: 1.097 - ETA: 52s - loss: 1.09 - ETA: 49s - loss: 1.09 - ETA: 45s - loss: 1.09 - ETA: 42s - loss: 1.09 - ETA: 39s - loss: 1.09 - ETA: 36s - loss: 1.09 - ETA: 33s - loss: 1.09 - ETA: 30s - loss: 1.09 - ETA: 27s - loss: 1.09 - ETA: 25s - loss: 1.09 - ETA: 22s - loss: 1.09 - ETA: 20s - loss: 1.09 - ETA: 17s - loss: 1.09 - ETA: 15s - loss: 1.09 - ETA: 12s - loss: 1.09 - ETA: 10s - loss: 1.09 - ETA: 7s - loss: 1.0968 - ETA: 5s - loss: 1.096 - ETA: 3s - loss: 1.096 - ETA: 0s - loss: 1.096 - 84s 5ms/step - loss: 1.0965 - val_loss: 1.0946\n",
      "Epoch 2/100\n",
      "17621/17621 [==============================] - ETA: 1:04 - loss: 1.093 - ETA: 1:03 - loss: 1.094 - ETA: 1:00 - loss: 1.095 - ETA: 58s - loss: 1.094 - ETA: 56s - loss: 1.09 - ETA: 54s - loss: 1.09 - ETA: 53s - loss: 1.09 - ETA: 51s - loss: 1.09 - ETA: 49s - loss: 1.09 - ETA: 47s - loss: 1.09 - ETA: 45s - loss: 1.09 - ETA: 43s - loss: 1.09 - ETA: 41s - loss: 1.09 - ETA: 39s - loss: 1.09 - ETA: 37s - loss: 1.09 - ETA: 35s - loss: 1.09 - ETA: 33s - loss: 1.09 - ETA: 31s - loss: 1.09 - ETA: 29s - loss: 1.09 - ETA: 27s - loss: 1.09 - ETA: 25s - loss: 1.09 - ETA: 24s - loss: 1.09 - ETA: 22s - loss: 1.09 - ETA: 20s - loss: 1.09 - ETA: 18s - loss: 1.09 - ETA: 16s - loss: 1.09 - ETA: 14s - loss: 1.09 - ETA: 12s - loss: 1.09 - ETA: 10s - loss: 1.09 - ETA: 8s - loss: 1.0933 - ETA: 6s - loss: 1.093 - ETA: 4s - loss: 1.093 - ETA: 2s - loss: 1.093 - ETA: 0s - loss: 1.093 - 70s 4ms/step - loss: 1.0931 - val_loss: 1.0918\n",
      "Epoch 3/100\n",
      "17621/17621 [==============================] - ETA: 1:13 - loss: 1.096 - ETA: 1:09 - loss: 1.093 - ETA: 1:05 - loss: 1.092 - ETA: 1:01 - loss: 1.092 - ETA: 59s - loss: 1.093 - ETA: 57s - loss: 1.09 - ETA: 54s - loss: 1.09 - ETA: 52s - loss: 1.09 - ETA: 50s - loss: 1.09 - ETA: 49s - loss: 1.09 - ETA: 47s - loss: 1.09 - ETA: 45s - loss: 1.09 - ETA: 46s - loss: 1.09 - ETA: 45s - loss: 1.09 - ETA: 42s - loss: 1.09 - ETA: 40s - loss: 1.09 - ETA: 38s - loss: 1.09 - ETA: 35s - loss: 1.09 - ETA: 33s - loss: 1.09 - ETA: 31s - loss: 1.09 - ETA: 29s - loss: 1.09 - ETA: 26s - loss: 1.09 - ETA: 24s - loss: 1.09 - ETA: 22s - loss: 1.09 - ETA: 20s - loss: 1.09 - ETA: 18s - loss: 1.09 - ETA: 16s - loss: 1.09 - ETA: 13s - loss: 1.09 - ETA: 11s - loss: 1.09 - ETA: 9s - loss: 1.0912 - ETA: 7s - loss: 1.091 - ETA: 5s - loss: 1.091 - ETA: 3s - loss: 1.091 - ETA: 0s - loss: 1.090 - 77s 4ms/step - loss: 1.0908 - val_loss: 1.0900\n",
      "Epoch 4/100\n",
      "17621/17621 [==============================] - ETA: 1:03 - loss: 1.089 - ETA: 1:02 - loss: 1.095 - ETA: 1:00 - loss: 1.093 - ETA: 59s - loss: 1.093 - ETA: 57s - loss: 1.09 - ETA: 55s - loss: 1.09 - ETA: 53s - loss: 1.09 - ETA: 51s - loss: 1.09 - ETA: 49s - loss: 1.09 - ETA: 47s - loss: 1.09 - ETA: 45s - loss: 1.09 - ETA: 43s - loss: 1.09 - ETA: 41s - loss: 1.09 - ETA: 39s - loss: 1.09 - ETA: 38s - loss: 1.09 - ETA: 36s - loss: 1.09 - ETA: 34s - loss: 1.09 - ETA: 32s - loss: 1.09 - ETA: 30s - loss: 1.09 - ETA: 28s - loss: 1.09 - ETA: 26s - loss: 1.09 - ETA: 24s - loss: 1.09 - ETA: 22s - loss: 1.09 - ETA: 20s - loss: 1.09 - ETA: 18s - loss: 1.09 - ETA: 16s - loss: 1.08 - ETA: 14s - loss: 1.09 - ETA: 12s - loss: 1.09 - ETA: 10s - loss: 1.08 - ETA: 8s - loss: 1.0900 - ETA: 6s - loss: 1.089 - ETA: 4s - loss: 1.089 - ETA: 2s - loss: 1.089 - ETA: 0s - loss: 1.089 - 71s 4ms/step - loss: 1.0894 - val_loss: 1.0889\n",
      "Epoch 5/100\n",
      "17621/17621 [==============================] - ETA: 1:05 - loss: 1.088 - ETA: 1:04 - loss: 1.083 - ETA: 1:02 - loss: 1.083 - ETA: 1:00 - loss: 1.085 - ETA: 58s - loss: 1.087 - ETA: 56s - loss: 1.08 - ETA: 54s - loss: 1.08 - ETA: 51s - loss: 1.08 - ETA: 49s - loss: 1.08 - ETA: 47s - loss: 1.08 - ETA: 45s - loss: 1.08 - ETA: 43s - loss: 1.08 - ETA: 41s - loss: 1.08 - ETA: 39s - loss: 1.08 - ETA: 37s - loss: 1.08 - ETA: 35s - loss: 1.08 - ETA: 33s - loss: 1.08 - ETA: 31s - loss: 1.08 - ETA: 29s - loss: 1.08 - ETA: 28s - loss: 1.08 - ETA: 26s - loss: 1.08 - ETA: 24s - loss: 1.08 - ETA: 22s - loss: 1.08 - ETA: 20s - loss: 1.08 - ETA: 18s - loss: 1.08 - ETA: 16s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 8s - loss: 1.0888 - ETA: 6s - loss: 1.088 - ETA: 4s - loss: 1.088 - ETA: 2s - loss: 1.088 - ETA: 0s - loss: 1.088 - 71s 4ms/step - loss: 1.0886 - val_loss: 1.0882\n",
      "Epoch 6/100\n",
      "17621/17621 [==============================] - ETA: 1:06 - loss: 1.086 - ETA: 1:05 - loss: 1.086 - ETA: 1:03 - loss: 1.089 - ETA: 1:00 - loss: 1.089 - ETA: 58s - loss: 1.091 - ETA: 55s - loss: 1.09 - ETA: 54s - loss: 1.09 - ETA: 52s - loss: 1.09 - ETA: 50s - loss: 1.08 - ETA: 48s - loss: 1.08 - ETA: 46s - loss: 1.09 - ETA: 44s - loss: 1.08 - ETA: 42s - loss: 1.09 - ETA: 40s - loss: 1.09 - ETA: 38s - loss: 1.08 - ETA: 36s - loss: 1.08 - ETA: 34s - loss: 1.08 - ETA: 32s - loss: 1.08 - ETA: 32s - loss: 1.08 - ETA: 31s - loss: 1.08 - ETA: 29s - loss: 1.08 - ETA: 27s - loss: 1.08 - ETA: 24s - loss: 1.08 - ETA: 22s - loss: 1.08 - ETA: 20s - loss: 1.08 - ETA: 18s - loss: 1.08 - ETA: 15s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 9s - loss: 1.0880 - ETA: 7s - loss: 1.088 - ETA: 5s - loss: 1.088 - ETA: 2s - loss: 1.088 - ETA: 0s - loss: 1.088 - 75s 4ms/step - loss: 1.0880 - val_loss: 1.0879\n",
      "Epoch 7/100\n",
      "17621/17621 [==============================] - ETA: 1:03 - loss: 1.088 - ETA: 1:01 - loss: 1.085 - ETA: 59s - loss: 1.086 - ETA: 58s - loss: 1.08 - ETA: 56s - loss: 1.08 - ETA: 54s - loss: 1.08 - ETA: 53s - loss: 1.08 - ETA: 51s - loss: 1.08 - ETA: 49s - loss: 1.08 - ETA: 47s - loss: 1.08 - ETA: 45s - loss: 1.08 - ETA: 43s - loss: 1.08 - ETA: 41s - loss: 1.08 - ETA: 39s - loss: 1.08 - ETA: 37s - loss: 1.08 - ETA: 35s - loss: 1.08 - ETA: 33s - loss: 1.08 - ETA: 31s - loss: 1.08 - ETA: 30s - loss: 1.08 - ETA: 28s - loss: 1.08 - ETA: 26s - loss: 1.08 - ETA: 24s - loss: 1.08 - ETA: 22s - loss: 1.08 - ETA: 20s - loss: 1.08 - ETA: 18s - loss: 1.08 - ETA: 16s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 8s - loss: 1.0876 - ETA: 6s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 0s - loss: 1.087 - 69s 4ms/step - loss: 1.0878 - val_loss: 1.0877\n",
      "Epoch 8/100\n",
      "17621/17621 [==============================] - ETA: 1:02 - loss: 1.086 - ETA: 1:00 - loss: 1.088 - ETA: 58s - loss: 1.088 - ETA: 56s - loss: 1.08 - ETA: 54s - loss: 1.08 - ETA: 53s - loss: 1.09 - ETA: 51s - loss: 1.09 - ETA: 49s - loss: 1.08 - ETA: 47s - loss: 1.08 - ETA: 45s - loss: 1.08 - ETA: 43s - loss: 1.08 - ETA: 41s - loss: 1.08 - ETA: 39s - loss: 1.08 - ETA: 38s - loss: 1.08 - ETA: 36s - loss: 1.08 - ETA: 34s - loss: 1.08 - ETA: 32s - loss: 1.08 - ETA: 30s - loss: 1.08 - ETA: 28s - loss: 1.08 - ETA: 26s - loss: 1.08 - ETA: 24s - loss: 1.08 - ETA: 23s - loss: 1.08 - ETA: 21s - loss: 1.08 - ETA: 19s - loss: 1.08 - ETA: 17s - loss: 1.08 - ETA: 15s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 8s - loss: 1.0883 - ETA: 6s - loss: 1.088 - ETA: 4s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 0s - loss: 1.087 - 67s 4ms/step - loss: 1.0876 - val_loss: 1.0876\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17621/17621 [==============================] - ETA: 1:01 - loss: 1.079 - ETA: 1:00 - loss: 1.081 - ETA: 58s - loss: 1.080 - ETA: 56s - loss: 1.08 - ETA: 54s - loss: 1.08 - ETA: 55s - loss: 1.08 - ETA: 53s - loss: 1.08 - ETA: 50s - loss: 1.08 - ETA: 48s - loss: 1.08 - ETA: 46s - loss: 1.08 - ETA: 44s - loss: 1.08 - ETA: 42s - loss: 1.08 - ETA: 40s - loss: 1.08 - ETA: 38s - loss: 1.08 - ETA: 36s - loss: 1.08 - ETA: 34s - loss: 1.08 - ETA: 33s - loss: 1.08 - ETA: 31s - loss: 1.08 - ETA: 29s - loss: 1.08 - ETA: 27s - loss: 1.08 - ETA: 25s - loss: 1.08 - ETA: 23s - loss: 1.08 - ETA: 21s - loss: 1.08 - ETA: 19s - loss: 1.08 - ETA: 17s - loss: 1.08 - ETA: 15s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 8s - loss: 1.0875 - ETA: 6s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 0s - loss: 1.087 - 68s 4ms/step - loss: 1.0876 - val_loss: 1.0876\n",
      "Epoch 10/100\n",
      "17621/17621 [==============================] - ETA: 1:01 - loss: 1.086 - ETA: 1:00 - loss: 1.086 - ETA: 58s - loss: 1.082 - ETA: 56s - loss: 1.08 - ETA: 55s - loss: 1.08 - ETA: 53s - loss: 1.08 - ETA: 51s - loss: 1.08 - ETA: 49s - loss: 1.08 - ETA: 47s - loss: 1.08 - ETA: 45s - loss: 1.08 - ETA: 43s - loss: 1.08 - ETA: 41s - loss: 1.08 - ETA: 39s - loss: 1.08 - ETA: 38s - loss: 1.08 - ETA: 36s - loss: 1.08 - ETA: 34s - loss: 1.08 - ETA: 32s - loss: 1.08 - ETA: 30s - loss: 1.08 - ETA: 28s - loss: 1.08 - ETA: 26s - loss: 1.08 - ETA: 25s - loss: 1.08 - ETA: 23s - loss: 1.08 - ETA: 21s - loss: 1.08 - ETA: 19s - loss: 1.08 - ETA: 17s - loss: 1.08 - ETA: 15s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 8s - loss: 1.0875 - ETA: 6s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 0s - loss: 1.087 - 67s 4ms/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 11/100\n",
      "17621/17621 [==============================] - ETA: 1:04 - loss: 1.093 - ETA: 1:03 - loss: 1.093 - ETA: 1:00 - loss: 1.087 - ETA: 57s - loss: 1.087 - ETA: 55s - loss: 1.08 - ETA: 53s - loss: 1.08 - ETA: 51s - loss: 1.08 - ETA: 49s - loss: 1.08 - ETA: 47s - loss: 1.08 - ETA: 45s - loss: 1.08 - ETA: 44s - loss: 1.08 - ETA: 42s - loss: 1.08 - ETA: 40s - loss: 1.08 - ETA: 38s - loss: 1.08 - ETA: 36s - loss: 1.08 - ETA: 34s - loss: 1.08 - ETA: 32s - loss: 1.08 - ETA: 30s - loss: 1.08 - ETA: 28s - loss: 1.08 - ETA: 27s - loss: 1.08 - ETA: 25s - loss: 1.08 - ETA: 23s - loss: 1.08 - ETA: 21s - loss: 1.08 - ETA: 19s - loss: 1.08 - ETA: 17s - loss: 1.08 - ETA: 15s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 8s - loss: 1.0874 - ETA: 6s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 0s - loss: 1.087 - 67s 4ms/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 12/100\n",
      "17621/17621 [==============================] - ETA: 1:03 - loss: 1.080 - ETA: 1:00 - loss: 1.081 - ETA: 58s - loss: 1.085 - ETA: 56s - loss: 1.08 - ETA: 55s - loss: 1.08 - ETA: 53s - loss: 1.08 - ETA: 51s - loss: 1.08 - ETA: 49s - loss: 1.08 - ETA: 47s - loss: 1.08 - ETA: 45s - loss: 1.08 - ETA: 43s - loss: 1.08 - ETA: 41s - loss: 1.08 - ETA: 39s - loss: 1.08 - ETA: 38s - loss: 1.08 - ETA: 36s - loss: 1.08 - ETA: 34s - loss: 1.08 - ETA: 32s - loss: 1.08 - ETA: 30s - loss: 1.08 - ETA: 28s - loss: 1.08 - ETA: 26s - loss: 1.08 - ETA: 25s - loss: 1.08 - ETA: 23s - loss: 1.08 - ETA: 21s - loss: 1.08 - ETA: 19s - loss: 1.08 - ETA: 17s - loss: 1.08 - ETA: 15s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 8s - loss: 1.0868 - ETA: 6s - loss: 1.086 - ETA: 4s - loss: 1.086 - ETA: 2s - loss: 1.087 - ETA: 0s - loss: 1.087 - 67s 4ms/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 13/100\n",
      "17621/17621 [==============================] - ETA: 1:01 - loss: 1.091 - ETA: 1:00 - loss: 1.089 - ETA: 58s - loss: 1.089 - ETA: 57s - loss: 1.09 - ETA: 55s - loss: 1.09 - ETA: 53s - loss: 1.08 - ETA: 51s - loss: 1.08 - ETA: 49s - loss: 1.08 - ETA: 47s - loss: 1.08 - ETA: 45s - loss: 1.08 - ETA: 43s - loss: 1.08 - ETA: 42s - loss: 1.08 - ETA: 40s - loss: 1.08 - ETA: 38s - loss: 1.08 - ETA: 36s - loss: 1.08 - ETA: 34s - loss: 1.08 - ETA: 32s - loss: 1.08 - ETA: 30s - loss: 1.08 - ETA: 28s - loss: 1.08 - ETA: 26s - loss: 1.08 - ETA: 25s - loss: 1.08 - ETA: 23s - loss: 1.08 - ETA: 21s - loss: 1.08 - ETA: 19s - loss: 1.08 - ETA: 17s - loss: 1.08 - ETA: 15s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 11s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 8s - loss: 1.0878 - ETA: 6s - loss: 1.087 - ETA: 4s - loss: 1.087 - ETA: 2s - loss: 1.087 - ETA: 0s - loss: 1.087 - 67s 4ms/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 14/100\n",
      "17621/17621 [==============================] - ETA: 1:02 - loss: 1.085 - ETA: 1:01 - loss: 1.091 - ETA: 58s - loss: 1.088 - ETA: 56s - loss: 1.08 - ETA: 54s - loss: 1.08 - ETA: 52s - loss: 1.08 - ETA: 51s - loss: 1.08 - ETA: 49s - loss: 1.08 - ETA: 47s - loss: 1.08 - ETA: 45s - loss: 1.08 - ETA: 43s - loss: 1.08 - ETA: 41s - loss: 1.08 - ETA: 39s - loss: 1.08 - ETA: 38s - loss: 1.08 - ETA: 36s - loss: 1.08 - ETA: 34s - loss: 1.08 - ETA: 32s - loss: 1.08 - ETA: 30s - loss: 1.08 - ETA: 29s - loss: 1.08 - ETA: 27s - loss: 1.08 - ETA: 25s - loss: 1.08 - ETA: 23s - loss: 1.08 - ETA: 21s - loss: 1.08 - ETA: 19s - loss: 1.08 - ETA: 17s - loss: 1.08 - ETA: 15s - loss: 1.08 - ETA: 13s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 8s - loss: 1.0884 - ETA: 6s - loss: 1.088 - ETA: 4s - loss: 1.088 - ETA: 2s - loss: 1.088 - ETA: 0s - loss: 1.087 - 68s 4ms/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 15/100\n",
      "17621/17621 [==============================] - ETA: 1:02 - loss: 1.082 - ETA: 1:00 - loss: 1.079 - ETA: 58s - loss: 1.078 - ETA: 56s - loss: 1.08 - ETA: 54s - loss: 1.08 - ETA: 53s - loss: 1.08 - ETA: 51s - loss: 1.08 - ETA: 49s - loss: 1.08 - ETA: 47s - loss: 1.08 - ETA: 45s - loss: 1.08 - ETA: 44s - loss: 1.08 - ETA: 42s - loss: 1.08 - ETA: 40s - loss: 1.08 - ETA: 38s - loss: 1.08 - ETA: 36s - loss: 1.08 - ETA: 34s - loss: 1.08 - ETA: 32s - loss: 1.08 - ETA: 31s - loss: 1.08 - ETA: 29s - loss: 1.08 - ETA: 27s - loss: 1.08 - ETA: 25s - loss: 1.08 - ETA: 23s - loss: 1.08 - ETA: 21s - loss: 1.08 - ETA: 19s - loss: 1.08 - ETA: 17s - loss: 1.08 - ETA: 15s - loss: 1.08 - ETA: 14s - loss: 1.08 - ETA: 12s - loss: 1.08 - ETA: 10s - loss: 1.08 - ETA: 8s - loss: 1.0875 - ETA: 6s - loss: 1.087 - ETA: 4s - loss: 1.088 - ETA: 2s - loss: 1.088 - ETA: 0s - loss: 1.087 - 68s 4ms/step - loss: 1.0875 - val_loss: 1.0875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c3a05c88>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GRU with glove embeddings and two dense layers\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(word_index) + 1,\n",
    "                     300,\n",
    "                     weights=[embedding_matrix],\n",
    "                     input_length=max_len,\n",
    "                     trainable=False))\n",
    "model.add(SpatialDropout1D(0.3))\n",
    "model.add(GRU(300, dropout=0.3, recurrent_dropout=0.3, return_sequences=True))\n",
    "model.add(GRU(300, dropout=0.3, recurrent_dropout=0.3))\n",
    "\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.8))\n",
    "\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.8))\n",
    "\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "# Fit the model with early stopping callback\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
    "model.fit(xtrain_pad, y=ytrain_enc, batch_size=512, epochs=100, \n",
    "          verbose=1, validation_data=(xvalid_pad, yvalid_enc), callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the main ensembling class. how to use it is in the next cell!\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=\"[%(asctime)s] %(levelname)s %(message)s\",\n",
    "    datefmt=\"%H:%M:%S\", stream=sys.stdout)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class Ensembler(object):\n",
    "    def __init__(self, model_dict, num_folds=3, task_type='classification', optimize=roc_auc_score,\n",
    "                 lower_is_better=False, save_path=None):\n",
    "        \"\"\"\n",
    "        Ensembler init function\n",
    "        :param model_dict: model dictionary, see README for its format\n",
    "        :param num_folds: the number of folds for ensembling\n",
    "        :param task_type: classification or regression\n",
    "        :param optimize: the function to optimize for, e.g. AUC, logloss, etc. Must have two arguments y_test and y_pred\n",
    "        :param lower_is_better: is lower value of optimization function better or higher\n",
    "        :param save_path: path to which model pickles will be dumped to along with generated predictions, or None\n",
    "        \"\"\"\n",
    "\n",
    "        self.model_dict = model_dict\n",
    "        self.levels = len(self.model_dict)\n",
    "        self.num_folds = num_folds\n",
    "        self.task_type = task_type\n",
    "        self.optimize = optimize\n",
    "        self.lower_is_better = lower_is_better\n",
    "        self.save_path = save_path\n",
    "\n",
    "        self.training_data = None\n",
    "        self.test_data = None\n",
    "        self.y = None\n",
    "        self.lbl_enc = None\n",
    "        self.y_enc = None\n",
    "        self.train_prediction_dict = None\n",
    "        self.test_prediction_dict = None\n",
    "        self.num_classes = None\n",
    "\n",
    "    def fit(self, training_data, y, lentrain):\n",
    "        \"\"\"\n",
    "        :param training_data: training data in tabular format\n",
    "        :param y: binary, multi-class or regression\n",
    "        :return: chain of models to be used in prediction\n",
    "        \"\"\"\n",
    "\n",
    "        self.training_data = training_data\n",
    "        self.y = y\n",
    "\n",
    "        if self.task_type == 'classification':\n",
    "            self.num_classes = len(np.unique(self.y))\n",
    "            logger.info(\"Found %d classes\", self.num_classes)\n",
    "            self.lbl_enc = LabelEncoder()\n",
    "            self.y_enc = self.lbl_enc.fit_transform(self.y)\n",
    "            kf = StratifiedKFold(n_splits=self.num_folds)\n",
    "            train_prediction_shape = (lentrain, self.num_classes)\n",
    "        else:\n",
    "            self.num_classes = -1\n",
    "            self.y_enc = self.y\n",
    "            kf = KFold(n_splits=self.num_folds)\n",
    "            train_prediction_shape = (lentrain, 1)\n",
    "\n",
    "        self.train_prediction_dict = {}\n",
    "        for level in range(self.levels):\n",
    "            self.train_prediction_dict[level] = np.zeros((train_prediction_shape[0],\n",
    "                                                          train_prediction_shape[1] * len(self.model_dict[level])))\n",
    "\n",
    "        for level in range(self.levels):\n",
    "\n",
    "            if level == 0:\n",
    "                temp_train = self.training_data\n",
    "            else:\n",
    "                temp_train = self.train_prediction_dict[level - 1]\n",
    "\n",
    "            for model_num, model in enumerate(self.model_dict[level]):\n",
    "                validation_scores = []\n",
    "                foldnum = 1\n",
    "                for train_index, valid_index in kf.split(self.train_prediction_dict[0], self.y_enc):\n",
    "                    logger.info(\"Training Level %d Fold # %d. Model # %d\", level, foldnum, model_num)\n",
    "\n",
    "                    if level != 0:\n",
    "                        l_training_data = temp_train[train_index]\n",
    "                        l_validation_data = temp_train[valid_index]\n",
    "                        model.fit(l_training_data, self.y_enc[train_index])\n",
    "                    else:\n",
    "                        l0_training_data = temp_train[0][model_num]\n",
    "                        if type(l0_training_data) == list:\n",
    "                            l_training_data = [x[train_index] for x in l0_training_data]\n",
    "                            l_validation_data = [x[valid_index] for x in l0_training_data]\n",
    "                        else:\n",
    "                            l_training_data = l0_training_data[train_index]\n",
    "                            l_validation_data = l0_training_data[valid_index]\n",
    "                        model.fit(l_training_data, self.y_enc[train_index])\n",
    "\n",
    "                    logger.info(\"Predicting Level %d. Fold # %d. Model # %d\", level, foldnum, model_num)\n",
    "\n",
    "                    if self.task_type == 'classification':\n",
    "                        temp_train_predictions = model.predict_proba(l_validation_data)\n",
    "                        self.train_prediction_dict[level][valid_index,\n",
    "                        (model_num * self.num_classes):(model_num * self.num_classes) +\n",
    "                                                       self.num_classes] = temp_train_predictions\n",
    "\n",
    "                    else:\n",
    "                        temp_train_predictions = model.predict(l_validation_data)\n",
    "                        self.train_prediction_dict[level][valid_index, model_num] = temp_train_predictions\n",
    "                    validation_score = self.optimize(self.y_enc[valid_index], temp_train_predictions)\n",
    "                    validation_scores.append(validation_score)\n",
    "                    logger.info(\"Level %d. Fold # %d. Model # %d. Validation Score = %f\", level, foldnum, model_num,\n",
    "                                validation_score)\n",
    "                    foldnum += 1\n",
    "                avg_score = np.mean(validation_scores)\n",
    "                std_score = np.std(validation_scores)\n",
    "                logger.info(\"Level %d. Model # %d. Mean Score = %f. Std Dev = %f\", level, model_num,\n",
    "                            avg_score, std_score)\n",
    "\n",
    "            logger.info(\"Saving predictions for level # %d\", level)\n",
    "            train_predictions_df = pd.DataFrame(self.train_prediction_dict[level])\n",
    "            train_predictions_df.to_csv(os.path.join(self.save_path, \"train_predictions_level_\" + str(level) + \".csv\"),\n",
    "                                        index=False, header=None)\n",
    "\n",
    "        return self.train_prediction_dict\n",
    "\n",
    "    def predict(self, test_data, lentest):\n",
    "        self.test_data = test_data\n",
    "        if self.task_type == 'classification':\n",
    "            test_prediction_shape = (lentest, self.num_classes)\n",
    "        else:\n",
    "            test_prediction_shape = (lentest, 1)\n",
    "\n",
    "        self.test_prediction_dict = {}\n",
    "        for level in range(self.levels):\n",
    "            self.test_prediction_dict[level] = np.zeros((test_prediction_shape[0],\n",
    "                                                         test_prediction_shape[1] * len(self.model_dict[level])))\n",
    "        self.test_data = test_data\n",
    "        for level in range(self.levels):\n",
    "            if level == 0:\n",
    "                temp_train = self.training_data\n",
    "                temp_test = self.test_data\n",
    "            else:\n",
    "                temp_train = self.train_prediction_dict[level - 1]\n",
    "                temp_test = self.test_prediction_dict[level - 1]\n",
    "\n",
    "            for model_num, model in enumerate(self.model_dict[level]):\n",
    "\n",
    "                logger.info(\"Training Fulldata Level %d. Model # %d\", level, model_num)\n",
    "                if level == 0:\n",
    "                    model.fit(temp_train[0][model_num], self.y_enc)\n",
    "                else:\n",
    "                    model.fit(temp_train, self.y_enc)\n",
    "\n",
    "                logger.info(\"Predicting Test Level %d. Model # %d\", level, model_num)\n",
    "\n",
    "                if self.task_type == 'classification':\n",
    "                    if level == 0:\n",
    "                        temp_test_predictions = model.predict_proba(temp_test[0][model_num])\n",
    "                    else:\n",
    "                        temp_test_predictions = model.predict_proba(temp_test)\n",
    "                    self.test_prediction_dict[level][:, (model_num * self.num_classes): (model_num * self.num_classes) +\n",
    "                                                                                        self.num_classes] = temp_test_predictions\n",
    "\n",
    "                else:\n",
    "                    if level == 0:\n",
    "                        temp_test_predictions = model.predict(temp_test[0][model_num])\n",
    "                    else:\n",
    "                        temp_test_predictions = model.predict(temp_test)\n",
    "                    self.test_prediction_dict[level][:, model_num] = temp_test_predictions\n",
    "\n",
    "            test_predictions_df = pd.DataFrame(self.test_prediction_dict[level])\n",
    "            test_predictions_df.to_csv(os.path.join(self.save_path, \"test_predictions_level_\" + str(level) + \".csv\"),\n",
    "                                       index=False, header=None)\n",
    "\n",
    "        return self.test_prediction_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:21:04] INFO Found 3 classes\n",
      "[16:21:04] INFO Training Level 0 Fold # 1. Model # 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Software\\Anaconda\\envs\\py3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\Software\\Anaconda\\envs\\py3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:21:08] INFO Predicting Level 0. Fold # 1. Model # 0\n",
      "[16:21:08] INFO Level 0. Fold # 1. Model # 0. Validation Score = 0.679328\n",
      "[16:21:08] INFO Training Level 0 Fold # 2. Model # 0\n",
      "[16:21:11] INFO Predicting Level 0. Fold # 2. Model # 0\n",
      "[16:21:11] INFO Level 0. Fold # 2. Model # 0. Validation Score = 0.670841\n",
      "[16:21:11] INFO Training Level 0 Fold # 3. Model # 0\n",
      "[16:21:13] INFO Predicting Level 0. Fold # 3. Model # 0\n",
      "[16:21:13] INFO Level 0. Fold # 3. Model # 0. Validation Score = 0.672830\n",
      "[16:21:13] INFO Level 0. Model # 0. Mean Score = 0.674333. Std Dev = 0.003624\n",
      "[16:21:13] INFO Training Level 0 Fold # 1. Model # 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Software\\Anaconda\\envs\\py3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\Software\\Anaconda\\envs\\py3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:21:22] INFO Predicting Level 0. Fold # 1. Model # 1\n",
      "[16:21:22] INFO Level 0. Fold # 1. Model # 1. Validation Score = 0.574757\n",
      "[16:21:22] INFO Training Level 0 Fold # 2. Model # 1\n",
      "[16:21:31] INFO Predicting Level 0. Fold # 2. Model # 1\n",
      "[16:21:31] INFO Level 0. Fold # 2. Model # 1. Validation Score = 0.561418\n",
      "[16:21:31] INFO Training Level 0 Fold # 3. Model # 1\n",
      "[16:21:38] INFO Predicting Level 0. Fold # 3. Model # 1\n",
      "[16:21:38] INFO Level 0. Fold # 3. Model # 1. Validation Score = 0.565262\n",
      "[16:21:38] INFO Level 0. Model # 1. Mean Score = 0.567146. Std Dev = 0.005607\n",
      "[16:21:38] INFO Training Level 0 Fold # 1. Model # 2\n",
      "[16:21:38] INFO Predicting Level 0. Fold # 1. Model # 2\n",
      "[16:21:38] INFO Level 0. Fold # 1. Model # 2. Validation Score = 0.463231\n",
      "[16:21:38] INFO Training Level 0 Fold # 2. Model # 2\n",
      "[16:21:38] INFO Predicting Level 0. Fold # 2. Model # 2\n",
      "[16:21:38] INFO Level 0. Fold # 2. Model # 2. Validation Score = 0.456515\n",
      "[16:21:38] INFO Training Level 0 Fold # 3. Model # 2\n",
      "[16:21:38] INFO Predicting Level 0. Fold # 3. Model # 2\n",
      "[16:21:38] INFO Level 0. Fold # 3. Model # 2. Validation Score = 0.461664\n",
      "[16:21:38] INFO Level 0. Model # 2. Mean Score = 0.460470. Std Dev = 0.002869\n",
      "[16:21:38] INFO Training Level 0 Fold # 1. Model # 3\n",
      "[16:21:38] INFO Predicting Level 0. Fold # 1. Model # 3\n",
      "[16:21:38] INFO Level 0. Fold # 1. Model # 3. Validation Score = 0.472310\n",
      "[16:21:38] INFO Training Level 0 Fold # 2. Model # 3\n",
      "[16:21:38] INFO Predicting Level 0. Fold # 2. Model # 3\n",
      "[16:21:38] INFO Level 0. Fold # 2. Model # 3. Validation Score = 0.473339\n",
      "[16:21:38] INFO Training Level 0 Fold # 3. Model # 3\n",
      "[16:21:39] INFO Predicting Level 0. Fold # 3. Model # 3\n",
      "[16:21:39] INFO Level 0. Fold # 3. Model # 3. Validation Score = 0.479033\n",
      "[16:21:39] INFO Level 0. Model # 3. Mean Score = 0.474894. Std Dev = 0.002957\n",
      "[16:21:39] INFO Saving predictions for level # 0\n",
      "[16:21:40] INFO Training Level 1 Fold # 1. Model # 0\n",
      "[16:21:53] INFO Predicting Level 1. Fold # 1. Model # 0\n",
      "[16:21:53] INFO Level 1. Fold # 1. Model # 0. Validation Score = 0.436703\n",
      "[16:21:53] INFO Training Level 1 Fold # 2. Model # 0\n",
      "[16:22:06] INFO Predicting Level 1. Fold # 2. Model # 0\n",
      "[16:22:07] INFO Level 1. Fold # 2. Model # 0. Validation Score = 0.424468\n",
      "[16:22:07] INFO Training Level 1 Fold # 3. Model # 0\n",
      "[16:22:20] INFO Predicting Level 1. Fold # 3. Model # 0\n",
      "[16:22:20] INFO Level 1. Fold # 3. Model # 0. Validation Score = 0.439232\n",
      "[16:22:20] INFO Level 1. Model # 0. Mean Score = 0.433468. Std Dev = 0.006447\n",
      "[16:22:20] INFO Saving predictions for level # 1\n",
      "[16:22:20] INFO Training Fulldata Level 0. Model # 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Software\\Anaconda\\envs\\py3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\Software\\Anaconda\\envs\\py3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:22:23] INFO Predicting Test Level 0. Model # 0\n",
      "[16:22:23] INFO Training Fulldata Level 0. Model # 1\n",
      "[16:22:29] INFO Predicting Test Level 0. Model # 1\n",
      "[16:22:29] INFO Training Fulldata Level 0. Model # 2\n",
      "[16:22:29] INFO Predicting Test Level 0. Model # 2\n",
      "[16:22:29] INFO Training Fulldata Level 0. Model # 3\n",
      "[16:22:29] INFO Predicting Test Level 0. Model # 3\n",
      "[16:22:29] INFO Training Fulldata Level 1. Model # 0\n",
      "[16:22:49] INFO Predicting Test Level 1. Model # 0\n"
     ]
    }
   ],
   "source": [
    "# specify the data to be used for every level of ensembling:\n",
    "train_data_dict = {0: [xtrain_tfv, xtrain_ctv, xtrain_tfv, xtrain_ctv], 1: [xtrain_glove]}\n",
    "test_data_dict = {0: [xvalid_tfv, xvalid_ctv, xvalid_tfv, xvalid_ctv], 1: [xvalid_glove]}\n",
    "\n",
    "model_dict = {0: [LogisticRegression(), LogisticRegression(), MultinomialNB(alpha=0.1), MultinomialNB()],\n",
    "\n",
    "              1: [xgb.XGBClassifier(silent=True, n_estimators=120, max_depth=7)]}\n",
    "\n",
    "ens = Ensembler(model_dict=model_dict, num_folds=3, task_type='classification',\n",
    "                optimize=multiclass_logloss, lower_is_better=True, save_path='')\n",
    "\n",
    "ens.fit(train_data_dict, ytrain, lentrain=xtrain_glove.shape[0])\n",
    "preds = ens.predict(test_data_dict, lentest=xvalid_glove.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42372574824662645"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check error:\n",
    "multiclass_logloss(yvalid, preds[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
